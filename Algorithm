// 算法在计算中的作用
// 1.1 算法Algorithm
//   任何良定义的计算过程，将某个值或值的集合作为输入并产生某个值或值的集合作为输出。算法在这个过程中就是一系列计算步骤的序列。
//   对一个问题的阐述，表明期望的输入/输出关系，算法描述了一个特定过程来实现这种关系。
//   正确的算法：输入实例算法以正确的输出停机。
//   不正确的算法在错误率可控时可能是可用的。
//   算法问题共有的特征：1 存在许多候选解，找尽可能的最优解。  2 存在实际应用。

// 1.1.1  以排序问题举例：
//     输入：n个数的序列
//     输出：输入序列的一个排列，满足一定关系
//     给定输入序列，称为排序问题的一个实例。   问题实例由计算该问题必须的（满足问题中的各种约束）输入组成。
//   排序问题在应用中选择算法的影响因素：将被排序的项数、这些项已被排序的程度、项值的限制、计算机体系结构、存储设备种类。

// 1.1.2 数据结构：一种存储和组织数据的方式，旨在便于访问和修改。

// 1.1.3 技术：无法用已有算法来解决问题时，能够自行设计算法、证明正确性、计算其效率。

// 1.1.4 难题
//   对于有效算法，用产生结果需要的时间来衡量其效率。
//   对于未知有效算法的问题，称之为难题。
//       如：NP完全问题（Non-deterministic Polynomial Problem/多项式复杂程度的非确定性问题）
//       1 现状：目前仍未找到对NP完全问题的有效算法
//       2 其性质：如果任一Np完全问题存在有效算法，那么所有NP完全问题都存在有效算法。
//       3 意义：有几个NP完全问题类似存在有效算法的问题，但不完全等同。可以用对问题陈述的小变动来极大改变已有算法的效率。
//       所以，如果一个问题NP完全，可以有有效算法去解决，但不一定是最佳算法，这种算法被称为“近似算法”。

// 1.1.5 并行性
//   单线程：一个计算核心处理问题，一步一步顺序往下运行。（随着功率提高，存在物理限制，不能无限提高性能）
//   多线程（并行）：用多个计算核心，分解问题，每个核心负责部分运算。（可以通过增加核心量来提高计算效率）
//   因此为了从多核计算机获取最佳性能，设计算法时要考虑并行性。


// 1.2.2 算法与其他技术
//   其他对系统性能重要的技术：
//     先进的计算机体系结构与制造技术
//     易于使用、直观的图形用户界面
//     面向对象的系统
//     集成的万维网技术
//     有线与无线的快速组网



// 算法基础
// 介绍一个贯彻始终的框架，后续的算法设计与分析都基于这个框架，就像骨头上长出肌肉、血管乃至皮肤。
// 以排序问题的插入排序算法为例，引入伪代码说明算法执行步骤、功能，分析其运行时间。
// 引入分治法开发归并排序算法，分析其运行时间。

// 2.1 插入排序
//   选出一个数，从左向右（其实就是按一个顺序）依次比较，然后放入合适的位置。
// 例
//int main()
//{
//	int arr[5];
//	int i, j, t;
//	printf("输入5个元素：");
//	for (i = 0; i < 5; i++)
//		scanf_s("%d", &arr[i]);
//	for (j = 1; j < 5; j++)       // 指出正在被插入的当前数。
//	{
//		t = arr[j];
//		i = j - 1;
//		while (i >= 0 && arr[i] > t) //循环不变式
//		{
//			arr[i + 1] = arr[i];
//			i = i - 1;
//		}
//		arr[i + 1] = t;
//	}
//	for (i = 0; i < 5; i++)
//		printf("%d ", arr[i]);
//	return 0;
//}
// 循环不变式三条性质
//     1 初始化：循环第一次迭代之前为真。（循环起码能运行一次）
//     2 保持：如果循环某次迭代为真，那下次迭代之前仍为真。（保证未满足终止条件时，循环能正常继续下去）
//     3 终止：循环终止时，证明算法是正确的。（类似for，while循环的终止条件）
// 伪代码中的一些约定：
//       1 缩进代表块结构。
//       2 退出循环后，计数器保持当前值。
//       3 符号//后内容表示注释。
//       4 多重赋值表达式，r如i=j=e,将e的值赋给i和j。
//       5 若无特殊说明，变量均为局部变量。
//       6 数组元素通过数组名[下标]来访问。
//       7 复合数据通常被组织成对象，对象又由属性组成。对象名.属性名，可以逐级向下访问。
//         把表示一个数组或对象的变量看做是其指针。y=x后，xy指向相同的对象。
//         属性记号还可串联。如f指向g，记作f.g，又x.f.g。如果y=x.f ,根据上一条有x.f.g = y.g
//         空指针可以记作NIL
//       8 按值把参数传递给过程，当对象被传递时，指向表示对象数据的指针被复制而其属性没有。

// 2.2 分析算法
//   分析算法的结果意味着预测算法需要的资源。通过分析求解某个问题的候选算法，从中选出最有效的。
//   分析前要使用一个实现技术的模型（一台假想电脑）。本书中假定为一种通用的单处理器计算模型（随机访问机）
//   RAM模型包含真实计算机的常见指令：算术指令、数据移动指令、控制指令。每条指令所需时间均为常量。
//          数据类型：整数型、浮点型。 对每个数据字节假定一个范围以符合使用需要、实际情况。
//          分析过程需要使用到的数学工具可能包括：组合学、概率论、代数技巧，识别一个公式中最具意义的项。
//          通常只选一种机器模型来分析某个给定的算法。

// 2.2.1 插入排序算法的分析（asymptotic analysis渐进分析）
//   2.2.1.1 插入排序过程需要的时间依赖输入规模。 一般来说，算法需要时间随输入规模同步增长，所以将一个程序的运行时间描述为输入规模的函数。
//       输入规模：依赖研究的问题。对不同问题，输入规模的量度不同（单位不同）。
//       运行时间：执行的基本操作数或步数
//   分析过程中，由繁到简地改进运行时间表达式，并用简单记号表示语句代价Ci（忽略具体的实际代价），更关注增长率。
//               假定注释是不可执行语句，不需要运行时间。
//   2.2.1.2 现分析伪代码如下：
//   for j=2 to A.length           c1  n
//       key = A[j]                c2  n-1
//       // insert A[j] into sort   0  n-1
//       i=j-1                     c4  n-1
//       while i>0 and A[i]>key    c5  tj(for j=2 to n求和)
//             A[i+1] = A[i]       c6  tj-1(for j=2 to n求和)
//             i = i -1            c7  tj-1(for j=2 to n求和)
//       A[i+1] = key              c8  n-1
//   算法运行时间=代价 x 次数 的总和
//   T(n) = c1n + c2(n-1) + c4(n-1) + c5(求和tj) + c6(求和tj-1) + c7(求和tj-1) + c8(n-1)
//       最佳情况 T(n) = (c1+c2+c4+c5+c8)n - (c2+c4+c5+c8) = an - b
//       最坏情况 T(n) = (c5/2+c6/2+c7/2)nn + (c1+c2+c4+c5/2-c6/2-c7/2+c8)n - (c2+c4+c5+c8) = ann + bn + c
//   注：通常运行时间对给定输入是固定的，但是也有一些随机化算法（对固定输入，其行为可能变化导致运行时间不定）

// 2.2.2 最坏情况和平均情况的分析
//     往往只考虑求最坏情况的运行时间，即对于输入规模n，算法最长运行时间。
//         最坏情况运行时间给出任何输入的运行时间上界，能确保该算法绝不会超出这个运行时间。
//         对于某些算法，最坏情况经常出现。
//         平均情况往往和最坏情况一样差。
//         随机化算法中，假定给定规模的所有输入具有相同的可能性，以允许进行概率分析并产生某个期望的运行时间。
// 注：期望是一种均值，是试验中每次可能结果的概率 x 结果的总和，用于反应随机变量平均取值大小。

// 2.2.3 增长量级
//   使用简化抽象以化简分析。
//       Ci表示代价以忽略实际代价。常量a,b,c忽略Ci进一步简化
//       关注增长率，只考虑最重要的项，如最高次项。
//       当忽略低价项及最重要项的常系数时，使用asymptotic notation（theta），记为o(最重要项因子)


// 2.3 设计算法
//   插入排序使用了增量方法（排序好子列后，将后面的元素插入子列）
//   分治法，其最坏运行时间比插入排序要少得多。
// 2.3.1 分治法
//   在算法结构上是递归的：为了解决一个给定问题，一次或多次递归调用自身来解决相关的子问题。
//   思想：原问题分解为规模较小且类似的子问题，递归求解子问题，合并子问题的解来求出原问题的解。
//   步骤：分解，解决，合并。  当待排序列长度为1时，递归开始回升。
//   2.3.1.1 
//     MERGE(A,p,q,r) 合并函数，用于合并子数列A[p...q]和A[q+1...r],结果为A[p...r]
//     过程MERGE需要o(n)的时间 n=r-p+1（待合并元素总数），每次比较两个数组的当前元素，较小的放到输出数组中，放一次比一次，直到n个元素全放入输出数组。
//     如果当一个数组已经全部放入输出数组，则另一个数组剩余元素没有必要继续比较，可直接顺次放入输出数组。所以在数组底部放特殊值，当比较时出现该值可直接跳过比较。
//     伪代码如下：
//     MERGE(A,p,q,r)
//       n1=q-p+1
//       n2=r-q
//       //let L[1...n1+1]  and R[1...n2+1] be new arrays
//       for i=1 to n1
//           L[i] = A[p+i-1]
//       for j=1 to n2
//           R[j] = A[q+j]
//       L[n1+1] = infinitas
//       R[n2+1] = infinitas
//       i = 1
//       j = 1
//       for k=p to r
//           if L[i] <= R[j]
//              A[k] = L[i]
//              i = i + 1
//           else A[k] = R[j]
//                j = j + 1
//     MERGE-SORT (A,p,r)
//       if p<r
//          q=[(p+r)/2] (取整)
//           MERGE-SORT (A,q,r)
//           MERGE-SORT (A,q+1,r)
//           MERGE (A,p,q,r)
//     C语言封装成函数如下： //(有问题)
//void Merge(char arr[],int p,int q,int r)
//{
//	int i, j, k, n1, n2;
//	n1 = q - p;
//	n2 = r - q;
//	char L[5], R[5];
//	for (i = 0; i < n1; i++)
//		L[i] = arr[p + i];
//	for (j = 0; j < n2; j++)
//		R[j] = arr[q + j];
//	L[i + 1] = 'N';
//	R[i + 1] = 'N';
//	i = 0;
//	j = 0;
//	for (k = p; k < r; k++)
//	{
//		if (L[i] <= R[j])
//		{
//			arr[k] = L[i];
//			i++;
//		}
//		else
//		{
//			arr[k] = R[j];
//			j++;
//		}
//	}
//}
//void Merge_sort(char arr[], int p, int r)
//{
//	int q = 0;
//	if (p < r)
//	{
//		q = (p + r) / 2;
//		Merge_sort(arr, p, q);      // 左列排序
//		Merge_sort(arr, q + 1, r);  // 右列排序
//		Merge(arr, p, q, r);        // 合并左右列
//	}
//}
//int main()
//{
//	int i;
//	char arr[6] = { '2','6','4','5','9','1' };
//	int p = 0;
//	int r = sizeof(arr);
//	/*printf("%d", r);*/
//	Merge_sort(arr, p, r);
//	for (i = 0; i < r; i++)
//		printf("%c ", arr[i]);
//	return 0;
//}

// test
// 2.3-2 重写MERGE，不用哨兵。
//   MERGE(A,p,q,r)
//   n1=q-p+1
//   n2=r-q
//   for i=1 to n1
//       L[i]=A[p+i-1]
//   for j=1 t0 n2
//       R[j]=A[q+j]
//   i=1
//   j=1
//   while i<=q and j<=r
//        for k=p to r
//          if L[i]<=R[j]
//             A[k]=L[i]
//             i=i+1
//          else A[k]=R[j]
//               j=j+1
//   while k<=r  
//        if i == q+1
//           A[k]=R[j]
//           k=k+1
//           j=j+1
//         else
//           A[k]=L[i]
//           k=k+1
//           j=j+1

// 2.3.4 插入排序：为排序A[1...n],递归排序A[1...n-1],然后插入A[n]，求最坏运行时间递归式
//   1 分解：当数组只剩一个元素时，耗时为常量，记作o(1)
//   2 解决：递归求解n-1个元素，需要时间T(n-1)
//   3 合并：一个具有n-1个元素的数组，插入第n个元素需要时间cn
//   递归式 T(n) = o(1)         n=1
//               = T(n-1) + cn  n>1

// 2.3.5 二分法查找最坏运行时间
//   BINARY_SEARCH(A,x)
//     low=1
//     high=A.length
//     while low<=high
//       mid=(low+high)/2
//       if A[mid] == x
//          return mid
//       elseif A[mid]<x
//          low=mid+1
//       else
//          high=mid-1
//   T(n+1)=T(n/2)+c  最坏运行时间o(lgn)

// 2.3.7 给定n个整数的集合S和另一个整数x，确定S中是否存在两个和刚好为x的元素，其运行时间为o(nlgn)
//   SUM_FIND(S,x)
//     MERGE_SORT(S,1,S.length) // 先将S从小到大归并排序 o(nlgn)
//     for i=1 to S.length      // 再二分法查找是否存在两个数和为x。 需要时间： n x o(lgn) = o(nlgn)
//         if BINARY_SEARCH(S,x-S[i]) != nil // 找到了
//            return ture
//     return false                          // 没找到
//     总运行时间为o(nlgn)

// 2.1 在归并排序中对小数组采用插入排序
//   1 插入排序：排序n/k个长度为k的子表。排序一个需要T(k)=akk+bk+c,n/k个T=n/k(akk+bk+c)=ank+bn+cn/k=o(nk)
//   2 递归式 T(a)= 0          a=1
//              = T(a/2)+ak  a=2
//     归纳得 T(a)=aklga
//     T(n/k)=nlg(n/k)   so  o(nlg(n/k))
//   3 o(nk+nlg(n/k))<=o(nlgn)
//     so k<=lg(n/k)   k max 满足k2k次幂<n
//   4 当递归的子问题耗时大于直接插入排序时对应的k即为所求

// 2.2 冒泡排序正确性
//   1 还需证明A'中的所有元素就是A中各个元素
//   2 证明j循环的循环不变式
//     初始化：第一轮迭代开始前，只有j=A[length]一个元素，显然已排序，所以第一轮迭代之前已成立
//     保持：  迭代之前，假设A[j]...A[length]是已排序的，待排序元素A[j-1]依次与A[j]...A[length]比较，
//             如果A[j-1] > A[j],则交换位置，此时整个数列已排好序。
//             即j成立情况下，j-1也成立，证明其迭代过程中保持成立。
//     终止：  当i=A.length-1时，j=A.length,A'[1...n]个元素都已排好序。
//   3 证明i,j循环不变式
//     初始化：第一次循环开始时，A[1...i-1]为空数组，循环不变式成立。
//     保持：  A[1...i-1]满足循环不变式条件，j循环保证A[i]为A[i...n]中最小的元素。
//             迭代之前，A[1...i-1]内是已升序排序的数组，且A[i]大于A[1...i-1]中每个元素
//             即A[1...i-1]成立条件下，A[1...i]也成立,证明其迭代过程中保持成立。
//     终止：  i=n,A[1...n-1]满足循环不变式，由于A[1...n-1]由数组中最小的数组成，则A[n]必大于[1...n-1]所有数，则A[1...n]已排好序。
//   4 冒泡排序最坏运行时间o(nn),且无论是否已排好序。每次都执行判断，循环总次数不变,实际运行时间恒等于o(nn).
//     插入排序最坏运行时间o(nn),一旦找到插入位置循环结束，实际运行时间<=o(nn)
//     总体而言，插入排序性能更佳

// 2.3 霍纳Horner规则正确性
//   给定系数ai(i=1...n)和x的值
//   y=0
//   for i=n downto 0
//       y=ai + xy
//   实现了求值多项式 P(x) = 求和ak(x的k次幂) = a0 + x(a2+...+x(an-1+xan)...))
//   1 o(n)
//   2 嵌套循环城际结果累加 o(nn),比霍纳规则慢
//   3 证明循环不变式
//     初始化：i=n,y=0,循环不变式成立。
//     保持：  迭代开始时，y=求和(k=0,n-i-1)a(k+i+1)(x的k次幂)
//             循环后y = ai+x求和(k=0,n-i-1)a(k+i+1) = ai(x的0次幂)+求和(k=1,n-i)a(k+i)(x的k次幂)
//             y = a(k+i)(x的0次幂) + 求和(k=1,n-i)a(k+i)(x的k次幂) = 求和(k=0,n-i)a(k+i)(x的k次幂)迭代过程中保持成立。
//     终止：i=-1 ,y=求和(k=0,n)ak(x的k次幂)

// 2.4 逆序对 数组元素大小顺序与下标顺序相反
//   1 2，3，8，6，1的五个逆序对 ： (3,4),(3,5),(4,5),(1,5),(2,5)
//   2 {n...2,1}具有最多逆序对，有(n-1+1)(n-1)/2
//   3 INSERTION_SORT(A):
//        c=0
//        for j=2 to A.length
//            key=A[j]
//            i=j-1
//            while i>0 and A[i]>key
//                  A[i+1]=A[i]
//                  i=i-1
//                  c=c+1
//             A[i-1]=key
//    Prove：
//          1 初始化：第一次循环开始前，c=0，A[1]只有一个元素，不存在逆序对，不变式成立。
//          2 保持：  c为当前A[1...j-1]的逆序对个数。
//                    本次循环时，在A[1...j-1]中找比A[j]大的元素，直至退出子循环。
//                    循环结束A[1...j-1]都比A[j]小，A[j+1...n]都比A[j]大。此时c为A[j]与A[1...j-1]的逆序对个数，不变成成立。
//          3 终止：   j=A.length+1，c为A[1...n]的逆序对个数。
//    4 
//int Merge(int arr[], int p, int q, int r)
//{
//	int c = 0, k = 0, i, j;
//	int n1 = q - p + 1;
//	int n2 = r - q;
//	int* L = (int*)malloc((n1+1) * sizeof(int));
//	int* R = (int*)malloc((n2+1) * sizeof(int));
//	for (i = 0; i < n1; i++)
//		*(L + i) = arr[p + i];
//	for (j = 0; j < n2; j++)
//		*(R + j) = arr[q + 1 + j];
//	*(L + i) = 100;
//	*(R + j) = 100;
//	i = 0;
//	j = 0;
//	for (k = p; k <= r; k++)
//	{
//		if (*(L + i) <= *(R + j))
//		{
//			arr[k] = *(L + i);
//			i++;
//		}
//		else
//		{
//			arr[k] = *(R + j);
//			j++;
//			c++;
//		}
//	}
//	//while( i<=q && j<=r)
//	//{
//	//	for (k = p; k <= r; k++)
//	//	{
//	//		if (*(L + i) <= *(R + j))
//	//		{
//	//			arr[k] = *(L + i);
//	//			i++;
//	//		}
//	//		else
//	//		{
//	//			arr[k] = *(R + j);
//	//			j++;
//	//			c++;
//	//		}
//	//	}
//	//}
//	//while (k <= r)
//	//{
//	//	if (i == q + 1)
//	//	{
//	//		arr[k] = *(R + j);
//	//		k++;
//	//		j++;
//	//	}	
//	//	else
//	//	{
//	//		arr[k] = *(L + i);
//	//		k++;
//	//		j++;
//	//	}
//	//}
//	free(L);
//	free(R);
//	return c;
//}
//int Merge_sortC(int arr[], int p, int r)
//{
//	int c = 0;
//	if (p < r)
//	{
//		int q = (p + r) / 2;
//		return Merge_sortC(arr, p, q) + Merge_sortC(arr, q + 1, r) + Merge(arr, p, q, r);
//	}
//	else
//		return 0;
//}

//int Merge_sort(int a[], int p, int q, int r)
//{
//	int t[5];
//	int c = 0;
//	int i = p;
//	int j = q + 1;
//	for (int k = p; k <= r; k++)
//	{
//		if ((j > r) || (i <= q) && (a[i] <= a[j]))
//			t[k] = a[i++];
//		else
//		{
//			t[k] = a[j++];
//			c += q - i + 1;
//		}
//	}
//	for (i = p; i <= r; i++)
//		a[i] = t[i];
//	return c;
//}
//int Merge_sortC(int a[], int p, int r)
//{
//	if (p < r)
//	{
//		int q = p + (r - p) / 2;
//		return Merge_sortC(a, p, q) + Merge_sortC(a, q + 1, r) + Merge_sort(a, p, q, r);
//	}
//	else
//		return 0;
//}
//int main()
//{
//	int arr[5] = { 2,3,8,6,1 };
//	int c = Merge_sortC(arr, 0, 4);
//	printf("%d", c);
//	return 0;
//}



// 函数增长
//   虽然有时能确定一个算法的精确运行时间，但是通常不值得计算获得多余精度。
//   当输入规模足够大时，只与运行时间的增长量级有关时，研究算法的渐进效率。

// 3.1 渐进记号
//   用来描述算法渐进运行时间的记号根据定义域为自然数集N的函数来定义。 （对整数输入规模）
//   但采用渐进记号更为方便。（目的还是为了简化）

// 3.1.1 渐进记号、函数与运行时间
//   如插入排序，其最坏运行时间可写为函数T(n)=ann+bn+c,使用渐进记号o(nn)来描述它。
//   除时间函数外，渐进记号还可以描述算法的其他方面，如：空间数量，甚至是与算法无关的函数。
//   使用渐进记号来描述算法运行时间，不光是最坏运行时间，更希望是对所有输入的，因此有完全适合任何输入的运行时间的渐进记号。
//   3.1.1.1 theta记号
//   对于一个给定函数g(n),用theta(g(n))来表述以下函数的集合：
//   theta(g(n)) = {f(n):存在正常量c1,c2和n0，使得对所有n >= n0,有0 <= c1g(n) <= f(n) <= c2g(n)}
//      解读：若存在正常数c1和c2，使得对于足够大的n，函数f(n)能夹入c1g(n)和c2g(n)之间，则f(n)属于集合o(g(n))。
//            因为theta(g(n))是一个集合，，所以f(n)是它的成员，可以记为f(n)属于theta(g(n))，替代记为f(n)=tehta(g(n))
//            类似于夹逼准则，对所以n>=n0,f(n)在常量因子内等于g(n),称g(n)是f(n)的一个渐进紧确界。
//            定义要求，每个成员f(n)均渐进非负（c>0 nn>0,f夹在两者之间必非负）
//   简单记忆：只保留最高次项。 准确定义：如上。
//   Prove:  c1nn <=   ann+bn+c    <= c2nn    // 必有a>0
//           c1   <=  a+b/n+c/nn   <= c2      // 对不同n，可确定不同c1、c2,反之亦可。
//           c1/a <=  1+b/an+c/ann <= c2/a    // 进一步，最高次项的系数也可以忽略。
//          一般性的，对任意d阶多项式p(n),有p(n)=o（n的d次方）
//   3.1.1.2 O记号
//   相对theta记号给出一个函数的上界和下界，当只有一个渐进上界时，使用O记号。
//   对于一个给定函数g(n),用O(g(n))来表述以下函数的集合：
//   O(g(n)) = {f(n):存在正常量c和n0，使得对所有n>=n0,有0 <= f(n)<= cg(n)}
//      解读：给出函数的上界，即对n0及其右边的所有n值，f(n) <= cg(n)
//            记f(n)=O(g(n)). 注意f(n)=o(g(n))中包含f(n)=O(g(n))。
//            当使用f(n)=O(g(n))时，仅仅要求g(n)的某个常数倍是f(n)的上界，但这个上界并不一定紧确。
//            使用O记号描述上界，可以仅通过算法的总体结构来描述算法运行时间,但由于输入变化，其最坏运行时间为O(nn)，但其他情况下不是。
//   3.1.1.3 Omiga记号
//   Omiga记号提供了函数下界。
//   对于一个给定函数g(n),用Omiga(g(n))来表述以下函数的集合：
//   Omiga(g(n)) = {f(n):存在正常量c和n0，使得对所有n>=n0，有0 <= cg(n) <= f(n)}
//      解读：给出函数的上界，即对n0及其右边的所有n值，cg(n) <= f(n)

// 3.1.2 定理3.1
//   对于任意两个函数f(n)和g(n),有f(n)=o(g(n))。当且仅当f(n)=O(g(n))且f(n)=Omiga(g(n)).
//   对于ann+bn+c=0(nn)，实际应通过定理3.1从渐进确界获取渐进上下界，用渐进上界和下界证明渐进确界。
//   算法的最佳情况运行时间为Omiga，最坏运行情况时间为O，所以算法运行时间就在两者确定的渐进确界之间，需要时间为o

// 3.1.3 等式和不等式中的渐进记号
//   渐进记号可以用于数学公式中。
//   当渐进记号独立于等式或不等式一侧时，已经明确等号所指的集合关系。但渐进记号出现于在某个公式中时，将其解释为匿名函数。
//      如：2nn+3n+1=2nn+theta(n) 意为 2nn+3n+1=2nn+f(n)  f(n)为theta(n)中的某个函数。称f(n)为匿名函数。
//          总之利用渐进记号，消除等式中无关杂项（多为低阶项）。
//          一个表达式中匿名函数的数目可以理解为等于渐进记号出现的次数。
//   当渐进记号出现在等式一侧时，如： 2nn+theta(n)=theta(nn)
//         无论怎样选择等号左边的匿名函数，总有一种办法来选择等号右边的匿名函数使等式成立。
//         等式右边是等式左边的进一步简化版。
//   3.1.3.1 o记号
//     O记号提供的渐进上界可能不是紧确的。如：2nn=O(nn)是紧确的 2n=O(n)却不是。
//     因此采用o记号来表示一个非渐进紧确的上界。 对于一个给定函数g(n),用o(g(n))来表述以下函数的集合：
//     o(g(n)) = {f(n):存在正常量c和n0，使得对所有n>=n0,有0 <= f(n)< cg(n)}
//     极限n趋于无穷，f(n)/g(n)=0,可以作为o记号的定义。
//   3.1.3.2 w记号
//     w记号于Omiga记号的关系类似o记号与O记号的关系。 用w记号表示一个非渐进紧确的下界。
//     对于一个给定函数g(n),用w(g(n))来表述以下函数的集合：
//     w(g(n)) = {f(n):存在正常量c和n0，使得对所有n>=n0，有0 <= cg(n) < f(n)}
//     极限n趋于无穷，f(n)/g(n)=无穷,可以作为o记号的定义。
//     也可以利用o记号定义： f(n) belong w(g(n))     only when     g(n) belong o(f(n))
//   3.1.3.3 应用
//     实数的许多关系性质也适用于渐进比较。 假定f(n)、g(n)渐进为正。
//     1 传递性
//       f(n)=theta(g(n))  and   g(n)=theta(h(n))    so   f(n)=theta(h(n))
//       f(n)=O(g(n))      and   g(n)=O(h(n))        so   f(n)=O(h(n))
//       f(n)=Omiga(g(n))  and   g(n)=Omiga(h(n))    so   f(n)=Omiga(h(n))
//       f(n)=o(g(n))      and   g(n)=o(h(n))        so   f(n)=o(h(n))
//       f(n)=w(g(n))      and   g(n)=w(h(n))        so   f(n)=w(h(n))
//     2 自反性
//       f(n) = theta(f(n))
//       f(n) = O(f(n))
//       f(n) = Omiga(f(n))
//     3 对称性
//       f(n) = theta(g(n))  only when  g(n) = theta(f(n))
//     4 转置对称性
//       f(n) = O(g(n))      only when  g(n) = Omiga(f(n))
//       f(n) = o(g(n))      only when  g(n) = w(f(n))
//     5 类比
//       O      a<=b  ;   o  a<b
//       Omiga  a>=b  ;   w  a>b
//       theta  a=b
//     6 三分性
//       对任意两个实数a，b，必存在三种关系中的某一种:a<b,a=b,a>b
//       但对于函数并不一定，即不是所有函数都可以渐进比较。


// test
// 3.1.1 
//   c1f(n) <= f(n) <= c2f(n)
//   c3g(n) <= g(n) <= c4g(n)
//   不妨设f(n) >= g(n)，则max(f(n),g(n))=f(n)
//   所以存在c5,c6，满足c5（f(n)+g(n)) <= f(n)=max(f(n),g(n)) <= c6(f(n)+g(n))
//   即证max(f(n),g(n))  =  theta(f(n)+g(n))

// 3.1.2
//   将（n+a）的b次方，多项式展开得，最高次项为n的b次方.
//   所以（n+a）的b次方 = theta(n的b次方)

// 3.1.3
//   O记号代表算法运行时间上限，与表述“运行时间至少”相矛盾。

// 3.1.4
//   2的(n+1)次方 = 2x2的n次方 = O(2的n次方) 成立 
//   2的2n次方    = 2的n次方 x 2的n次方 不等于 cx2的n次方  不成立

// 3.1.5 
//   因为 f(n) = theta(g(n))
//   所以 f(n)满足 c1g(n) <= f(n) <= c2g(n)
//   即同时满足  c1g(n) <= f(n)      ,   f(n) <= c2g(n)
//   即同时满足  f(n) = Omiga(g(n))  ,   f(n) = O(g(n))
//   所以 f(n) = theta(g(n)) 与 f(n) = Omiga(g(n))，f(n) = O(g(n))同时成立 两者等价。

// 3.1.6
//   类3.1.5证明。 Omiga(g(n))代表算法下界（最好情况运行时间），O(g(n))代表算法上界（最坏情况运行时间）

// 3.1.7
//   反证法  设存在f(n) = o(g(n))∩w(g(n))
//   则f(n)满足 f(n)<c1g(n)  且 f(n)>c2g(n)>=0
//   因为c1,c2是任意常数，令c1=c2，则 cg(n)<f(n)<cg(n)
//   不存在f(n)满足上不等式，矛盾，故o(g(n))∩w(g(n))为空集。

// 3.1.8
//   记号有两个参数的情况（n,m）
//   O(g(n,m)) = {f(n,m):存在正常量c、n0和m0,使得对所有n>=n0或m>=m0,有0 <= f(n,m) <= cg(n,m)}
//   Omiga(g(n,m)) = {f(n,m):存在正常量c、n0和m0,使得对所有n>=n0或m>=m0,有0 <= cg(n,m) <= f(n,m)}
//   theta(g(n,m)) = {f(n,m):存在正常量c1、c2、n0和m0,使得对所有n>=n0或m>=m0,有0 <= c1g(n,m) <= f(n,m) <= c2g(n,m)}


// 3.2 标准记号与常用函数
// 3.2.1 单调性
//   m<=n f(m)<=f(n),则函数f(x)单调递增     ; m<=n f(m)>=f(n)，则函数f(x)单调递减。
//   m<n  f(m)<f(n) ,则函数f(x)严格单调递增 ; m<n  f(m)>f(n)，则函数f(x)严格单调递减。

// 3.2.2 向下取整与向上取整
//   [x]表示小于或等于x的最大整数（读作x的向下取整）； [X]表示大于或等于x的最大整数（读作x的向上取整）
//   对所有实数x： x-1 < [x] <= x <= [X] < x+1
//   对任意整数n： [n/2] + [N/2] = n
//   对任意实数x>=0和整数a,b>0: [[X/A]/B] = [X/AB]
//                              [[x/a]/b] = [x/ab]
//                              [A/B]     <= (a+(b-1))/b
//                              [a/b]     >= (a-(b-a))/b
//   向下取整和向上取整函数都是单调递增的。

// 3.2.3 模运算
//   对任意整数a和任意正整数n，a mod n的值就是商a/n的余数：
//                             a mod n = a - n[a/n]
//                             0 <= a mod n < n
//   a mod n = b mod n时，记a=b(mod n) 称模n时，a等价于b。（即a模n与b模n有相同的余数）

// 3.2.4 多项式
//   给定一个非负整数d，n的d次多项式为p(n) = 求和(i=0到d)ai(n的i次方)
//   其中ai为多项式系数且ad不等于0
//   一个多项式为渐进正的 当且仅当ad>0，有p(n)=theta(n的d次方)。
//   对任意实常量a>=0,函数n的a次方单调递增；对任意实常量a<=0,函数n的a次方单调递减。
//   若对某常量k，有f(n)=O(n的k次方),则称函数f(n)是多项式有界的。

// 3.2.5 指数
//   n的b次方 = o(a的n次方)  (a>0)
//   对任意实数x:  e的x次方 >= 1+x  (x=0时取等号)
//   当|x|<=1时 :  1+x <= e的x次方 <= 1+x+xx  
//   当x趋于0时 :  e的x次方 = 1+x+theta(xx)

// 3.2.6 对数
//   对x>-1 : x/(1+x) <= ln(1+x) <= x  (x=0时取等号)
//   对任意常量a>0 : (lgn)的b次方 = o(n的a次方)

// 3.2.7 阶乘
//   n! = 1        n=0
//      = n(n-1)!  n>0
//   n! = 1x2x3x......xn
//   阶乘函数的一个弱上界是n! <= n的n次方。 因为阶乘中每一项小于等于n
//       斯特林近似公式： n! = 根号下(2pien) x (n/e)的n次方 x (1+theta(1/n))  给出一个更紧确的上界和下界。
//   对所有n>=1  n! = 根号下(2pien) x (n/e)的n次方 x e的an次方 。  其中 1/(12n+1) < an < 1(12n)

// 3.2.8 多重函数
//   f(i)(n)表示函数f(n)重复i次作用于一个初值n上
//   f(i)(n) = n            i=0
//           = f(f(i-1)(n)) i>0

// 3.2.9 多重对数函数
//   lg*n = min{i>=0: lg(i)n<=1}

// 3.2.10 斐波那契数
//   F0 = 0
//   F1 = 1
//   Fi = Fi-1 + Fi-2  i>=2
//   斐波那契数与黄金分割率及其共轭数有关，是方程xx=x+1的两个根
//   Fi = (黄金分割率i - 其共轭数i)/根号5 = [黄金分割率i/根号5 + 1/2]


// test
// 3.2.1 证明单调性
//   设a,b是定义域上任意两点，且a<b
//   因为f(n),g(n)单调递增，所以f(a)<=f(b),g(a)<=g(b)
//   所以f(a)+g(a)<=f(b)+g(b),即函数f(n)+g(n)单调递增
//   所以f(g(a))<=f(g(b)),即函数f(g(n))单调递增
//   若f(n),g(n)>=0,则0<=f(a)g(a)<=f(b)g(b),则函数f(n)g(n)单调递增。

// 3.2.2 证明a的logb(c) = c的logb(a)
//   等式两端同取logc：logb(c)logc(a)     logb(a)logc(c)
//                     logb(a)       =    logb(a) 等式成立，即证

// 3.2.3 证明lg(n!) = theta(nlgn)
//   lg(n!)=lg1 + lg2 + ... +lgn <= lgn + lgn + ... +lgn = nlgn
//   所以lg(n!) = theta(nlgn)
//   n! = 1x2x...xn < nxnx...xn = n的n次方,所以n!= o(n的n次方)
//   n! = 1x2x3x4...xn > 2x2x2x...x2 =2的n次方，所以n! = w(2的n次方)

// 3.2.4 证明[lgN]!无界，[lg(lgN)]!有界
//   首先，f(n)多项式有界的充分必要条件是 lgf(n) = O(lgn) （存在常数c和n0，当n>=n0时，f(n)<c*n的k次方）
//   1 设f(n)=(lgn)!   存在常数c和n0，当n>=n0时，lg(f(n)) >= c(lgn)lg(lgn)
//     由于lg(lgn)是单调递增函数，总可以在n >= n0的范围内找到n >= n1，使得clg(lgn) >= 1
//     则此时lg(f(n)) >= lgn，并不能满足lgf(n) = O(lgn).  所以(lgn)!并不是多项式有界函数。
//   2 设f(n)=(lglgn)! 由公式3.2.3，lg(n!)=theta(nlgn)，得lg(f(n))=lg((lglgn)!) = theta(lg(lgn(lglglgn)))
//     因为对于任意的n > 1，lglglgn < lglgn，则存在常数c和n0，使得n >= n0时，lg(f(n)) <= c(lglgn)²
//     又因为任意多项式函数都比任意多对数函数增长快，所以c(lglgn)² = O(lgn), 所以lg(f(n)) = O(lgn),则f(n) = (lglgn)!多项式有界。

// 3.2.5 
//   lg*(lgn)=lg*n+1   lg(lg*n)为lg*n的对数函数，因而lg*(lgn)渐进更大些

// 3.2.6
//   黄金分割率及其共轭数带入方程xx=x+1即证

// 3.2.8
//    证明klnk = theta(n) 蕴含着k=theta(n/ln(n)).
//    当klnk = theta(n)时，则存在正常量c1, c2和n0,使得对所有n ≥ n0,有0 ≤ c1∗n ≤ nln(n) ≤ c2∗n 
//    此时n>=1,有0<=c1*n/(lnn) <= n <= c2*n/(lnn)，即证

// 3.1 
//   https://blog.csdn.net/victoryaoyu/article/details/76237944

// 3.2 相对渐进增长 （k>=1 e>0 c>1且均为常量）
//   (lgn)的k次方 <=   n的e次方
//   n的k次方     <=   c的n次方
//   根号n        no   n的sinn次方
//   2的n次方     >=   2的(n/2)次方
//   n的lgc次方   =    c的lgn次方
//   lg(n!)       =    lg(n的n次方)

// 3.3 根据渐进增长率排序 (g1=Omiga(g2)=Omiga(g3)=...=Omiga(g30))
//   2的(2的(n+1)次方)次方
//   2的(2的n次方)次方
//   (n+1)!
//   n!
//   e的n次方
//   n(2的n次方)
//   2的n次方
//   (3/2)的n次方
//   n的(lglgn)次方 = (lgn)的lgn次方
//   (lgn)!
//   n的3次方
//   n的平方 = 14的(lgn)次方
//   nlgn 近似于 lg(n!)
//   n = 2的lgn次方
//   (根号2)的lgn次方
//   2的根号2lgn次方
//   (lgn)的平方
//   lnn
//   根号lgn
//   lnlnn
//   2的(lg*n)次方
//   lg*n 近似于 lg*(lgn)
//   lg(lg*n)
//   1 = n的(1/lgn)
//   不是上述函数上界或下界的函数 (2的(2的(2的(n+1)次方))次方)的sinx次方

// 3.4 渐进记号的性质
// f(n) = O(g(n)) 不等价于 g(n) = O(f(n))   如 n=O(nn)
// f(n)+g(n) 不等于 theta(min{f(n),g(n)})   如 n+nn 不等于 theta(min{n,nn})
// f(n) = O(g(n)) 等价于 lg(f(n)) = O(lg(g(n)),其中对所有足够大的n，有lg(g(n))>=1且f(n)>=1
// f(n) = O(g(n)) 不等价于 2的f(n)次方=O(2的g(n)次方)  如 2n=O(n),4的n次方不等于O(2的n次方)
// f(n)>=1时，f(n) = O((f(n))的平方) ；f(n)<1时，不成立。
// f(n) = O(g(n)) 等价于 g(n) = Omiga(f(n))
// f(n) 不等于 theta(f(n/2))   如 n! 不等于 theta((n/2)!)
// f(n)+o(f(n)) = theta(f(n))

// 3.5 Omiga无穷：若存在正常量c，使得对无穷多个整数n，有f(n)>=cg(n)>=0，则称f(n)=Omiga无穷(g(n))
//   1 对渐进非负的任意两个函数f(n)和g(n),或者f(n)=O(g(n))或者f(n)=Omiga无穷(g(n))或者两者均成立。但Omiga替代Omiga无穷时，命题为假。
//     若f(n) 不等于 O(g(n)) ,则必有无穷多个正整数n，使f(n)>=cg(n)>=0,即f(n)=Omiga无穷成立。
//     若f(n) = theta(g(n)),则两者同时成立。
//     若用Omiga替代Omiga无穷则不一定成立，如n=Omiga无穷(n的sinn次方),但n不等于Omiga(n的sinn次方)
//   2 Omiga无穷替代Omiga
//     优点：Omiga无穷对下界要求更宽松，可以兼容更多情况。
//     缺点：Omiga无穷不是严格的渐进下界，实际意义不大。
//   3 O'：f(n)=O'(g(n)) only when  |f(n)|=O(g(n))
//     用O'替代O仍使用Omiga，对定理3.1没有影响。
//     因为f(n)=O(g(n))成立代表f(n)渐进非负，所有|f(n)|=f(n)。
//   4 定义软O记号，意指忽略对数因子的O：
//     软O(g(n)) = {f(n):存在正常量c,k,n0,使得对所有n>=n0,有0<=f(n)<=cg(n)(lg(n))的k次方}
//     类似定义软Omiga和软theta
//     软Omiga(g(n)) = {f(n):存在正常量c,k,n0,使得对所有n>=n0，有0<=cg(n)(lg(n))的k次方<=f(n)}
//     软theta(g(n)) = {f(n):存在正常量c1,c2,k1,k2,n0,使得对所有n>=n0,有0<=c1g(n)(lg(n))的k1次方<=f(n)<=c2g(n)(lg(n))的k2次方}

// 3.6 多重函数：将用于函数lg*的多重操作符*应用于实数集上的任意单调递增函数f(n).
//   对给定常量c属于R，定义多重函数fc*(n) = min{i>=0,f(i)(n)<=c}
//   该函数不必在所有情况下都良定义。值fc*(n)是为缩小其参数到c或更小所需函数f重复应用的次数。
//   对于每个函数f(n)和常数c，给出fc*(n)的一个尽量紧确的界。
//   f(n)          c          fc*(n)
//   n-1           0          theta(n)
//   lgn           1          theta(lg*n)
//   n/2           1          theta(lgn)
//   n/2           2          theta(lgn)
//   根号n         2          theta(lglgn)
//   根号n         1          无法收敛
//   n的1/3次方    2          theta(log3(lgn))
//   n/lgn         2          w(lglgn),o(lgn)



// 分治策略
// 分解、解决、合并。 子问题足够大时，递归求解，称之为递归情况；子问题足够小时，递归触底，进入基本情况。
// 有时除了与原问题完全一样的子问题外，还有不完全一样的将其归入合并步骤。
//   递归式
//     一个等式或不等式，通过更小的输入来描述一个函数。 子问题的规模不一定是原问题规模的一个固定比例。
//     求解递归式的方法：代入法、递归树法、主方法。
//   递归式技术细节
//     实际应用中会忽略递归式声明和求解一些技术细节。 如：向下取整或向上取整、边界条件。

// 4.1 最大子数组问题
//   以股票为例，利益最大化即最低价买入最高价卖出。
//   若最高价出现在最低价之前，则无法实现理想的利益最大化，因而实际的利益最大化是买入（不一定是最低价）和卖出（不一定是最高价）的差价最高。
//  4.1.1 暴力求解法
//    对可能的买进和卖出日期全部组合一边，从中遍历出最大值。 运行时间为Omiga(nn)
//  4.1.2 问题变换
//    不再从每日价格的角度看待数据，而是考虑每日价格变化。
//    第i天价格变化定义为：第i天和第i-1天的价格差。 将价格变化看做一个数组A，则问题转化成找A的和最大的非空连续子数组（最大子数组）。
//    最大子数组可能不止一个
//    目前该方法仍需检查（n-1，2）=theta(nn)个子数组，和暴力求解法近似.
//  4.1.3 分治策略
//    设寻找子数组A[low...high]的最大子数组。
//    将数组尽可能分成两个规模相等的子数组，分别找其内部的最大子数组。
//    最大子数组A[low...high]的任何连续子数组A[i...j]必然位于以下三种情况之一：
//      1 完全位于子数组A[low...high]中。
//      2 完全位于子数组A[mid+1...high]中。
//      3 跨越mid。
//      对于情况3，将数组分为左右两个数组，分别找出左右的最大子数组，再将它们合并即为所求。
//      Find_Max_Crossing_Subarray(A,low,mid,high)
//    1 left-sum = - 无穷
//    2 sum = 0
//    3 for i=mid downto low     // 从中点往左找最大子数组
//    4     sum = sum + A[i]     // 求子数组的和
//    5     if sum >left-sum     // 如果求和大于之前的最大值
//    6        left-sum = sum    // 赋值，即为当前左数组的最大子数组
//    7        max-left = i      // 记录左边界
//    8 right-sum = -无穷        // 原理同求左数列
//    9 sum = 0
//   10 for i=mid+1 to high
//   11     sum = sum + A[i]
//   12     if sum>right-sum
//   13        right-sum = sum
//   14        max-right = i
//   15 retrun (max-left,max-right,left-sum+right-sum)
//   上述过程花费theta(n)的时间
//   下面用分治法求解最大子数组问题
//   Find_Maximum_Subarray(A,low,high)
//  1  if high == low
//  2     return (low,high,A[low])  // 数组只有一个元素
//  3  else mid = [(low+high)/2]    // 中点位置向下取整
//  4       (left-low,left-high,left-sum) = Find_Maximum_Subarray(A,low,mid)               // 情况1，求左数组中的最大子数组
//  5       (right-low,right-high,right-sum) = Find_Maximum_Subarray(A,mid+1,high)         // 情况2，求右数组中的最大子数组
//  6       (cross-low,cross-high,cross-sum) = Find_Max_Crossing_Subarray(A,low,mid,high)  // 情况3，求跨mid最大子数组
//  7  if left-sum >= right-sum and left-sum >= cross-sum         // 如果左数组的最大子数组最大，则它为整个数组的最大子数组
//  8     return (left-low,left-high,left-sum)
//  9  elseif right-sum >= letf-sum and right-sum >= cross-sum    // 如果右数组的最大子数组最大，则它为整个数组的最大子数组
// 10      return (right-low,right-high,right-sum)
// 11   else return (cross-low,cross-high,cross-sum)               // 如果cross数组的最大子数组最大，则它为整个数组的最大子数组
//  4.1.4 分治算法分析
//    1、2行花费常量时间。 T(1) = theta(1)
//    3花费常量时间。
//    4、5解决两个规模为n/2的子问题，每个子问题花费T(n/2)
//    6调用Find_Max_Crossing_Subarray,花费theta(n)
//    7-11花费theta(1)时间
//    总体花费T(n) = theta(1) + 2T(n/2) + theta(n) +theta(1) = 2T(n/2) + theta(n)
//    递归式： T(n) = theta(1)            n=1
//                  = 2T(n/2) + theta(n)  n>1
//    利用主方法，求解时间为T(n) = theta(nlgn)   (或者可以用递归树理解)


// test 
// 1 当A的所有元素为负数时，Find_Maximum_Subarray返回什么？
//   返回数组最大元素

// 2 对最大子数组，编写暴力求解方法的伪代码，运行时间为theta(nn)
//   Sum(A,low,high)
//     sum = 0
//     for i=low to high
//         sum += A[i]
//     return sum
// 
//   Find_Max_Subarray(A,n)
//     max_sum = -无穷
//     max_left = 0
//     max_right = 0
//     for i=1 to n
//       for j=i to n
//         temp_sum = sum(A,i,j)
//         if temp_sum > max_sum
//            max_sum = temp_sum
//            max_left = i
//            max_right = j
//     return (max_left,max_right,max_sum)

// 3 暴力算法和递归算法的性能交叉点
//   theta(nn) = theta(nlgn) 解出n0
//   在0-n0使用暴力算法，在n0到正无穷使用递归算法

// 4 修改最大子数组定义，允许空子数组为结果，其和为0.
//   if low = high and a[high]<0
//      return (-1,-1,0)

// 5 最大子数组的非递归、线性时间算法。
//   若A[1...j]为最大子数组，求A[1...j+1]的最大子数组。
//    A[1...j+1]的最大子数组要么是A[1...j]的最大子数组，要么是A[i...j+1].
//   Find_Max_Subarray(A,n)
//    low = 1
//    high = 1
//    sum = A[1]
//    for j=2 to n
//        temp_sum = 0
//        sum1 = A[j]
//        low1 = j
//        high1 = j
//        for i=j downto 1
//            temp_sum += A[i]
//            if temp_sum > sum1
//               sum1 = temp_sum
//               low1 = i
//        if sum1 > sum
//           sum = suum1
//           low = low1
//           high = high1
//     return(low,high,sum)


// 4.2 矩阵乘法的Strassen算法
//   需要计算nn个矩阵元素，每个元素是n个值的和。 给出伪代码如下：
//   Square_Matrix_Multiply(A,B)
//     n = A.rows
//     let C be a new nxn matrix
//     for i=1 to n
//         for j=1 to n
//             cij = 0
//             for k=1 to n
//                 cij = cij + aik x bik
//     return C
//   花费theta(nnn)时间
//   但使用Strassen的nxn矩阵相乘的递归算法，其运行时间为theta(n的lg7次方)

// 4.2.1 一个简单的分治算法
//   将n x n矩阵划分成4个n/2 x n/2的子矩阵构成的矩阵
//   对应C11 = A11 x B11 + A12 x B21，即每个公式对应两对n/2 x n/2矩阵乘法的加法。
//   直接的递归分治算法伪代码如下：
//   Square_Matrix_Multiply_Recursive(A,B)
//     n = A.rows
//     let C be a new nxn matrix
//     if n==1
//        c11 = a11 x b11
//     else partition A,B and C(利用下标)
//        c11 = Square_Matrix_Multiply_Recursive(A11,B11) + Square_Matrix_Multiply_Recursive(A12,B21)
//        c12 = Square_Matrix_Multiply_Recursive(A11,B12) + Square_Matrix_Multiply_Recursive(A12,B22)
//        c21 = Square_Matrix_Multiply_Recursive(A21,B11) + Square_Matrix_Multiply_Recursive(A22,B21)
//        c22 = Square_Matrix_Multiply_Recursive(A21,B12) + Square_Matrix_Multiply_Recursive(A22,B22)
//     return C
//  递归式 T(n) = theta(1)                        n=1
//              = theta(1) + 8T(n/2) + theta(nn)  n>1

// 4.2.2 strassen方法
//   在分治算法的基础上，只递归七次而不是8次。
//   步骤：
//     1 将A、B、C分解为n/2 x n/2子矩阵，theta(1)
//     2 创建10个n/2 x n/2的矩阵，每个矩阵保存1中两个子矩阵的和或差,theta(nn)
//     3 用1、2创建的矩阵，递归计算七个矩阵的积。
//     4 通过3计算的矩阵不同组合加减运算，计算出C的子矩阵，theta(nn)
//   步骤2中：S1=B12 - B22  S2=A11 + A12  S3=A21 + A22  S4=B21 - B11  S5=A11 + A22
//            S6=B11 + B22  S7=A12 - A22  S8=B21 + B22  S9=A11 - A21  S10=B11 + B12
//   步骤3中：P1=A11 x S1   P2=S2 x B22  P3=S3 x B11  P4=A22 x S4  P5=S5 x S6  P6=S7 x S8  P7=S9 x S10
//   步骤4中：C11 = P5 + P4 - P2 + P6 = A11 x B11 + A12 x B21
//            C12 = P1 + P2 = A11 x B12 + A12 x B22
//            C21 = P3 + P4 = A21 x B11 + A22 x B21
//            C22 = P5 + P1 - P3 - P7 = A22 x B22 + A21 x B12
//   递归式：T(n) = theta(1)             n=1
//                = 7T(n/2) + theta(nn)  n>1
//   递归式解为：T(n) = theta(n的lg7次方)


// test
// 1 使用Strassen算法计算矩阵乘法
//   S1=8-2=6 S2=1+3=4 S3=7+5=12 S4=4-6=-2 S5=1+5=6
//   S6=6+2=8 S7=3-5=-2 S8=4+2=6 S9=1-7=-6 S10=6+8=14
//   P1=6 P2=8 P3=72 P4=-10 P5=48 P6=-12 P7=-84
//   C11=26 C12=14 C21=62 C22=66

// 2 Strassen算法伪代码
//   Strassen(A,B)
//    let C be a new nxn matrix
//    if A.row == 1
//       C = A * B
//    else partition A,B,C
//       S1=B12 - B22  
//       S2=A11 + A12  
//       S3=A21 + A22 
//       S4=B21 - B11
//       S5=A11 + A22
//       S6=B11 + B22  
//       S7=A12 - A22
//       S8=B21 + B22  
//       S9=A11 - A21  
//       S10=B11 + B12
//       P1=A11 x S1   
//       P2=S2 x B22  
//       P3=S3 x B11
//       P4=A22 x S4
//       P5=S5 x S6
//       P6=S7 x S8
//       P7=S9 x S10
//       C11 = P5 + P4 - P2 + P6
//       C12 = P1 + P2
//       C21 = P3 + P4
//       C22 = P5 + P1 - P3 - P7
//    return C

// 3 修改strassen算法，使之适应矩阵规模不是2的幂的情况。
//   将矩阵扩展成2的[lgN] x 2的[lgN]矩阵，缺少的地方补0.

// 4 用k次乘法操作完成两个3x3矩阵相乘，可以在theta(n的lg7)时间内完成nxn矩阵相乘，满足条件k最大为多少，运行时间如何？
//   先将3x3矩阵补成4x4矩阵，k=4的lg7次方<=49

// 5 V.Pan算法，132464次乘法完成68x68矩阵乘法，143640次乘法完成70x70矩阵乘法，155424次乘法完成72x72矩阵乘法。
//   72x72矩阵会得到最佳渐进运行时间，其性能优于strassen算法。

// 6 strassen算法作为子进程处理kn x n矩阵乘n x kn矩阵，最快耗时？前后互换呢？
//   将A、B矩阵拆分为k个nxn矩阵，AxB=knxkn的矩阵，内部每个子矩阵相乘用strassen算法，theta(kkn的lg7次方)
//   反之，AxB=nxn的矩阵，theta(kn2的lg7次方)

// 7 三次实数乘法完成两个复数的相乘，接受abcd作为输入，输出实部和虚部。
//   A = (a + b)*c
//   B = (c + d)*b
//   C = (b - a)*d
//   (a + bi)*(c + di) = (A - B) + (B - C)i


// 4.3 用代入法求递归式
//   1 猜测解的形式
//   2 用数学归纳法求出解中的常数，并证明解的正确性                 
//   举例： 递归式T(n) = 2T([n/2]) + n,猜测其解为T(n)=O(nlgn)
//   证明：选择常数c>0，有T(n) <= cnlgn.
//         假设上界对所有m<n成立，对于m=[n/2],有T([n/2]) <= c[n/2]lg([n/2]).
//         so T(n) <= 2(c[n/2]lg([n/2])) + n <= cnlg(n/2) + n
//                  = cnlgn - cnlg2 + n
//                  = cnlgn - cn + n
//                 <= cnlgn (when c>=1)

// 4.3.1 做出好的猜测
//   1 靠经验、创造力和递归树。
//   2 先估计一个宽松的上下界，再逐步逼近渐进紧确界

// 4.3.2 微妙的细节
//   有时猜出了递归式的渐进界，但证明失败。问题在于归纳假设不够，应修改猜测，减去一个低阶项可能起效。
//   例：T(n) <= T([n/2]) + T([N/2]) + 1
//       猜测T(n) = O(n) T(n) <= cn,证明失败
//       再猜测T(n) <= cn - d
//             T(n) <= c[n/2]-d + c[N/2]-d + 1 <= cn- 2d + 1 <= cn - d  (when d>=1) 证明成立

// 4.3.3 避免陷阱
//   使用渐进符号容易出错，要证出与归纳假设严格一致的格式。
//   如：T(n) <= 2(c[n/2]) + n <= cn + n 不能证明T(n) <= cn 即T(n) = O(n)

//  4.3.4 改变变量
//    用代数运算将一个未知的递归式变成熟悉的形式。
//    如：T(n) = 2T([根号n]) + lgn
//        令 m = lgn 得到T(2的m次方) = 2T([2的m/2次方]) + m
//       变量代换后,S(m) = 2S(m/2) + m 有 S(m)=O(mlgm)
//       so T(n) = T(2的m次方) = S(m) = O(mlgm) = O(lgn lglgn)


// test
// 1 证明T(n) = T(n-1) + n的解为O(nn)
//   即证T(n) <= cnn - d
//   T(n) = T(n-1) + n
//       <= c(n-1)(n-1)+ n
//        = cnn - (2c-1)n + c  ( -(2c-1)n + c < 0)
//       <= cnn (when c>=n/(2n+1) 取c=1)

// 2 证明T(n) = T([N/2]) + 1的解为O(lgn)
//   即证T(n) <= clgn
//   T(n) = T([N/2]) + 1
//       <= clg([N/2]) + 1  (when n>=2,1<=[N/2]<=2n/3 )
//        = clgn + clg(2/3) + 1 (令 -clg(2/3) + 1 <0)
//       <= clgn (when c>1/lg(2/3))

// 3 证明T(n) = 2T([n/2]) + n的解为theta(nlgn)
//   即证c1[n]lg[n] <= T([n]) <= c2[n]lg[n]
//   对左不等式：
//   T(n) >= 2c[n/2]lg[n/2] + n
//        >= 2c(n/3)lg(n/3) + n
//         = (2/3)cnlgn - (2/3)cnlg3 + n (任意0<c<3/(2lg3))
//        >= (2/3)cnlgn

// 4 做出不同假设来克服T(n) = 2T([n/2]) + n的边界条件T(1) = 1
//   假设T(n) <= cnlgn + d (d>0)

// 5 证明归并排序的严格递推式的解为theta(nlgn)
//   任意m<n，存在c1、c2满足：c2mlgm <= T(m) <= c1mlgm
//   右不等式：T(n) <= 2c1[N/2]lg[N/2] + theta(n)
//                  <= 2(2/3)c1nlg(2n/3) + theta(n)
//                   = (4/3)c1nlgn + (4/3)c1nlg(2/3) + theta(n)
//                   = (4/3)c1nlgn
//    左不等式:T(n) >= 2c2[N/2]lg[N/2] + theta(n)
//                  >= 2(1/3)c2nlgn +theta(n)
//                   = (2/3)c2nlgn - c2(2/3)nlg3 + theta(n)
//                   = (2/3)c2nlgn

// 6 证明T(n) = 2T([n/2]+17) + n的解为O(nlgn)
//   即证T(n) <= cnlgn
//   T(n) = 2T([n/2]+17) + n
//       <= 2c([n/2]+17)lg([n/2]+17) + n (when n>=102,n/2+17>=2/3n)
//       <= (4/3)cnlgn + (4/3)cnlg(2/3) + n
//       <= (4/3)cnlgn (when c>=10)

// 7 使用主方法可以证明T(n) = 4T(n/3) + n的解为theta(n的log3(4)次方)
//   说明如何通过减去一个低阶项完成代入法证明。
//   不减低阶项时T(n) <= 4c((n/3)的log3(4)次方) + n，结构不严格一致，证明失败。
//   假设T(n) <= c(n的log3(4)次方) - dn
//   T(n) = 4T(n/3) + n
//       <= 4c((n/3)的log3(4)次方) - d(n/3) + n
//        = 4c(n的log3(4)次方) - (4/3)dn + n
//        = 4c(n的log3(4)次方) - (4d/3 - 1)n
//       <= 4c(n的log3(4)次方) - dn (when d>3)

// 8 使用主方法可以证明T(n) = 4T(n/2) + n的解为theta(nn)
//   说明如何通过减去一个低阶项完成代入法证明。
//   不减低阶项时T(n) <= cnn + n,结构不严格一致，证明失败。
//   假设T(n) <= cnn - dn
//   T(n) <= cnn  - dn + n
//         = cnn + (1-d)n (令1-d<0)
//        <= cnn (when d>1)

// 9 利用改变变量方法求解递归式T(n) = 3T(根号n) + lgn
//   令m = lgn,则n = 2的m次方，代入原式：T(2的m次方) = 3T(2的(m/2)次方) + m
//   令S(m) = T(2的m次方),则S(m) = 3S(m/2) + m
//   假设S(m) = theta(mlgm),c2mlgm <= S(m) <= c1mlgm
//   递归得c2(m/2)lg(m/2) <= S(m/2) <= c1(m/2)lg(m/2)
//   (3/2)c2mlgm - (3/2)c2mlg2 + n <= (3/2)c2mlg(m/2) + m <= S(m) <= (3/2)c1mlg(m/2) + m <= (3/2)c1mlgm - (3/2)c1mlg2 + m
//   when c1 >= 2/(3lg2) , c2 <= 2/(3lg2)
//     (3/2)c2mlgm <= S(m) <= (3/2)c1mlgm
//   so S(m) = theta(mlgm)
//   T(n) = T(2的m次方) = theta(lgn(lglgn))


// 4.4 用递归树求解递归式
//   画出递归树是设计好的猜测的一种简单而直接的方法。
//   一个结点表示一个单一子问题的代价，子问题对应某次递归函数的调用。
//   将树中每层代价求和，所有层代价总和即为总代价。
//   递归树最适合用来生成好的猜测，再用代入法验证猜测。
//   在建立递归树时，往往要忽略部分细节，来得到一个上界。


// test
// 1 对T(n) = 3T([n/2])+n,利用递归树确定一个好的渐近上界，用代入法验证。
//   假设n是2的幂
//   T(n) = n + (3/2)n + ((3/2)的平方)n + ... + ((3/2)的(lgn - 1)次方)n + theta(n的lg3次方)
//        = 求和(0到lgn - 1)(3/2)的i次方n + theta(n的lg3次方)
//        = 2(3的lgn次方) - 2n + theta(n的lg3次方)
//        = O(n的lg3次方)
//   证明T(n) <= cn的lg3次方 + n
//   T(n) = 3T(n/2) + 2n
//       <= 3c(n/2)的lg3次方 + 2n
//       <= cn的lg3次方 + 2n

// 2 对T(n) = T(n/2) + nn,利用递归树确定一个好的渐近上界，用代入法验证。
//   T(n) = nn + (1/4)nn + ((1/4)的平方)nn + ... + ((1/4)的(lgn - 1)次方)nn + T(1)
//        = 求和(0到lgn -1)((1/4)的i次方)nn + T(1)
//        < nn求和(0到无穷)((1/4)的i次方) + T(1)
//        = (4/3)nn + T(1)
//        = O(nn)
//   证明T(n) <= cnn
//   T(n) = T(n/2) + nn
//       <= (c/4)nn + nn
//        = (c/4 + 1)nn
//       <= cnn (when c > 4/3)

// 3 对T(n) = 4T(n/2+2) + n,利用递归树确定一个好的渐近上界，用代入法验证。
//   T(n) = n + (4(1/2)n+8) + (16(1/4)n+48) +...+ ((4的lgn - 1次方)((1/2)的lgn - 1次方))n + (4的lgn - 1次方)((1/2)的lgn - 3次方+...+2) + theta(nn)
//        = n求和(0到lgn - 1)(2的i次方) + 求和(1到lgn - 1)(4的(i+1)次方 - 2的(i+2)次方) + theta(nn)
//        = nn - n + (1/3)(4nn - 8) + 4n - 8 +theta(nn)
//        = theta(nn)
//   证明T(n) <= cnn + 2n
//   T(n) = 4T(n/2+2) + n
//        < 4c(n/2)(n/2) + 2(n/2) + n
//        = cnn + 2n

// 4 对T(n) = 2T(n-1) + 1,利用递归树确定一个好的渐近上界，用代入法验证。
//   T(n) = 1 + 2 + 4 + ... + 2的n-2次方 + theta(2的n-1次方) = theta(2的n次方)
//   证明T(n) <= c(2的n次方) + n
//   T(n) = 2T(n-1) + 1
//       <= 2c(2的n-1次方) + (n-1) + 1
//       <= c(2的n次方) + n

// 5 对T(n) = T(n-1) + T(n/2) + n,利用递归树确定一个好的渐近上界，用代入法验证。
//   不是完全二叉树，从lgn到n-1为非完全层。推测T(n) = O(2的n次方)
//   证明T(n) <= c(2的n次方) - 4n
//   T(n) = T(n-1) + T(n/2) + n
//       <= c(2的(n-1)次方 + 2的(n/2)次方) - 4(n-1) - 4n/2 + n
//       <= c(2的(n-1)次方 + 2的(n/2)次方) - 5n + 1  (when n > 1/4)
//       <= c(2的(n-1)次方 + 2的(n/2)次方) - 4n      (when n > 2)
//       <= c(2的m次方) - 4n

// 6 对T(n) = T(n/3) + T(2n/3) + cn,利用递归树论证解为Omiga(nlgn),其中c为常数。
//   递归树知道log3(n)后才开始不完全，每层代价都为cn
//   T(n) >= Omiga(nlog3(n)) = Omiga(nlgn)

// 7 对T(n) = 4T([n/2]) + cn,利用递归树解一个渐进紧确界，用代入法验证。
//   T(n) = cn + 2cn + 4cn +...+ (4的lgn - 1次方)(cn)/(2的lgn - 1次方) + theta(nn)
//        = cn求和(0到lgn - 1)(2的i次方) + theta(nn)
//        = cn(2的lgn次方 - 1) + theta(nn)
//        = theta(nn)
//   证明T(n) <= cnn + 2cn
//   T(n) = 4T([n/2]) + cn
//       <= 4c(n/2)(n/2) + 2cn/2 + cn
//        = cnn + 2cn
//   T(n) = 4T([n/2]) + cn
//       >= 4c(n/2)(n/2) + 2cn/2 + cn
//        = cnn + 2cn
//    so T(n) = theta(nn)

// 8 对T(n) = T(n-a) + T(a) + cn,利用递归树解一个渐进紧确解，用代入法验证。
//   T(n) = cn + cn + c(n-a) + c(n-2a) +...+ c(n-(n/a - 1)a + a) + theta(1)
//        = cnn/a + c(n/a -1)a - ca求和(1 to (n-a)/a-1)i + theta(1)
//        = tehta(nn)
//   证明T(n) <= cnn
//   T(n) = T(n-a) + T(a) + cn
//       <= c(n-a)(n-a) + caa + cn
//       <= cnn - cn(2a-1) + caa + ca (when a>=1,n>(aa+a)/(2a-1))
//       <= cnn
//   证明T(n) >= cnn
//   T(n) = T(n-a) + T(a) + cn
//       >= c(n-a)(n-a) + caa + cn
//        = cnn - 2an + 2caa + cn
//        = cnn + (c-2a)n + 2caa
//       >= cnn (when c>=2a,a>=0)
//   so T(n) = theta(nn)

// 9 对T(n) = T(an) + T((1-a)n) + cn,利用递归树解一个渐进紧确解.
//   T(n) <= cnlg(1/(1-a))n <= cnlgn (1-a <= 1/2)
//   T(n) = Omiga(nlgn)
//   证明T(n) <= dnlgn
//   T(n) = T(an) + T((1-a)n) + cn
//       <= danlg(an) + c(1-a)nlg((1-a)n) + cn
//        = danlgn + d(1-a)nlgn + danlga + d(1-a)nlg(1-a) + cn
//       <= dnlgn + (d(alga + (1-a)lg(1-a))+c)n
//       <= dnlgn (when d >= -c/(alga + (1-a)lg(1-a))
//   so T(n) = theta(nlgn)


// 4.5 用主方法求解递归式
//   为形式如T(n) = aT(n/b) + f(n) 的递归式，提供了一种“菜谱”式求解方法
//     其中，a>=1 b>=1，f(n) 是渐近正函数。
//   牢记三种情况，可以很容易求解很多递归式.
//   T(n) = aT(n/b) + f(n) 描述这样一种算法：
//        将规模为n的问题分解为a个子问题，每个子问题规模为n/b。
//        递归解决a个子问题，每个花费时间T(n/b).
//        f(n)包含了问题分解和合并的代价。
//   从技术正确性来看，该方法不是良定义，因为n/b可能不是整数，但可以用[]替换且不影响递归式渐近性质。

// 4.5.1 主定理
//   定理4.1（主定理） 令a>=1,b>1是常数，f(n)是一个函数，T(n)是定义在非负整数上的递归式： T(n) = aT(n/b) + f(n)
//                     其中将n/b解释为[n/b]或[N/b],则T(n)有如下渐近界：
//                         1 若对某个常数e>0有f(n) = O(n的(logb(a-e)次方)，则T(n) = theta(n的logb(a)次方)。
//                         2 若f(n) = theta(n的logb(a)次方)，则T(n) = theta(n的(logb(a))次方lgn)。
//                         3 若对某个常数e>0有f(n) = Omiga(n的(logb(a+e))次方)，且对某个常数c<1和所有足够大的n有af(n.b)<=cf(n)，则T(n) = theta(f(n))。
//   对三种情况，都将 f(n) 与 n的logb(a)次方 进行比较。直观上，前者更大，解如情况3；后者更大，解如情况1，两者相等，解如情况2.
//   实际上，不是简单小于、大于即可，而要是多项式的渐近小于(相差因子n的e次方)、大于(满足正则条件af(n/b) <= cf(n))
//   三种情况之间还存在其他可能，在这些范围内不能使用主定理。
//   附：正则条件：指在陈述某个定理时，限定它的使用范围。如果超出这个范围，会导致定理不成立。

// 4.5.2 使用主方法
//   分析对应a、b的值，判断 f(n) 与 n的logb(a)次方 的渐近大小。
//   确定主定理的哪种情况成立，即可得到解。


// test
// 1 主方法求渐近紧确界
//   a T(n) = 2T(n/4) + 1        theta(n的(1/2)次方)
//   b T(n) = 2T(n/4) + 根号n    theta(n的(1/2)次方lgn)
//   c T(n) = 2T(n/4) + n        theta(n)
//   d T(n) = 2T(n/4) + nn       theta(nn)

// 2 Caesar教授想设计一个渐近快于Strassen算法的矩阵乘法。
//   采用分治法，将矩阵分解为n/4 x n/4的子矩阵，分解和合并花费theta(nn)时间。
//   需要创建多少个子问题才能击败Strassen算法？
//   T(n) = aT(n/4) + theta(nn) 求a的最大整数值。
//   Strassen: theta(n的lg7次方)
//   Caesar:   theta(n的log4(a)次方)
//   log4(a) < lg7  so a<=48

// 3 使用主方法证明，二分查找递归式T(n) = T(n/2) + theta(1) 的解时T(n) = theta(lgn)
//   a=1  b=2  n的lgb(a)=1=f(n)
//   so situation2：T(n) = theta(n的logb(a)次方lgn) = theta(lgn)

// 4 主方法能用于递归式T(n) = 4T(n/2) + nnlgn吗？ 给出一个渐近上界
//   a=4  b=2  n的lgb(a)= nn 
//   f(n) = nnlgn 渐近大于 nn,但不存在e>0,使f(n) = Omiga(n的logb(a+e)次方)
//   So can not prove.
//   用递归树求解：
//   T(n) = 求和(0 to lgn - 1)nn(lgn - i) + theta(nn)
//        = (1/2)nn(lgn)的平方 + theta(nn)
//        = O(nn(lgn)的平方) (when c>=1)


// 4.6 证明主定理
//   1 分析主递归式，简化定义n为b的幂次。
//   2 分析扩展到所有整数n，应用向下和向上取整的数学技巧。
//   3 稍微滥用渐近符号，用以描述b的幂上的函数行为。  当然，再有限值域上应用渐近符号应当小心，避免错误结论。

// 4.6.1 对b的幂证明主定理
//   引理4.2 令a>=1.b>1是常数，f(n)是一个定义在b的幂上的非负函数。T(n)是定义在b的幂上的递归式：
//           T(n) = theta(1)        n=1
//                = aT(n/b) + f(n)  n=b的i次方(i为正整数)
//           T(n) = theta(n的logb(a)次方) + 求和(0 to logb(n-1))(a的j次方)f(n/(b的j次方))  (使用递归树求总代价)
//   从递归树看，主定理三种情况对应：
//       1 树的总代价由叶结点的代价决定
//       2 树的总代价均匀分布在树的所有层上
//       3 树的总代价由根结点的代价决定
//   引理4.3 令a>=1.b>1是常数，f(n)是一个定义在b的幂上的非负函数。g(n)是定义在b的幂上的函数：
//           g(n) = 求和(0 to logb(n-1)) (a的j次方)f(n/(b的j次方))
//           对b的幂，g(n)有如下渐近界：
//              1 若对某个常数e>0有f(n) = O(n的(logb(a-e))),则g(n) = O(n的logb(a)次方)
//              2 若f(n) = theta(n的logb(a)次方),则g(n) = theta(n的logb(a)次方lgn)
//              3 若对某个常数c<1和足够大的n有af(n/b) <= cf(n),则g(n) = theta(f(n))
//   引理4.4 利用4.3的界和4.2的和式进行求值。
//           1 T(n) = theta(n的logb(a)次方) + O(n的logb(a)次方)        = theta(n的logb(a)次方)
//           2 T(n) = theta(n的logb(a)次方) + theta(n的logb(a)次方lgn) = theta(n的logb(a)次方lgn)
//           3 T(n) = theta(n的logb(a)次方) + theta(f(n))              = theta(f(n))

// 4.6.2 向下取整和向上取整
//   通过向下或向上取整，将递归式定义在所有整数上。
//   上下界证明类似，以上界证明为例。
//   nj(表示序列中第j个元素) = n        j=1
//                           = [Nj-1/b] j>0
//   nj <= n/b的j次方 + 求和(0 to j-1)(1/b的i次方) < n/b的j次方 + 求和(0 to 无穷)(1/b的i次方) = n/b的j次方 + b/(b-1)
//   令j=[logb(n)], nj < b + b/(b-1) = O(1)
//   T(n) = theta(n的logb(a)次方) + 求和(0 to [logb(n)]-1)(a的j次方)f(nj)
//   f(nj) <= c(n/b的j次方 + b/(b-1))的logb(a)次方 <= O(n的logb(a)次方/a的j次方)


// test 
// 1 对b是正整数而非任意实数的情况，给出公式(4.27)中nj的简单而准确的表达式
//   nj = [N/b的j次方]

// 2 Show that if f(n) = theta(n的logb(⁡a)次方(lgn)次方), where k≥0k≥0, then the master recurrence has solution T(n)=theta(n的logb(a)次方(lgn)的k次方).
//   For simplicity, confine your analysis to exact powers of b.
//   g(n) = 求和(0 to logb(n-1)) (a的j次方f(n/b的j次方))
//   代入f(n) = theta(n的logb(⁡a)次方(lgn)次方)
//   g(n) = theta(求和(0 to logb(n-1)) a的j次方 x (n/b的j次方)的logb(⁡a)次方 x (lg(n/b的j次方))次方)
//        = n的logb(a)次方 x 求和(0 to logb(n-1)) (a/(b的logb(a)))的j次方 x (lg(n/b的j次方))次方)
//        = n的logb(a)次方 x 求和(0 to logb(n-1))(lg(n/b的j次方))次方)
//        = n的logb(a)次方 x 求和(0 to logb(n-1))((lgn)的k次方 - o((lgn)的k次方)
//        = n的logb(a)次方 x (logb(n)(lgn)的k次方 + logb(n) x o((lgn)的k次方)
//        = n的logb(a)次方 x theta(logb(n) x (lgn)的k次方)
//        = theta(n的logb(a)次方 x (lgn)的k+1次方)
//   T(n) = theta(n的logb(a)次方) + g(n) 
//        = theta(n的logb(a)次方) + theta(n的logb(a)次方 x (lgn)的k+1次方)
//        = theta(n的logb(a)次方 x (lgn)的k+1次方) 即证

// 3 证明主定理情况3被过分强调了，某种意义上，对某个常数c<1,正则条件af(n/b)<=cf(n)成立本身意味着存在常数e>0,使得f(n) = Omiga(n的logb(a+e)次方)
//   令A = a/c
//   af(n/b) <= cf(n) 等价为 Af(n/b) <= f(n)
//   Af(n) <= f(nb)
//   A的i次方f(n) <= f(n(b的i次方))
//   A的i次方f(1) <= f(b的i次方)
//   令n = b的i次方，i = logb(n),则
//   f(n) = A的logb(n)次方 x f(1) = Omiga(n的logb(A))  (A>a 等价于 A=a+d when c<1,d>0)
//   等价于 f(n) = n的(logb(a) + logb(d))次方 = n的logb(a+e)次方 (when e=logb(d))


// hard test
// 1 给出每个递归式的渐近上下界，并验证。假定n<=2时，T(n)是常数。
// a T(n) = 2T(n/2) + nnnn
//   a=2,b=2,n的logb(a)次方=n < f(n)=nnnn
//   T(n) = theta(nnnn)
//   Prove: T(n) <= cnnnn
//   T(n) = 2T(n/2) + nnnn
//       <= 2c(n/2)的4次方 + nnnn
//        = (c/8+1)nnnn
// b T(n) = T(7n/10) + n
//   a=1,b=7,n的logb(a)次方=1 < f(n)=n
//   T(n) = theta(n)
//   Prove: T(n) <= cn
//   T(n) = T(7n/10) + n
//       <= c(7n/10) + n
//        = (7c/10 + 1)n
// c T(n) = 16T(n/4) + nn
//   a=16,b=4,n的logb(a)次方=nn = f(n)=nn
//   T(n) = theta(nnlgn)
//   Prove: T(n) <= cnnlgn
//   T(n) = 16T(n/4) + nn
//       <= 16c(n/4)的平方lg(n/4) + nn
//        = cnnlgn +  (1-2c)nn
//       <= cnnlgn  (when c >= 1/2)
// d T(n) = 7T(n/3) + nn
//   a=7,b=3,n的logb(a)次方 < f(n)=nn
//   T(n) = theta(nn)
//   Prove: T(n) <= cnn
//   T(n) = 7(n/3) + nn
//       <= c7(n/3)的平方 + nn
//        = (7c/9 + 1)nn
// e T(n) = 7T(n/2) + nn
//   a=7,b=2,n的logb(a)次方 > f(n)=nn
//   T(n) = theta(n的log2(7)次方)
//   Prove: T(n) <= cn的log2(7)次方 - dnn
//   T(n) = 7T(n/2) + nn
//       <= 7c(n/2)的log2(7)次方 -d(n/2)的平方 + nn
//        = cn的log2(7)次方 + (1 - d/4)nn
//       <= cn的log2(7)次方 (when d >= 4)
// f T(n) = 2T(n/4) + 根号n
//   a=2,b=4,n的logb(a)次方=根号n = f(n)
//   T(n) = theta((根号n)lgn)
//   Prove: T(n) <= c(根号n)lgn
//   T(n) = 2T(n/4) + 根号n
//       <= 2c(根号n/4)lg(n/4) + 根号n
//        = c(根号n)lgn + (1 - 2c)(根号n)
//       <= c(根号n)lgn (when c >= 1/2)
// g T(n) = T(n-2) + nn
//   不适用主方法，采用递归树法。
//   T(n) = nn + (n-2)的平方 + (n-4)的平方 +...+ T(2)
//        = 求和(0 to n/2 - 1)(n - 2i)的平方 + T(2)
//        = theta(nnn)

// 2 参数传递的代价
//  1 数组通过指针传递，时间=theta(1)
//  2 数组通过元素复制来传递，时间=theta(N) (N为数组规模)
//  3 传递数组时，只复制过程可能访问的子区域，时间=theta(q-p+1) (子区间长度)
// a 采用递归二分查找法，求三种情况下最坏运行时间的递归式，并给出解的上界。
//   1 T(n) = T(n/2) + c =theta(lgn)
//   2 T(n) = T(n/2) + cN = T(n/4) + 2cN =...= 求和(0 to lgn-1)(2的i次方cN) = cNlgn =theta(nlgn)
//   3 T(n) = T(n/2) + cn = theta(n)
// b 采用归并排序
//   1 T(n) = 2T(n/2) + cn = theta(nlgn)
//   2 T(n) = 2T(n/2) + cn + 2N 
//          = 求和(0 to lgn-1)(cn + 2的i次方N) 
//          = cnlgn + N((2的lgn次方-1)/(2-1))
//          = cnlgn + nN - N
//          = theta(nn)
//   3 T(n) = 2T(n/2) + cn + 2n/2
//          = 2T(n/2) + (c+1)n
//          = theta(nlgn)

// 3 给出每个递归式的渐近上下界，并验证。假定对足够小的n，T(n)是常数。
//  1 T(n) = 4T(n/3) + nlgn
//    a=4,b=3,n的logb(a)次方=n的log3(4)次方=n(n的log3(4/3)次方) > nn > f(n)=nlgn
//    T(n) = theta(n的log3(4)次方)
//  2 T(n) = 3T(n/3) + n/lgn
//    a=3,b=3,n的logb(a)次方=n   f(n)=n/lgn
//    when n>=2  n的logb(a)次方 >= f(n)   so T(n) = theta(n)
//    or 积分求和的近似
//    T(n) = 3T(n/3) + n/lgn = ntheta(1) + 求和(0 to log3(n-1)) (n/(lg n-1))
//         = theta(n) + 求和(1 + lgn - log3(n)) (1/i)
//         = theta(nlglgn)
//  3 T(n) = 4T(n/2) + nn根号n
//    a=4,b=2,n的logb(a)次方=nn < f(n)
//    T(n) = theta(nn根号n)
//  4 T(n) = 3T(n/3 - 2) + n/2
//    n足够大时，忽略-2. a=3,b=3,n的logb(a)次方n = f(n)
//    T(n) = theta(nlgn)
//  5 T(n) = 2T(n/2) + n/lgn
//    积分求和近似
//    T(n) = 2T(n/2) + n/lgn
//         = theta(n) + 求和(0 to lg n-1) (n/(lgn - i))
//         = theta(nlglgn)
//  6 T(n) = T(n/2) + T(n/4) + T(n/8) + n
//    类4.4-6，从log8(n)开始不完全，每层代价为cn，层高为lgn
//    T(n) >= O(nlgn)
//  7 T(n) = T(n-1) + 1/n
//    积分求和近似
//    T(n) = T(n-1) + 1/n
//         = 1/n + 1/(n-1) + T(n-2)
//         = 求和(0 to n-1) (1/(n-i)) + theta(1)
//         = theta(lgn)
//  8 T(n) = T(n-1) + lgn
//    递归树
//    T(n) = 求和(0 to n-1)(lg n-i)
//         = 求和(1 to n) (lgi) + theta(1)
//         = theta(lg(n!))
//        <= theta(nlgn)
//  9 T(n) = T(n-2) + 1/lgn
//    积分求和的近似
//    T(n) = 1/lgn + 1/lg(n-2) +...+ theta(1)
//         = 求和(0 to n/2 - 1)(1/lg(n-2i))
//         = 求和(2 to n)(1/lgi)
//         = 求和(1 to lgn)(1/i)
//         = theta(lglgn)
//  10 T(n) = 根号nT(根号n) + n
//     换元法 + 主定理
//     令S(n) = T(n)/n,则S(n) = S(根号n) + 1
//     考虑n=2的m次方时，有S(2的m次方) = S(2的m/2次方) + 1
//     令P(m) = S(2的m次方),则P(m) = P(m/2) + 1
//     a=1,b=2,n的logb(a)次方=1 = f(n)
//     P(m) = theta(lgm)
//     T(n) = nS(n) = nP(m) = theta(nlgm) = theta(nlglgn)

// 4 Fibonacci numbers (Fi = Fi-1 + Fi-2)
//   讨论递归式定义的斐波那契数的性质。使用生成函数技术求解斐波那契递归式。
//   生成函数(形式幂级数F) F(z) = 求和(0 to 无穷)(Fi(z的i次方))
//   a Prove:F(z) = z + zF(z) + zzF(z)
//     F(z) = z + z求和(0 to 无穷)(Fi(z的i次方)) + zz求和(0 to 无穷)(Fi(z的i次方))
//          = z + 求和(1 to 无穷)(Fi-1(z的i次方)) + 求和(2 to 无穷)(Fi-2(z的i次方))
//          = z + 求和(2 to 无穷)((Fi-1 + Fi-2)(z的i次方))
//          = z + 求和(2 to 无穷)(Fi(z的i次方))
//          = F(z)
//   b Prove: F(z) = z/(1-z-zz) = z/(1-fz)(1-f'z) = 1/根号5(1/(1-fz) - 1/(1-f'z))
//     f = (1+根号5)/2  f' = (1 - 根号5)/2
//     From a: F(z) = z/(1-z-zz)
//   c Prove: F(z) = 求和(0 to 无穷)(1/根号5(f的i次方 - f'的i次方)(z的i次方))
//     由几何级数性质1/(1-x) = 求和(0 to 无穷)(x的k次方) (when -1<x<1)
//     F(z) = 1/根号5(1/(1-fz) - 1/(1-f'z))
//          = 1/根号5(求和(0 to 无穷)((f的i次方)(z的i次方)) - 求和(0 to 无穷)((f'的i次方)(z的i次方)))
//          = 求和(0 to 无穷)(1/根号5(f的i次方 - f'的i次方)(z的i次方))
//   d Prove: 对i>0, Fi = f的i次方/根号5，结果舍入到最接近的整数。
//     Fi = f的i次方/根号5 - f'的i次方/根号5
//     Fi = {0，1，2，3，5，8，13，......}
//     当i>0 , -1<f'<1时， -0.5<f'的i次方/根号5<0.5
//     所以，对一个整数，加减一个小于0.5的数，对所得结果舍入到最近整数即可。

// 5 芯片检测。 有n片可能完全一样的芯片，可以相互检测。一次只能装两块，两块互测，好芯片能准确报告，坏芯片不能。
//   可能结果：1代表好，0代表坏
//    11 - 都好或都坏  10 - 至少一个坏  01 - 至少一个坏  00 - 至少一个坏
//  a 如果超过n/2块坏芯片，任何逐对检测都无法确定芯片好坏。
//    当好芯片数量少于n/2时，会有同样数量或更多的坏芯片，无法判断准确性。
//    当好芯片数量多余n/2时，准确判断的结果多于不准确的，因此报告结果最多的即为准确结果。
//  b 考虑从n块芯片中找一块好芯片，假设有超过n/2块好芯片。证明：进行[n/2]次逐对检测足以将问题规模减半。
//    分两类，每类[n/2]个，逐对比较，保留情况1的（也就是至少剔除一个坏的）。剩下的每对芯片随机留一个，组成新集合。
//    该集合满足：超过一半的好芯片，同时规模减半。
//  c 求b对应的递归式及对应的解。
//    T(n) = T(n/2) + [n/2]
//    T(n) = theta(n)

// 6 Monge阵列  对一个mxn实数阵列A，若对所有满足1<=i<k<=m和1<=j<l<=n的i,j,k,l有：
//   A[i,j] + A[k,l] <= A[i,l] + A[k,j],则称为Monge阵列。
//   换言之，无论何时选出Monge阵列的两行或两列，对于交叉点上的4个元素，左上和右下之和总小于左下和右上之和。
// a 证明：一个数组是Monge阵列当且仅当对所有i=1,2...,m-1和j=1,2...n-1，有A[i,j] + A[i+1,j+1] <= A[i,j+1] + A[i+1,j]
//   假设    A[i,j] + A[k,j+1] <= A[i,j+1] + A[k,j]
//   递归    A[k,j] + A[k+1,j+1] <= A[k,j+1] + A[k+1,j]
//   相加得  A[i,j] + A[k,j+1] + A[k,j] + A[k+1,j+1] <= A[i,j+1] + A[k,j] + A[k,j+1] + A[k+1,j]
//   两边同时消去A[k,j+1] + A[k,j] 得A[i,j] + A[k+1,j+1] <= A[i,j+1] + A[k+1,j]
//   同理得证列
// b 下列数组不是Monge阵列。改变一个元素使之变成Monge阵列
//    37 23 22 32
//    21  6  7 10
//    53 34 30 31
//    32 13  9  6
//    43 21 15  8
//   将第一行第三列22改为24.
// c 令f(i)表示第i行最左最小元素的列下标。证明：对任意mxn的Monge阵列，f(1)<=f(2)<=...f(m)
//   反证法。 若f(i) > f(j) (i<j)
//   A[i,f(i)] + A[j,f(j)] < A[i,f(j)] + A[j,f(i)]
//   与A[i,f(j)] + A[j,f(i)] <= A[i,f(i)] + A[j,f(j)]矛盾
// d 计算mxn的Monge阵列A每一行最左最小元素的分治算法的描述：
//     提取A的偶数行构造子矩阵A'。递归确定A'每行的最左最小元素。然后计算A的奇数行的最左最小元素。
//   解释如何在O(m+n)时间内计算A的奇数行的最左最小元素（在偶数行的最左最小元素已知的情况下）
//   T(m,n) = 求和(0 to m/2 - 1)(u2i+2 - u2i + 1)
//          = 求和(0 to m/2 - 1)(u2i+2) - 求和(0 to m/2 - 1)(u2i) + m/2
//          = 求和(1 to m/2)(u2i) - 求和(0 to m/2 - 1)(u2i) +m/2
//          = um - u0 + m/2
//         <= n + m/2
//          = O(m+n)
// e 给出d中算法的递归式，求解。
//   T(m) = T(m/2) + cn + m/2
//        = cn + dm/2 + cn + dm/4 +...
//        = 求和(0 to lg m-1)(cn) + 求和(0 to lgm)(dm/(2的i+1次方))
//        = cnlgm + dm求和(0 to lg m-1)(1/2的i+1次方)
//        < cnlgm + dm求和(0 to 无穷)(1/2的i次方)
//        = cnlgm + 2dm
//        = O(nlgm + m)


// 概率分析和随机算法
// 5.1 雇佣问题
//   需要雇佣一名新的办公助理。雇佣代理每天推荐一个应聘者。
//   给雇佣代理一小笔费用用于推荐，如果雇佣需要一大笔钱且辞掉目前办公助理。
//   任何时候都需要有在职的办公助理，如果发现更合适的，则辞掉目前的聘用新的。
//   采取该策略，估算费用是多少。
//   假设应聘候选人编号1-n。过程中，面试完i后，决定i是否是目前见过的最佳人选。初始化时，虚拟应聘者0，他是所有人里最差的。
//  伪代码：
//  Hire_Assistant(n)
//   best = 0
//   for i=1 to n
//     interview candidate i
//     if candidate i is better than candidate best
//        best = i
//        hire candidate i
//     该模型与第二章不同，不关注执行时间，而关注面试和雇佣产生的费用。但都是计算特定基本操作的执行次数。
//     面试费用较低，记为ci；雇佣费用较高记为ch。假设雇佣人数为m，则算法总费用为O(cin + chm)
//     由于需要面试所有人，即总是花费cin，所有关注于分析chm
//   这个场景用作一般计算范式的模型。通常通过检查序列中每个成员，维护一个当前的best，来找出序列中的最值。这个问题对当前best的更新频率建立模型。

// 5.1.1 最坏情形分析
//   应聘者质量按出现次序严格递增，雇佣了n次，总费用为O(chn)
//   但应聘者质量并非总以递增次序出现。事实上也无法知道出现次序，无法控制次序。
//   因此会想在一种典型或平均情形下，会有什么发生。

// 5.1.2 概率分析
//   在问题分析中应用概率的理念。 
//   大多数情况下，运用概率分析来分析算法运行时间或分析其他量（如费用）
//   为了概率分析，需要使用或假设关于输入的分布，计算出平均情形下的运行时间。对所有可能输入产生的时间取平均，即平均情况运行时间。
//   在确定输入分布时必须非常小心，需要确定一个合理的输入分布，在此基础上设计算法。如果输入分布不合理，则不能采用概率分析。
//   雇佣问题中，假设应聘者随机出现，应聘者存在全序关系。因此，对应聘者用唯一号码排列名次，排名构成一个均匀随机排列，每种等概率出现。

// 5.1.3 随机算法
//   许多情况下，对输入分布的了解很少。即使知道输入分布的部分信息，也难以建立计算模型。
//   通过算法部分行为随机化，可以利用概率和随机性作为算法设计和分析的工具。
//   如果一个算法的行为不仅由输入决定，也由随机数生成器产生的数值决定，则称该算法是一个随机算法。
//   随机数生成器RANDOM(a,b)返回一个介于ab之间的数，等可能出现。(实践中，编程环境提供一个伪随机数生成器，是一个确定性算法，返回值在统计上看起来是随机的)
//   在分析一个随机算法时，以运行时间的期望值衡量(期望运行时间)


// test
// 1 证明：假设在过程Hire_Assistant的第4行中，总能决定哪一个应聘者最佳，则意味着我们知道应聘者排名的全部次序。
//   1 由于总能决定那个应聘者最佳，故两两之间都定义了关系，所以是一个全关系
//   2 其次由于1、每个应聘者都比自己好或者更好，所以满足自反性；
//             2、如果应聘者A比B好或更好，B又比A好或更好，而且因为总能决定哪个应聘者最佳，故显然没有两个同样好的不同应聘者，那么显然A就是B，所以满足反对称性；
//             3、如果应聘者A比B好，B又比C好，那么显然A就比C好，所以满足传递性。因此该关系就是一个偏序关系。
//   3 由于该关系同时是全关系和偏序关系，所以就是一个全序关系，所以我们能知道应聘者的全部次序。

// 2 描述Random(a,b)过程的一种实现，只调用Random(0,1).
//   伪代码：
//   Random(a,b)
//   do
//     取n为log(b-a)的向上取整
//      x = 0
//      for i=0 to n-1
//          x += pow(2,i) * Random(0,1)
//    while (x <= b-a)  
//    return x+a

// 3 以1/2的概率输出0与1.使用输出0或1的过程Biased_Random.
//   以概率p输出1，概率1-p输出0，0<p<1.
//   给出一个算法，返回一个无偏的结果，能以1/2概率输出1.
//   伪代码：
//   Biased_Random(p)
//    x = p
//    while x isn't integer  //p小数点右移等到整数x
//          x *= 10t
//    total = x/p   // 将p扩大到x一共扩大了total倍
//    if Random(0,total) <= x  // total个数中，调用Random(0,total)返回值小于x，返回1
//       return 1
//    else
//       return 0
//    NonBiased_Random(0,1)
// 1   x = 0
// 2   for i=0 to 1
// 3       x += pow(x,i) * Biased_Random(0,1)  // pow(x,y)=x的y次幂
 //    if x==1
//        return 0
//     else if x==2
//        return 1
//     else
//        circle step 1 to 3

// 5.2 指示器随机变量
//   为了分析雇佣问题在内的许多算法，采用指示器随机变量，为概率与期望之间的转换提供一个便利方法。
//   给定一个样本空间S和一个事件A，A对应的指示器变量I{A}定义为：
//       I{A} = 1 (when A happen)
//            = 0 (when A didn't happen)
// 5.2.1 引理5.1 
//   给定一个样本空间S和S中的一个事件A，设XA=I{A}，那么E[XA]=Pr{A}.
//   Prove: E[XA] = E[I{A}] = 1xPr{A} + 0xPr{A~} = Pr{A}
//   期望的线性性质利用指示器随机变量作为一种强大的分析技术；当随机变量之间存在依赖关系时也成立。
//   相比和等式(C.37)，指示器随机变量极大简化计算过程。

// 5.2.2 用指示器变量分析雇佣问题
//   假设应聘者以随机顺序出现。设X是一个随机变量，值等于我们雇佣一个新办公助理的次数。
//   应用期望定义，E[X] = 求和(x=1 to n)xPr{X=x} (但是这样计算麻烦)
//   为了利用指示器随机变量，通过定义n个变量，与每个应聘者是否被雇佣对应。
//   假设Xi对应于第i个应聘者被雇佣该事件的指示器随机变量，
//       Xi = I{应聘者i被雇佣} = 1 如果i被雇佣
//                             = 0 如果i不被雇佣
//       X = 求和(i=1 to n) (Xi)
//       E[Xi] = Pr{应聘者i被雇佣}
//   前i个应聘者中任意一个都等可能地是目前最有资格的。应聘者i比应聘者1到i-1更有资格的概率是1/i，被雇佣的概率为1/i
//       E[Xi] = 1/i
//       E[X] = E[求和(i=1 to n) (Xi)] = 求和(i=1 to n)E[Xi] = lnn + O(1)  
//   尽管面试了n个人，平均下来只雇佣了其中的lnn个人。

// 5.2.3 引理5.2
//   假设应聘者以随机次序出现，算法Hire_Assistant总的雇佣费用平均情形下为O(Chlnn)
//   由上述等式证得。


// test
// 1 Hire_Assistant中，雇佣一次的概率为，雇佣n次的概率为？
//   A雇佣一次：最佳者出现在第一次面试 Pr{A}=1/n
//   B雇佣n次： 面试者出现顺序按递增排序（唯一），共有n!种排列可能 Pr{B}=1/n!

// 3 利用指示器随机变量来计算掷n个骰子之和的期望值
//   扔一个骰子E(x) = 1*1/6 + 2*1/6 + 3*1/6 + 4*1/6 + 5*1/6 + 6*1/6 = 3.5
//   扔n个骰子 E(nx) = nE(x) = 3.5n

// 4 帽子核对问题：n位顾客，他们每个人给餐厅核对帽子的服务生一顶帽子。服务生随机顺序将帽子归还给顾客。拿回自己帽子的客户的期望数。
//   第一位顾客：E(X1) = 1/n
//   第二位顾客：E(X2) = (n-1)/n (帽子没被拿错的概率) * (1/(n-1)) (拿到自己帽子的概率) = 1/n
//   ...
//   第n位顾客： E(Xn) = 1/n
//   E(X) = E(X1) + E(X2) +...+ E(Xn) = 1

// 5 设A[1...n]是由n个不同的数构成数组。如果i<j且A[i]>A[j],则称(i,j)对为A的一个逆序对
//   假设A的元素构成<1,2,...,n>上的一个均匀随机排列。请用指示器随机变量来计算其中逆序对的数目期望。
//   n个元素有Cn(2)种选择方法，两个元素要么顺序要么逆序，可能性为1/2.
//   E(X) = E(X1)+E(X2)+...+E(Xn)=(1/2)Cn(2) = (n-1)n/4

// 5.3 随机算法
//   对于如雇佣问题，假设输入的所有排列等可能出现比较有益，通过概率分析可以指导设计一个随机算法。
//   不是假设输入的一个分布，而是设定一个分布。
//   在算法运行前，随机排列应聘者。
//   概率分析中，聘用一个新办公助理的期望次数是lnn；随机算法中，用应聘者有序排名列表来代表特定输入对应一个固定的输出，算法费用依赖输入。
//   先考虑对应聘者排列，在确定最佳应聘者的随机算法。让随机发生在算法上而不是输入分布上。
//   对于雇佣问题，代码中唯一改变的是随机变换应聘者序列
//   Randomized_Hire_Assistant(n)
//    randomly permute the list of candidates
//    best = 0
//    for i=1 to n
//        interview candidate i
//        if candidate i is better than candidate best
//           best = i
//           hire candidate i
// 5.3.1 引理5.3 过程Randomized_Hire_Assistant的雇佣费用期望是O(Chlhn)
//   Prove:对输入数组进行变换后，已经达到和Hire_Assistant概率分析时相同的情况。
//   引理5.2中，在输入上做出假设；引理5.3中没有做这种假设，但在随机化输入上会花费额外时间。
//   用平均情形下的雇佣费用来表达引理5.2，用期望雇佣费用来表达引理5.3.

// 5.3.2 随机排列数组
//   很多随机算法通过对给定输入变换排列使输入随机化(当然也有其他方法)
//   此处讨论两种随机化方法。假设给定一个数组A，包含元素1到n。通过该数组构造一个随机排列。
//   为每个数组元素A[i]赋一个随机优先级P[i],然后依据优先级对数组A种元素进行排序。
//     例如：对初始数组A=<1,2,3,4>,随机优先级P=<36,3,62,19>,产生数组B=<2,4,1,3>
//     称此过程为Permute_By_Sorting
//   Permute_By_Sorting:
// 1   n = A.length
// 2   let P[1...n] be a new array
// 3   for i=1 to n
// 4       P[i] = Random(1,nnn)
// 5   sort A,using P as sort keys
//   在第四行选取一个1到nnn之间的随机数（该范围为了使P中优先级尽可能唯一）
//   第五行耗时最多。如果使用比较排序将花费theta(nlgn)时间。如果P[i]是第j个最小优先级，它将出现在输出的j位置上。

// 5.3.2 引理5.4 假设所有优先级都不同，则过程Permute_By_Sorting产生输入的均匀随机排列。
//   Prove:考虑每个元素A[i]分配到第i个最小优先级的特殊排列开始，并说明这个排列正好发生的概率是1/n!
//         对i=1,2,...,n,设Ei代表元素A[i]分配到第i个最小优先级的事件。
//         计算对所有i，事件Ei发生的概率：Pr{E1∩E2∩...∩En-1∩En}
//         由C.2-5得：上式 = Pr{E1}*Pr{E2|E1}*Pr{E3|E2∩E1}*...*Pr{Ei|Ei-1∩Ei-2∩...∩E1}*...*Pr{En|En-1∩En-2∩...∩E1}
//         Pr{E1}代表从n个元素中随机选择最小优先级的概率，为1/n
//         Pr{E2|E1} = 1/(n-1)
//         ...
//         Pr{Ei|Ei-1∩Ei-2∩...∩E1} = 1/(n-i)
//         ...
//         Pr{En|En-1∩En-2∩...∩E1} = 1
//         所以 Pr{E1∩E2∩...∩En-1∩En} = 1/n * 1/(n-1) * ... * 1/2 * 1 = 1/(n!)
//         同理 获得任意特定排列的概率为1/(n!)

// 5.3.3 更好的算法以产生随机排列
//   要证明一个排列是均匀随机排列，即证每个元素出现在位置j的概率是1/n。但实际上这个若条件不充分。
//   产生随机排列的一个更好的算法是原址排列给定数组。过程Ranmoized_In_Place在O(n)内完成。在进行i次迭代时元素A[i]是从元素A[i]到A[n]随机选取的。i次后，A[i]不变。
//   Randomized_In_Place(A)
// 1  n = A.length
// 2  for i=1 to n
// 3      swap A[i] with A[Random(i,n)]
//   将使用循环不变式来证明过程能产生一个随机均匀排列，一个具有n个元素的k排列(k-permutation)是包含这n个元素中的k个元素的序列，并且不重复。一共有n!/(n-k)!种可能的k排列

// 5.3.4 引理5.5 过程Randomized_In_Place可计算出一个均匀随机排列
//   Prove:在第2-3行for循环的第i次迭代之前，对每个可能的(i-1)排列子数组A[1...i-1]包含这个(i-1)排列的概率是(n-i+1)!/n!
//         初始化：在第一次循环迭代时，i=1.对每个可排列的0排列，子数组A[1...0]包含这个0排列的概率是(n-i+1)!/n! = n!/n! = 1.子数组为空数组，无元素不需要排列，成立。
//         保持：假设在第i次迭代之前，对每种可能的(i-1)排列子数组A[1...i-1]包含这个(i-1)排列的概率是(n-i+1)!/n!。
//               在第i次迭代之后，对每种可能的i排列子数组A[1...i]包含这个i排列的概率是(n-i)!/n!
//               记Pr{E1} = (n-1+1)!/n!  E2表示第i次迭代在位置A[i放置xi的事件。
//               E1，E2恰好发生时，i排列<x1,...,xi>出现在A[1...i]中，计算Pr{E2∩E1} = Pr{E2|E1}*Pr{E1} = 1/(n-i+1) * (n-1+1)!/n! = (n-1)!/n! 成立
//         终止：终止时，i=n+1,子数组A[1...n]是一个给定n排列的概率为(n-(n+1)+1)/n! = 0!/n! = 1/n!
//         因此，Randomized_In_Place产生一个均匀随机排列。
//  一个随机算法通常是解决一个问题最简单、最有效的方法。

// test 
// 1 重写Randomize_In_Place,使得相关循环不变式适用于第一次迭代之前的非空子数组，并修改引理5.5的证明。
//   将数组A的第一个元素的随机交换单独列出
//   循环从数组A的第二个元素开始直至最后
//   Randomize_In_Place(A)
//     n = A.length
//     swap A[1] with A[Random(1,n)]
//     for i=2 to n
//         swap A[i] with A[Random(i,n)]
//   证明修改：
//     初始化：此时i=2。对每个可能的1排列，子数组A[1]包含这个1排列的概率：
//               (n-i+1)!/(n-1)! = (n-2+1)!/(n-1)! = 1
//             子数组A[1]是一个单元素数组，1排列也是单元素排列，因此任意1排列概率为1.成立。

// 2 Kelp教授写了一个过程来随机产生除恒等排列(identity permutation)外的任意排列
//   附：排列恒等式的定义：含有排列数的恒等式。 
//   伪代码如下：
//   Permute_Without_Identity(A):
//   1 n = A.length
//   2 for i=1 to n-1
//   3     swap A[i] with A[Random(i+1,n)]
//   能实现目的吗？ (经过随机排列之后，任意一共非恒等排列出现的概率均为1/(n!-1))
//     不能。 理由如下：
//     假设第i次循环之后，对于任意非恒等子排列出现在前i位的概率为1/(An(i) - 1)
//     如果假设成立，迭代到i=n-1时，目的实现，如果不成立，此时i对应的n即为反例。
//     设事件E1表示i次循环后，对于任意特定非恒等子排列，该排列的前i-1位出现数列的前i-1位；
//     设事件E2表示该特定非恒等子排列的第i位出现在数列第i位置。
//     当且仅当E1，E2同时发生的时候该特定顺序的前i位出现在数列的前i位。
//     该事件概率为P(E1∩E2) = P(E2|E1)*P(E1) = (n-i)/(n-i+1)*1/(n-i) = 1/(n-i+1)
//     又1/(n-i+1)*1/(An(i) - 1) != 1/(An(i) - 1) 不成立

// 3 假设不是将元素A[i]与子数组A[1...n]中的随机元素交换，而是将它与数组任何位置上的随机元素交换：
//   Permutation_With_All(A):
//   1 n = A.length
//   2 for i=1 to n
//   3     swap A[i] with A[Random(1,n)]
//   该代码会产生一个均匀随机排列吗？为什么会或为什么不会？
//   该代码能产生A中元素的全排列，但是可能出现相同的，如果重复次数相同就能产生均匀随机排列。
//   产生n的n次方个序列，而全排列只有n！个，n>2时不可能出现均匀随机序列。

// 4 Armstrong教授建议用下面的过程产生一个均匀随机排列：
//   Permutation_By_Cyclic(A):
//   1 n = A.length
//   2 let B[1...n] be a new array
//   3 offset = Random(1,n)
//   4 for i=1 to n
//   5     dest = i +offset
//   6     if dest>n
//   7        dest = dest - n
//   8     B[dest] = A[i]
//   9 return B
//   B其实是将A中每个元素，随机右移，显然不能得到A的所有排列，所以不是均匀随机排列。

// 5 证明：在过程Permute_By_Sorting的数组P中，所以元素都唯一的概率至少是1 - 1/n
//   设事件Ei为生成第i个标号与之前所有标号都不同，每个标号都不同的高铝为：
//   P(E) = P(E1∩E2∩...∩En) = P(E1)*P(E2|E1)*P(E3|E3∩E2∩E1)*...*P(En|En-1∩...∩E1)
//        = 连乘(i=1 to n) (nnn - 1 + 1/nnn)
//       >= (nnn - n/nnn)的n-1次方 (对i>=1 nnn-i>nnn-n)
//   又1 - 1/n = (n-1)/n = (n-1)的3次方/nnn = (nnn - n/nnn)的n-1次方
//   so P(E) >= 1 - 1/n

// 6 解释如何实现算法Permute_By_Sorting,以处理两个或更多优先级相同的情形。
//   当出现优先级相同的情况时，标记优先级相同的元素，递归调用该算法直至没有优先级相同的元素存在。
//   设对长度为n的数组生成优先级后，有k个元素优先级重复。
//   显然这k个元素的每一个排列单独对应整个数组的q个排列，容易证明q=An(n-k)=n!/k!
//   在已经出现了k个元素优先级相同的情况下，该优先级数列所表达的排列正好是一个特定的排列的事件E=事件E1
//   优先级不同的n-k个元素的顺序恰好是该特定顺序中优先级不同元素对应的顺序为事件E2
//   P(E) = P(E1∩E2) = P(E2|E1)*P(E1)
//   P(E1) = k!/n! 若P(E)=1.n!,则P(E2|E1)=1/k!
//   正好要求k个相同优先级对应元素的每种可能的顺序均为1/k!

// 7 希望创建集合{1,2,...,n}的一个随机样本，即具有m个元素的集合S，其中0<=m<=n,使得每个m集合被等可能创建。
//   一种方法是对i=1,2,...,n。设A[i]=i,调用Randomize_In_Place(A),取前m个元素，过程会对Random调用n次。
//   如果n远大于m，能够创建一个随机样本，只对Random调用更少次数。
//   请说明下面递归过程返回{1,2,...,n}的一个随机m子集S，其中每个m子集等可能的，然而只对Random调用m次。
//   Randomize_Sample(m,n)
//   1 if m==0
//   2    return 空集
//   3 else S=Randomize_Sample(m-1,n-1)
//   4      i = Random(1,n)
//   5      if i∈S
//   6         S = S ∪ {n}
//   7      else 
//   8         S = S ∪ {i}
//   9         return S
//   使用循环不定式证明。 严格意义上集合不分顺序，但算法和集合元素的自然顺序便于将集合看做有序。 集合前i个元素意为{1,2,...,i}
//   假设对于任意的i∈[1,m]表示递归返回次序。 第i次递归返回前，已经选取出容量为i-1的子集是集合S的前n-m+i-1个元素组成的集合的任意一个容量为i-1的子集的概率相等，均为1/C(n-m+i-1)(i-1)
//   当i增加到m+1时，从集合前n个元素中选出任意一个容量为m的子集的概率为1/Cn(m).
//   i = 1时，空集包含空集的概率为1；i = 2时，第一个选出元素是S的前n-m+1个元素中的任意一个的概率为P=1/(n-m+1).
//   第i次递归返回假设仍然成立，现证明如下:
//     设事件E表示第i次递归返回后，返回的容量为i的子集合是S的前n-m+i元素构成的集合中的某一个特定组合。
//     该组合的前i-1个元素一定均小于n-m+i，即一定是前n-m+i-1元素构成的集合某个容量为i-1的子集。
//     设E1包含第i-1次递归返回的集合属于该特定集合。
//     设E2表示第i次递归添加的元素属于该特定集合。
//     设E2表示该特定集合最大的元素恰好是n-m+i。
//     事件E相当于E1，E2同时发生。
//         P(E) = P(E1∩E1) = P(E1|E2)P(E2)
//     无论E3是否发生，当E2发生时，该特定顺序集合第i次之前添加的元素一定小于n-m+i。这些元素构成的集合恰好是第i次递归返回的集合的概率为1/C(n-m+i-1)(i-1)
//         P(E1|E2E3) = 1/C(n-m+i-1)(i-1)
//         P(E1|E2E3~) = 1/C(n-m+i-1)(i-1)
//         P(E1|E2) = 1/C(n-m+i-1)(i-1)
//     由概率论公理得：P(E2) = P(E2∩E3) + P(E2∩E3~)
//                     P(E2) = P(E2|E3)P(E3) + P(E2|E3~)P(E3~)
//     P(E2|E3) = (i-1+1)/(n-m+i) = 1/(n-m+i)
//     P(E2|E3~) = i/(n-m+i)
//     由组合数学得：P(E3) = C(n-m+i-1)(i-1)/C(n-m+i)(i)
//                   P(E3~) = C(n-m+i-1)(i)/C(n-m+i)(i)
//     so P(E2) = i/(n-m+i)
//        P(E) = P(E1|E2)P(E2) = 1/C(n-m+i)(i) 成立


// 5.4 概率分析和指示器随机变量的进一步使用
// 5.4.1 生日悖论
//   一个屋子里人数必须达到多少，才能使其中两人生日相同的机会达到百分之50？
//   用整数对屋子里的人编号(1,2,...,k)。不考虑闰年，假设n=365天。
//   对i=1,2,...k，设bi表示编号为i的人的生日，其中1<=bi<=n.
//   假设生日均匀分布在一年的n天中，因此对i=1,2,...,k和r=1,2,...,n，Pr{bi=r} = 1/n
//   前提：两个人i和j的生日正好相同的概率依赖于生日的随机选择是否独立。 
//         假设生日是独立的，于是i和j生日都在同一日r的概率是：Pr{bi=r ∩ bj=r} = Pr{bi=r}*Pr{bj=r} = 1/nn
//         则生日在同一天的概率是：Pr{bi=bj} = 求和(r=1 to n) (Pr{bi=r ∩ bj=r}) = 求和(r=1 to n) (1/nn) = 1/n
//   用事件补的方法来考虑。至少两人生日相同的概率=1 - 所有人生日不同的概率。
//       k个人生日互不相同的事件为：Bk = ∩(i=1 to k) (Ai)  (Ai是指对所有j<i,i与j生日不同的事件)
//       Bk = Ak∩B(k-1)  得递归式：Pr{Bk} = Pr{Bk-1}*Pr{Ak|B(k-1)}  (对i，b1,b2,...,bk互不相同的概率 = b1,b2,...,b(k-1)互不相同的概率 * bk != bi的概率)
//       其中取Pr{B1} = Pr{A1} = 1
//       所以 Pr{Bk} = Pr{B(k-1)}*Pr{Ak|B(k-1)}
//                   = ....
//                   = Pr{B1}*Pr{A2|B1}*...*Pr{Ak|B(k-1)}
//                   = 1*(n-1/n)*(n-2/n)*...*(n-k+1/n)
//                  <= (e的(-1/n)次方)*(e的(-2/n)次方)*...*(e的(-(k-1)/n)次方)  (1+x <= e的x次方)
//                   = (e的(-求和(i=1 to k-1)(i/n))次方)
//                  <= 1/2  (when -k(k-1)/2n <= ln(1/2))
//       解方程得：k >= (1+根号(1+(8ln2)n))/2,k个生日两两不同的概率至多是1/2.
//       当n=365使，必有k>=23   因此，至少23个人在一间物资里，那么至少有两个人生日相同的概率至少是1/2.

// 5.4.1.2 采用指示器随机变量的一个分析
//   用指示器随机变量给出生日悖论的一个简单近似分析。
//   对屋子里k个人中的每一对(i,j),对1<=i<j<=k，定义指示器随机变量Xij:
//     Xij = I{i和j生日相同} = 1  如果i和j生日相同
//                             0  其他
//   E[Xij] = Pr{i和j生日相同} = 1/n
//   设X表示计数生日相同两人对数目的随机变量 X = 求和(i=1 to k)(求和(j=k+1 to k)(Xij))
//     两边取期望 E[X] = E[求和(i=1 to k)(求和(j=k+1 to k)(Xij))] = 求和(i=1 to k)(求和(j=k+1 to k)(E[Xij])) = k(k-1)/2n
//   当k(k-1)>=2n时，生日相同的两人对的期望数至少是1。因此屋子里至少有(根号2n)+1个人，可以期望至少有两人生日相同。
//   对于n=365，若k=28，生日相同两人对的期望值为28*27/2*365=1.0356
//   第一种分析利用概率，第二种分析利用指示器随机变量。两种方法准确数目不同，但是都渐近于theta(根号n)

// 5.4.2 球与箱子
//   把相同的球随机投到b个箱子里。每次投球独立，每个球等可能落在每一个箱子中（概率为1/b）。
//   因此投球过程是一组伯努利实验吗，每次成功概率是1/b，其中成功指球落入指定箱子中。（该模型利于分析散列，11章）
//   有多少球落在给定箱子中？落在给定箱子里的球数服从二项分布b(k;n,1/b)。如果投n个球，落在给定箱子的球数期望值是n/b
//   在平均意义下，必须投多少个球，才能在给定箱子里投中一个球。 易知，成功投球次数期望值是b
//   需要投多少次球，才能使每个箱子里至少一个球？ 一次投球落在空箱子称为一次命中，即为求为了获得b次命中，所需投球次数的期望n。
//   采用命中次数，可以把n次投球分为几个阶段。 第i个阶段包括从第i-1次命中到第i次命中之间的投球。
//     第1阶段包含一次投球，因为都是空箱，所以可以保证一次命中。
//     第i阶段的每一次投球，有i-1个箱子有球，b-i+1个空箱子。 因此，第i阶段每次投球，命中一次的概率是(b-i+1)/b
//     设ni表示第i阶段投球次数。 为得到b次命中所需投球次数为n=求和(i=1 to b)(ni),每个随机变量ni服从几何分布，成功概率为(b-i+1)/b
//       so E[ni] = b/(b-i+1)
//          E[n] = E[求和(i=1 to b)(ni)] = 求和(i=1 to b)(E[ni]) = 求和(i=1 to b)(b/(b-i+1)) = b求和(i=1 to b)(1/i) = b(lnb+O(1))
//   所以期望每个箱子里都有一个球，大约要投blnb次。这个问题也被称为礼券收集者问题（收集b种不同的礼券中的每一种，大约需要blnb张随机得到的礼券）

// 5.4.3 特征序列
//   假设抛一枚硬币n次，最长连续正面的序列的期望长度是多少？ theta(lgn)
//     抛一次正面的概率为1/2   设Aik为这样的事件：长度至少为k的正面序列开始于第i次抛掷(i,i+1,...i+k-1都为正面，长度为k)
//     所有k次抛掷都是正面的概率为： Pr{Aik} = 1/2的k次方
//       对于k=2[lgN],Pr{Ai,2[lgN]} = 1/(2的2[lgN]次方) <= 1/(2的2[lgN]) = 1/nn
//       因此起始位置i，长度至少为2[lgN]的一个正面序列概率很小。这种序列起始位置之多有n-2[lgN]+1个。
//       长度至少为2[lgN]的正面序列开始于任一位置的概率是： Pr{∪(i=1 to n-2[lgN]+1) Ai,2[lgN]} <= 求和(i=1 to n-2[lgN]+1)(1/nn) = 1/n (由布尔不等式得，并集概率至多为各个事件概率之和)
//     利用不等式给出最长特征序列的长度界。
//       对于j=0，1，2，...，n。令Lj表示最长连续正面的特征序列长度正好是j的事件，设最长特征序列长度为L。
//       由期望定义得: E[L] = 求和(i=0 to n)(jPr{Lj})  得到一个弱的界。 此外，求和(j=0 to n)(Pr{Lj}) = 1,所以求和(j=0 to 2[lgN]-1)(Pr{Lj}) <= 1
//       所以 E[L] = 求和(i=0 to n)(jPr{Lj})
//                 = 求和(j=0 to 2[lgN]-1)(jPr{Lj}) + 求和(j=2[lgN] to n)(jPr{Lj})
//                 < 求和(j=0 to 2[lgN]-1)(2[lgN])(Pr{Lj}) + 求和(j=2[lgN] to n)(nPr{Lj})
//                 = 2[lgN]求和(j=0 to 2[lgN]-1)(2[lgN])(Pr{Lj}) + n求和(j=2[lgN] to n)(Pr{Lj})
//                 < 2[lgN]*1 + n*(1/n) 
//                 = O(lgn)  得到长度上界
//       正面特征序列长度超过r[lgN]次抛掷的概率随着r减少而减小。 对r>=1,正面特征序列长度小于r[lgN]的概率至少是1 - 1/(n的r-1次方)
//       求补充下界：n次硬币抛掷中，最长正面序列的长度期望为Omiga(lgn).
//         把n次抛掷分为大约n/s个组，每组s次抛掷，对长度为s的特征序列。
//         如果选择s=[(lgn)/2],可以说明这些组中至少有一组可能全是正面，因而可能最长特征序列的长度至少是s=Omiga(lgn)
//         从位置i开始的都是正面的组的概率为：Pr{Ai,[(lgn)/2]} = 1/(2的[(lgn)/2]) <= 1/根号n
//         所以长度至少为[(lgn)/2]的正面特征序列不从位置i开始的概率至多为1 - 1/根号n.
//         既然[n/[(lgn)/2]]个组彼此互斥、独立的抛硬币构成，其中每个组都不是长度为[(lgn)/2]的特征序列的概率至多是：
//             (1 - 1/根号n)的[n/[(lgn)/2]]次方 <= (1 - 1/根号n)的n/([(lgn)/2]-1)次方 
//                                              <= (1 - 1/根号n)的2n/(lgn - 1)次方 
//                                              <= e的-(2n/(lgn - 1))/根号n次方
//                                               = O(1/n)
//         因此最长特征序列超过[(lgn)/2]的概率为：求和(j=[(lgn)/2] to n)(Pr{Lj}) >= 1 - O(1/n)
//         E(L) = 求和(j=0 to n)(jPr{Lj})
//              = 求和(j=0 to [(lgn)/2]-1)(jPr(Lj)) + 求和(j=[(lgn)/2] to n)(jPr{Lj})
//             >= 求和(j=0 to [(lgn)/2]-1)(0*Pr(Lj)) + 求和(j=[(lgn)/2] to n)([(lgn)/2]*Pr{Lj})
//              = [(lgn)/2]*(1 - O(1/n))
//              = Omiga(lgn)
//     也可以采用指示器随机变量来得到一个简单近似分析。
//       设Xik=I{Aik}表示对应于特征序列长度至少为k，开始于位置i的指示器随机变量。
//       定义X = 求和(i=1 to n-k+1)(Xik)
//       两边取期望并利用期望的线性性质: E[X] = E[求和(i=1 to n-k+1)(Xik)] = 求和(i=1 to n-k+1)(E[Xik]) = 求和(i=1 to n-k+1)(1/2的k次方) = (n-k+1)/2的k次方
//       通过代入不同k值，可以计算出长度为k的特征序列的数目期望。对于某个正常数c，有k=clgn
//       则E[X] = (n-clgn+1)/2的clgn次方 = (n-clgn+1)/n的c次方 = 1/n的c-1次方 - (clgn-1)/n的c次方 = theta(1/n的c-1次方)

// 5.4.4 在线雇佣问题
//   雇佣问题的变形。假设现在我们不希望面试所有的应聘者以找到最好的一个。也不希望不停地雇佣新人解雇旧人。
//   愿意雇佣接近最好的应聘者，只雇佣一次。但是必须遵守，每次面试后必须马上提供职位给应聘者，或者马上拒绝该应聘者。
//   如何在最小化面试次数和最大化雇佣应聘者之间取得平衡？
//   建模如下：面试一个应聘者之后，给每个人一个分数；令score(i)表示第i个应聘者的分数，并假设没有两个应聘者得到同样的分数。
//             在已看过j个应聘者后，知道这j个人中哪一个分数更高，但不知道剩下n-j个人中会不会有更高分数的应聘者。
//   采取策略：选择一个正整数k<n，面试然后拒绝前k个应聘者，再雇佣其后比前面的应聘者有更高分数的第一个应聘者。
//             如果最好的应聘者在前k个面试之中，那么雇佣第n个应聘者。
//   伪代码：
//   On_Line_Maximum(k,n)
//   1 bestscore = -无穷
//   2 for i=1 to k
//   3     if score(i) > bestscore
//   4        bestscore = score(i)
//   5 for i=k+1 to n
//   6     if score(i) > bestscore
//   7        return i
//   8 return n
//   对每个可能的k，我们希望确定能雇佣最好应聘者的概率，然后选择最佳的k值。暂时假定k是固定的。
//   设M(j)=max{score(i)}表示1 to j中最高分数。设S表示成功选择最好应聘者的事件，Si表示最好应聘者是第i个面试者时成功的事件。
//   既然不同Si不相交，有Pr{S} = 求和(i=1 to n)(Pr{Si})。同时，当最好应聘者是前k个应聘者中的一个时，不会成功，于是对i=1,2,...,k,有Pr{Si}=0
//   因此，Pr{S} = 求和(i=k+1 to n)(Pr{Si})
//   计算Pr{Si}。为了当第i个应聘者是最好时成功，两件事必须发生。
//   第一，最好应聘者必须在位置i，用事件Bi表示。第二，算法不能选择从k+1 to i-1中的任何一个应聘者，即score(k+1) to score(i-1)均小于M(k).
//   如果其中有大于M(k)的数，则将返回第一个大于M(k)的数的下标。用事件Oi表示从位置1 to i-1中没有任何应聘者入选的事件。事件Bi于Oi相互独立。
//   Oi仅依赖于位置1 to i-1中值的相对次序，Bi仅依赖于位置i的值是否大于所有其他位置的值。从位置1 to i-1的排序不影响位置i的值是否大于其他值，i的值也不影响前面的次序。
//   因而 Pr{Si} = 求和(i=k+1 to n)(Pr{Si}) = Pr{Bi∩Oi} = Pr{Bi}*Pr{Oi}
//   Pr{Bi} = 1/n，因为最大值等可能是n个位置中的任意一个。 若事件Oi要发生，从位置1 to i-1的最大值必须在前k个位置的一个，并且最大值等可能地在这i-1个位置中。
//   于是 Pr{Oi} = k/(i-1) , Pr{Si} = k/(n(i-1)) , Pr{S} = 求和(i=k+1 to n)(Pr{Si}) = 求和(i=k+1 to n)(k/(n(i-1))) = (k/n)*求和(i=k to n-1)(1/i)
//   用积分近似约束这个和数的上下界： 积分(k to n)(1/x)dx <= 求和(i=k to n-1)(1/i) <= 积分(k-1 to n-1)(1/x)dx
//   得到一个相当紧确的界             (k/n)(lnn - lnk)    <= 求和(i=k to n-1)(1/i) <= (k/n)(ln(n-1) - ln(k-1))
//   因为希望最大化成功的概率，所以关注如何选取k值使Pr{S}的下界最大化。(当然下界更容易最大化) 以k为变量对下界表达式求导，得：(1/n)(lnn - lnk -1) = 0
//   所以k = n/e时，概率下界最大化。因而，如果用k = n/e来实现策略，那么将以至少1/e的概率成功雇佣到最好的应聘者。

// test
// 1 一个屋子必须要多少人，才能让某人和你生日相同的概率至少为1/2？必须要多少人，才能让至少两个人生日为7月4日的概率大于1/2？
//   设事件E表示至少有一个人和我生日相同，事件E~表示没人生日与我相同，则Pr{E} = 1 - Pr{E~} > 1/2
//   设有n个人，任意一个生日与我不同的概率为364/365，则事件Pr{E~} = (364/365)的n次方
//   Pr{E} = 1 - Pr{E~} = 1 - (364/365)的n次方 > 1/2   n>=253  
//   设房间里k个人，没人生日在7.4的概率为P1 = (364/365)的k次方
//   一人生日在7.4的概率为P2 = Ck(1) * 1/365 * (364/365)的k-1次方 = k/365 * (364/365)的k-1次方
//   则至少两人生日为7.4的概率为Pr = 1 - P1 - P2 = 1 - (364-k)/365 * (364/365)的k-1次方 >= 1/2
//   所以 k >= 115

// 2 假设将球投入b个箱子里，直到某箱子里中有两个球。每次投掷都是独立的，并且每个球等可能落入任意箱子。投球次数期望为？
//   任意球，投入某个箱子的概率为1/b
//   前i-1(2<=i<=b+1)次投掷，球在不同箱子的概率为1 * b-1/b * ... * (b-i+1)/b
//   第i个球落入已有球的箱子的概率(i-1)/b
//   所以第i次达成条件的概率为: Pr{i} = (i-1)/b * 连乘(j=1 to i-1)((b-j)/b)
//   E(X) = 求和(j=2 to b+1)(i*Pr{i}) = theta(根号b)

// 3 在生日悖论的分析中，要求各人生日彼此独立是否很重要？这个问题和生日悖论有什么关系？
//   分析中选取两人一对分析是否生日为同一天，所以只需要两两独立即可。

// 4 一次聚会需要邀请多少人，才能让其中3个人生日很可能相同？
//   设一共邀请n个人，令第i,j,k个人生日相同的指示器随机变量
//      Aijk = 1  i,j,k生日相同
//             0  i,j,k生日不同
//    则Pr{Aijk} = 求和(i=1 to 365)(1/365)的3次方 = (1/365)的平方
//    三人生日相同的组数的期望为: 
//       E[A] = 求和(i=1 to n)(求和(j=i+1 to n)(求和(k=j+1 to n)(Aijk)))
//            = 求和(i=1 to n)(求和(j=i+1 to n)(求和(k=j+1 to n)(1/365)的平方))
//            = (n(n-1)(n-2))/(6*(365)的2次方)
//    令E>=1 ,n >= 94

// 5 在大小为n的集合中，一个k字符串构成一个k排列的概率是多少？这个问题和生日悖论有什么关系？
//   P = (An(k))/((n-k)! * n的k次方)

// 6 假设将n个球投入n个箱子里，其中每次投球独立，并且每个球等可能落入任何箱子。空箱子的数目期望是多少?正好有一个球的箱子的数目期望是多少？
//   设第i号箱子为空的事件为Ai，概率为Pr{Ai} = (1 - 1/n)的n次方
//   当n比较大的时候， Pr{Ai} = 1/e
//   则空箱子数量的期望为: E(A) = 求和(i=0 to n-1)(Ai)
//                              = 求和(i=0 to n-1)(1/e)
//                              = n/e
//   则有一个球的箱子的期望是: E(B) = 求和(i=0 to n)(Bi)
//                                  = 求和(i=0 to n)(1/e)
//                                  = (n+1)/e

// 7 为使特征序列长度的下界变得更精确，请说明在n次硬币的公平抛掷中，不出现比lgn - 2lglgn更长的连续正面特征序列的概率小于1/n
//   设表示从第i项开始连续出现k个正面的事件，则：
//     Pr{Ai} = (1/2)的lgn - 2lglgn次方 = (lgn)的平方/n
//   则出现比lgn - 2lglgn更长的连续正面特征序列概率：
//     Pr >= 求和(i=1 to n-(lgn - 2lglgn)+1) (Pr{Ai})
//         = 求和(i=1 to n-(lgn - 2lglgn)+1) ((lgn)的平方/n)

// h1 概率计数
//    利用一个b位计数器，一般只能计数到2的b次方-1. 而用R.Mprris概率计数法，可以计数到一个大的多的值，但是精度会有损失。
//    对i=0,1,...,2的b次方-1，令计数器值i表示ni的计数，其中ni构成了一个非负的递增序列。假设计数器初值为0，表示计数n0=0.
//    Increment运算单元工作在一个计数器上，以概率的方式包含值i。如果i=2的b次方-1，则运算单元报告溢出错误；否则，以概率1/(ni+1 - ni)把计数器加1，以概率1 - 1/(ni+1 - ni)保持计数器不变。
//    对所有i>=0,若选择ni=i，次计数器就是普通计数器。若选择ni=2的i-1次方(i>0)或ni=Fi(第i个斐波那契数),则出现更多情形。
//    假设n(2的b次方 - 1)已足够大，发生溢出错误的概率可忽略。
//  1 说明执行n次Increment操作后，计数器表示的数期望值正好是n。
//    E[Xj] = 0*P{keep} + 1*P{increases}
//          = 0*(1 - 1/(ni+1 - ni)) + 1*(ni+1 - ni)*(1/(ni+1 - ni))
//          = 1
//    执行n次后，E[X] = n
//  2 分析计数器表示的计数的方差依赖于ni序列。一个简单情形：对所有i>=0,ni=100i。在执行n次Increment操作后，请估计计数器所表示数的方差。
//    单次方差: Var[Xj] = E[Xj平方] - (E[Xj])的平方
//                      = 0*99/100 + 100平方*1/100 - 1
//                      = 99
//    整体方差为：Var[X] = Var[X1 + X2 +...+Xn] = 99n

// h2 查找一个无序数组，在一个包含n个元素的无序数组A中查找一个值x。
//    随机策略：随机挑选一个A中的下标i。如果A[i]=x则终止；否则，继续挑选A中的一个新的随机下标。
//              重复随机挑选下标，直到找到一个下标j，使A[j]=x,或者直到我们已检查了所有元素。
// 1 Random_Search实现如上策略。
//   Random_Search(x,A,n)
//   1 v = 空集
//   2 while v != n   //v的大小
//   3       i = Random(1,n)
//   4       if A[i] = x
//   5          return i
//   6       else
//   7          v = v ∩ i
//   8 return NULL
// 2 假定恰好有一个下标i使得A[i] = x.在我们找到x和Random_Search结束之前，必须挑选A下标的数目期望是？
//   伯努利试验，期望n
// 3 假设有k>=1个下标i使得A[i]=x，推广对2的解答。在找到x或Random_Search结束之前，必须挑选A的下标数目期望为？
//   期望n/k   E[X] = 求和(i=1 to n-k) (i*(1-k/n)的n-k-1次方*k/n)
// 4 假设没有下标i使得A[i]=x.在检查完A的所有元素或Random_Search结束之前，必须挑选A的下标数目期望为？
//   球箱问题，期望n(lnn + O(1))
//    现考虑一个确定性的线性查找算法，称为Deterministic_Search
//    该算法在A中顺序查找x，考虑A[1],A[2],...,A[n],直到找到A[i]=x或者到达末尾。假设输入数组的所有排列等可能。
// 5 假设恰好有一个下标i满足。Deterministic_Search平均情形的运行时间为？最坏情形运行时间为？
//   平均情形为(n+1)/2    E[T] = 求和(i=1 to n)(i*1/n)  , 最坏情形为n
// 6 假设有k>=1个下标满足，推广对5的解答。
//   平均情况为(n-k+2)/2 ,最坏情况为 n-k+1
// 7 假设没有下标满足，求平均与最坏
//   平均与最坏都为n
//    最后随机算法Scramble_Search它先将输入数组随机变换排列，然后在变换后的数组上运行Deterministic_Search算法
// 8 设k是满足A[i]=x的下标数目，请给出k=0，k=1时，最坏运行时间和运行时间期望。推广k>=1的情况。
//   情况与Deterministic_Search相同(因为考虑原数组就是随机的，再随机打乱对后续分析没有影响)



// 第二部分 排序和顺序统计量
//   这一部分介绍了几种解决如下排序问题的算法：
//   输入：一个n个数的排序
//   输出：输入序列的一个排列（重排），使得排列遵循一定规律。
//   输入序列通常是一个n元数组，尽管它可以用链表等其他方式描述。

//  数据结构
//  实际中，待排序的数很少是单独的数值，通常是称为记录的数据集的一部分。每个记录包含一个关键字（排序中要重排的值）。
//  记录的剩余部分由卫星数据组成，通常与关键字是一同存取的。实际中，当算法重排关键字时，也必须重排卫星数据。
//  如果每个记录包含大量卫星数据，通常重排指向数据的指针，可以降低数据移动量。
//  某种意义上，正是这些细节的实现将一个算法与成熟的程序区分开。一个排序算法描述确定有序次序的方法，而不管我们是在排序单独的数还是包含很多卫星数据的大记录。
//  因此，在关注排序问题时通常假定输入只是由数组成。将对数进行排序的算法与对记录进行排序的算法是对应的。

//  为什么要排序
//  有时应用本身就需要信息经过排序。
//  很多算法把排序作为关键子程序。
//  现有排序算法数量庞大，所使用的技术非常丰富。
//  可以证明排序问题的一个非平凡下界，而最佳上界与非平凡下界渐近相等，代表算法是渐近最优的。
//  排序算法会有很多工程问题。

//  排序算法
//  第2章已经介绍了两种排序算法（插入排序和递归排序）。
//    插入排序最坏情况下可以在theta(nn)时间内将n个数排好序。由于内层循环紧凑，对于小规模输入，是一种非常快的原址排序算法。
//    附：如果输入数组中仅有常数个元素需要在排序过程中存储在数组之外，则称排序算法是原址的。
//    归并排序耗时theta(nlgn)，但他使用的Merge过程不是原址的。
//  这一部分中，将介绍两种新算法，可以排序任意实数。
//    第六章介绍堆排序，是一种O(nlgn)的原址排序算法。使用了一种称为堆的重要数据结构，堆可以实现优先队列。
//    第七章介绍快速排序，是一种原址排序算法，最坏情况运行时间为theta(nn),但期望运行时间为theta(nlgn)，实际应用中它比堆排序快。代码紧凑、运行时间隐含的常数系数小，是排大数组的常用算法。
//    插入排序、归并排序、堆排序、快速排序都是比较排序算法：都是通过对元素进行比较操作来确定输入数组的有序次序。
//    第八章介绍了决策树模型，可以研究比较排序算法的性能局限性。使用决策树可以证明任意比较排序算法n个元素的最坏情况运行时间的下界为Omiga(nlgn)，从而证明堆排序和归并排序是渐近最优的比较排序算法。
//          还展示了如果通过比较操作之外的方法来获取输入序列有序次序的信息，就有可能打破Omiga(nlgn)的下界。
//             如：计数排序算法假定输入元素的值均在集合{0,1,...,k}内。通过使用数组索引作为确定相对次序的工具，计数排序可以在theta(k+n)内排好。
//                 基数排序，可以拓展计数排序的适用范围。如果有n个整数需要排序，每个整数有d为数字，每个数字有k个可能取值，则可以在theta(d(n+k))内排序。
//                 桶排序，需要了解输入数组中数据的概率分布。对于半开区间[0,1)内服从均匀分布的n个实数，桶排序平均情况运行时间为O(n)

//  顺序统计量
//  一个n个数的集合的第i个顺序统计量就是集合中第i小的数，可以通过将输入排序，取输出的第i个元素来选择第i个顺序统计量。
//   当不知道输入数据分布时，这种方法的运行时间为Omiga(nlgn)，即第八章证明的下界。
//   第九章中，展示了即使输入数据是任意实数，也可以在O(n)时间内找到第i小的元素。提出一种随机算法，伪代码紧凑，最坏运行时间为theta(nn),期望运行时间为O(n).
//             还给出一种更复杂的算法，最坏情况运行时间为O(n)

//  背景
//  据说这一部分内容不依赖高深的数学知识，但是需要稍微复杂的数学知识。
//  快速排序、桶排序、顺序统计量算法要用到概率知识以及概率分析和随机算法。
//  顺序统计量算法的最坏情况线性时间分析涉及的数学知识更为复杂。


// 6 堆排序(heapsort)
//   时间复杂度O(nlgn). 与插入排序相同，与归并排序不同的是，堆排序具有空间原址性：任何时候只需要常数个额外元素空间存储临时数据。
//   因此堆排序集合了插入排序和归并排序的优点。
//   堆排序引入了一种算法设计技巧：使用一种称为“堆”的数据结构来进行信息管理。还可以构造一种有效的优先队列。
//   “堆”源自堆排序，目前被引申为“垃圾收集存储机制”。当然本书中堆指堆排序。
// 6.1 堆
//   (二叉)堆，可以被看做近似的完全二叉树，树上每一个结点对应数组的一个元素。除了最底层外，树是完全充满的，且从左向右填充。
//   表示堆的数组A包括两个属性：A.length给出数组元素的个数，A.heap-size表示有多少个堆元素存储在该数组中。
//   即，可能有A.length个数据，但是只有A.heap-size中存放的是堆的有效元素。 0 <= A.heap-size <= A.length
//   树的根结点是A[1],给定一个结点的下标i，可以计算它的父结点、左孩子、右孩子的下标：
//       PARENT(i)  return [i/2]
//       LEFT(i)    return 2i
//       RIGHT(i)   return 2i+1
//   大多数计算机，通过将i值左移一位，得到2i。右移一位得到[i/2]。在堆排序的好的实现中，这些函数通常以宏或者内联函数实现。
//   二叉堆可以分为：最大堆、最小堆。这两种堆都要满足堆的性质，但细节定义有差异。
//         最大堆中，除了根以外的所有结点i都要满足：A[PARENT(i)] >= A[i] （某个结点值至多与其父结点一样大，因此最大元素放在根结点当中）
//         最小堆与最大堆性质相反，即A[PARENT(i)] <= A[i]
//   堆排序算法中，使用最大堆。最小堆常用于构造优先队列。 对特定应用需要明确是最大堆还是最小堆；当两个都合适时，统称堆。
//   如果将堆看出一颗树，定义一个堆中的结点高度就是该结点到叶结点最长简单路径上边的数目，进而把堆的高度定义为根结点的高度。
//   既然一个包含n个元素的堆可以看做一颗完全二叉树，那么该堆的高度为theta(lgn)
//   堆结构上的一些基本操作的运行时间至多与树的高度成正比，即时间复杂度为O(lgn)。
//         Max_Heapify:时间复杂度O(lgn),是维护最大堆性质的关键。
//         Buid_Max_Heap:线性时间复杂度，功能是从无序的输入数据数组中的构造一个最大堆。
//         Heapsort:时间复杂度为O(nlgn)，功能是对一个数组进行原址排序。
//         Max_Heap_Insert,Heap_Extract_Max,Heap_Increase_Key,Heap_Maximum:时间复杂度为O(lgn)，功能是利用堆实现一个优先队列。

// test
// 1 在高度为h的堆中，元素个数最多和最少分别为多少？
//   最多 求和(i=1 to h)  (2的i次方)     = 2的h+1次方 - 1
//   最少 求和(i=1 to h-1)(2的i次方) + 1 = 2的h次方

// 2 证明：含n个元素的堆的高度为[lgn].
//   2^h <= n <= 2^(h+1) - 1
//   两边取对数得：lgn - 1 < h <= lgn
//   so h=[lgn]

// 3 证明：在最大堆的任一子树中，该子树所包含的最大元素在该子树的根结点上。
//   A[PARENT(i)] >= A[i]对任一子树成立
//   因此父结点必然>=子结点，根结点是最终的父结点，因而最大。

// 4 假设一个最大堆的所有元素都不相同，那么该堆的最小元素应该位于哪里？
//   最小元素必然没有子节点，因而应该位于最底层，或者没有子节点的次底层

// 5 一个已经排序好的数组是一个最小堆吗？
//   顺序递增为最小堆，顺序递减为最大堆

// 6 值为{23,17,14,6,13,10,1,5,7}的数组是一个最大堆吗？
//   不是，子树中父结点A[4]=6 < A[9]=7 不符合最大堆定义

// 7 证明：当用数组表示存储n个元素的堆时，叶节点下标分别是[n/2]+1,[n/2]+2,...,n
//   最后一个元素下标为n，说明最后一个有子结点的父结点下标为[n/2]
//   因此，从最后一个父结点之后全为叶节点，其下标依次加一。

// 6.2 维护堆的性质
//   Max_Heapify是用于维护最大堆性质的重要过程。
//   它的输入为一个数组A和一个下标i。
//   在调用Max_Heapify时，假定根结点为LEFT(i)和RIGHT(i)的二叉树都是最大堆，此时A[i]可能小于子节点。
//   Max_Heapify让A[i]的值在最大堆中逐级下降，从而使下标i为根节点的子树重新遵循最大堆性质。
//   Max_Heapify(A,i)
//   1 l = LEFT(i)
//   2 r = RIGHT(i)
//   3 if l <= A.heap-size and A[l] > A[largest]
//   4    largest = l
//   5 else largest = i
//   6 if r <= A.heap-size and A[r] > A[largest]
//   7    largest = r
//   8 if largest != i
//   9    exchange A[i] with A[largest]
//   10   Max_Heapify(A,largest)
//   对一棵以i为根结点、大小为n的子树，Max_Heapify的时间代价包括：
//     调整A[i]、A[LEFT(i)]和A[RIGHT(i)]的关系的时间代价theta(1)
//     一棵以i的一个孩子为根结点的子树上运行Max_Heapify的时间代价(假设递归发生)
//   因为每个子树的大小至多为2n/3(最坏情况发生在树的最底层恰好半满时)，递归式为：T(n) <= T(2n/3) + theta(1)
//   由主定理得 T(n) = O(lgn)

// test
// 1 说明Max_Heapify(A,3)在数组A={27,17,3,16,13,10,1,5,7,12,4,8,9,0}上的操作过程
//              27              
//       17            3        // 3与1换
//   16     13      10    1     
//  5  7  12  4    8  9  0  

// 2 Max_Heapify写出能够维护相应最小堆的Min_Heapify(A,i)的伪代码，并比较Min_Heapify与Max_Heapify的运行时间。
//   Min_Heapify(A,i)
//   1 l = LEFT(i)
//   2 r = RIGHT(i)
//   3 if l <= A.heap-size and A[l] < A[min]
//   4    min = l
//   5 else min = i
//   6 if r <= A.heap-size and A[r] < A[min]
//   7    min = r
//   8 if min != i
//   9    exchange A[i] with A[min]
//   10   Max_Heapify(A,min)
//   运行时间相同T(n) = O(lgn)

// 3 当元素A[i]比其子节点值都大时，调用Max_Heapify(A,i)会有什么结果?
//   符合最大堆性质，没有变化。

// 4 当i>A.heap-size/2时，调用Max_Heapify(A,i)会有什么结果？
//   此时A[i]为叶节点，调用不产生改变。

// 5 Max_Heapify代码效率很高，但第十行的递归调用可能例外，可能使某些编译器产生低效代码。请采用循环控制结构取代递归。
//   Max_Heapify(A,i)
//   while true
//     largest = i
//     l = LEFT(i)
//     r = RIGHT(i)
//     if l <= A.heap-size and A[l] > A[i]
//        largest = l
//     if r <= A.heap-size and A[r] > A[largest]
//        largest = r
//     if largest != i
//        exchange A[i] with A[largest]
//        i = largest
//     else
//        break

// 6 证明：对一个大小为n的堆，Max_Heapify的最坏情况运行时间为Omiga(lgn).
//   提示：对于n个结点的堆，可以通过对每个结点设定恰当的值，使得从根结点到叶结点的路径上的每个结点都会递归调用Max_Heapify。
//   n个元素的堆高为[lgn],最坏情况为每层都发生调换，每次调换代价为Omiga(1).
//   因此最坏情况时间代价：[lgn]*Omiga(1) = Omiga(lgn)

// 6.3 建堆
//   可以用自底向上的方法利用过程Max_Heapify把一个大小为n=A.length的数组A[1...n]转换为最大堆。
//   由练习6.1-7知，数组A{[n/2]+1,...,n}元素都是叶节点（最底层）。每个叶节点都可以看成只包含一个元素的堆。
//   过程Build_Max_Heap对树中其他结点都调用一次Max_Heapify。
//   Build_Max_Heap(A)
//   1 A.heap-size = A.length
//   2 for i = [A.length/2] downto 1
//   3     Max_Heapify(A,i)
//   证明Build_Max_Heap的正确性：
//   在第2-3行中每一次for循环开始，结点i+1,i+2,...,n都是一个最大堆的根结点。
//   初始化：在第一次循环之前，i=[n/2],而[n/2]+1,...,n都是叶节点，因而是平凡最大堆的根结点。
//   保持：  为了每次迭代都维护这个循环不变量，注意到结点i的孩子结点的下标均比i大，所以都是最大堆的根。
//           而Max_Heapify持续维护了这一性质，为下一次循环重新建立循环不变量。
//   终止：  i=0时终止。根据循环不变量，每个结点都是一个最大堆的根，结点1就是最大的堆的根结点。
//   简单估算Build_Max_Heap的运行时间上界。每次调用Max_Heapify耗时O(lgn),调用O(n)次，因此总代价为O(nlgn).当然这个上界正确但不紧确。
//     得到更紧确的界：不同结点运行Max_Heapify的时间与该结点的树高相关，而且大部分结点高度很小。
//     性质：包含n个元素的堆的高度为[lgn],高度为h的堆最多包含[n/2^(h+1)]个结点（练习6.3-3）
//     因此，在一个高度为h的结点上运行Max_Heapify的代价是O(h),总代价：
//           求和(h=0 to [lgn])([N/2^(h+1)]O(h)) = O(n求和(h=0 to [lgn])(h/2^h)
//           求和(h=0 to 无穷)(h/2^h) = (1/2)/(1 - 1/2)^2 = 2
//           Build_Max_Heap的时间复杂度：  O(n求和(h=0 to [lgn])(h/2^h) = O(求和(h=0 to 无穷)(h/2^h)) = O(2n) = O(n)
//     因此，可以在线性时间内把一个无序数组构造成一个最大堆。 同样也可以用于构造最小堆。

// test
// 1 说明Build_Max_Heap在数组A={5,3,17,10,84,19,6,22,9}上的操作过程
//                5             // 5与84换 5与22换 5与10换
//         3            17      // 3与84换  17与19换
//      10    84     19    6    // 10与22换   
//    22  9

// 2 对于Build_Max_Heap中第二行的循环控制变量i来说，为什么要求它从[A.length]到1递减，而不是1到[A.length]递增？
//   因为如果用递增循环从下标i=1开始，那么i的两个左右子树对于任意排序的数组来说就可能出现左右子树不是最大堆的情况（使用MAX - HEAPIFY(A, i)函数必须满足左右子树是最大堆）。
//   如果用递减循环从下标i = leghth[A] / 2开始，那么根据6.1 - 7知i = leghth[A] / 2的结点是刚开始含有子结点的情况，这时，子结点所组成的树只含有1个结点，那么肯定满足最大堆的情况。

// 3 证明：对于任一包含n个元素的堆中，至多有[n/2^(h+1)]个高度为h的结点。
//   n个元素的堆，总高度为H，则2^0+2^1+...+2^h >= 2^(h+1) = n
//   当h=0(最底层结点相对于叶节点的高度为0)，有n/2^(0+1) = (2^(h+1)-1)/2 = 2^h - 1/2 [ 2^h - 1/2]=2^h正好是完全二叉树最底层结点数。
//   由于最底层可能不满，所以h=0时，至多有[n/2^(h+1)]个高度为h的结点。 即证
//   当h=k时，至多有[n/2^(k+1)]个高度为h的结点成立。
//   当h=k+1时，h=k+1的节点数正好是h=k的一半(除了h=0，其他层都满结点),有(1/2)(2^(h+1)-1)/2^(k+1)=(2^(k+1)-1)/2^(k+2)=n/2^(h+1)成立
//   所以由数学归纳法得证。

// 6.4 堆排序算法
//   初始用Build_Max_Heap将输入数组A[1...n]建成最大堆，n=A.length。因为数组中的最大元素总在根结点A[1]中，通过将它与A[n]互换，可以让该元素放在正确的位置。
//   如果通过减少A.heap-size来去掉结点n，剩余结点中，原来根结点的子节点仍然是最大堆，而新的根结点可能违背最大堆性质。
//   为了维护最大堆性质，需要调用Max_Heapify(A,1),从而在A[1...n-1]上构造一个新的最大堆。
//   堆排序算法不断重复上述过程，直到堆的大小从n-1降到2。
//   Heapsort(A)
//   1 Build_Max_Heap(A)
//   2 for i=A.length downto 2
//   3     exchange A[1] with A[i]
//   4     A.heap-size = A.heap-size - 1
//   5     Max_Heapify(A,1)
//   Heapsort算法的时间复杂度为O(nlgn) (每次调用Build_Max_Heap需要O(n),调用n-1次Max_Heapify，每次O(lgn))

// test
// 1 说明Heapsort在数组A={5,13,2,25,7,17,20,8,4}
//        5            最大堆       25               新最大堆            20
//    13      2                13       20                          13        17
//  25  7   17  20           8   7    17   2                      8   7      4   2
// 8  4                    5  4                                 5  25
//        5            新最大堆      17              新最大堆            13         
//   13      17                  13      5                          8        5
//  8   7   4  2                8  7    4 2                       2   7    4   17
// 20 25                      20 25                             20 25
//         4           新最大堆    8                 新最大堆        7  
//     8       5               7      5                          4       5
//   2   7   13 17           2   4  13 17                      2   8   13 17         
// 20 25                   20 25                             20 25
//         5           新最大堆    4                 排序完成      2
//     4        2               2      5                      4          5
//   7   8   13  17           7   8  13 17                  7   8      13  17
// 20 25                    20  25                        20  25

// 2 试分析在使用下列循环不变量时，Heapsort的正确性：
//   在算法的第2-5行for循环每次迭代开始时，子数组A[1...i]是一个包含了数组A[1...n]中第i小元素的最大堆，而子数组A[i+1...n]包含了数组A[1...n]中已排序的n-i个最大元素？
//   初始化：子数组A[i+1...n]是空的，成立。
//   维持：  A[1]是A[1...i]中最大的元素，并且小于A[i+1,,,n]中的所有元素，当与第i个元素交换，A[i...n]仍是数组中最大已排序的元素。重新建最大堆保障新的根结点是A[1...i]的最大元素。
//   终止：  当i=1时，A[2...n]已排序好，且A[1]最小

// 3 对于一个按升序排列的包含n个元素的有序数组A来说，Heapsort的时间复杂度是多少？降序呢？
//   两种情况时间复杂度都是O(nlgn)
//   升序：算法需要时间O(n)将其转换成最大堆，需要n-1次Max_heapify维护最大堆性质，每次需要lgk的复杂度，一共求和(k=1 to n-1)(lgk) = O(nlgn)
//   降序：建立最大堆的时间更短，但维护最大堆性质耗时相同。
//   Heapsort时间复杂度主要由n-1次Max_Heapify决定。

// 4 证明：最坏情况下，Heapsort的时间复杂度是Omiga(nlgn)
//   升序排列即为最坏情况，耗时分析同3。

// 5 证明：在所有元素都不同的情况下，Heapsort的时间复杂度是Omiga(nlgn)
//   使用决策树模型分析，任意元素的比较排序算法时间复杂度下限Omiga(nlgn)

// 6.5 优先队列
//   堆排序是个优秀的算法，但在实际应用中快速排序的性能一般优于堆排序。
//   尽管如此，堆这一数据结构仍有很多应用。 堆的一个常见应用：作为高效的优先队列。
//   优先队列也有两种形式：最大优先队列和最小优先队列。
//     优先队列：是一种用来维护由一组元素构成的集合S的数据结构，其中每一个元素都有一个相关值，称为关键字(key)。
//     最大优先队列支持以下操作： Insert(S,x):把元素x插入集合S。等价于S=S∪{x}
//                                Maximum(S): 返回S中具有最大关键字的元素。
//                                Extract_Max(S):去掉并返回S中具有最大关键字的元素。
//                                Increase_Key(S):将元素x的关键字值增加到k，这里假设k的值不小于x的原关键字值。
//   最大优先队列的应用：其中之一是共享计算机系统的作业调度。 最大优先队列记录将要执行的各个作业以及它们之间相对优先级。
//                       当一个作业完成或者被中断之后，调度器调用Extract_Max从所有等待作业中，选出具有最高优先级的作业来执行。
//                       在任何时候，调度器可以调用Insert把一个新的作业加入队列中。
//   最小优先队列与之类似，操作包括Insert,Minimum,Extract_Min,Decrease_Key.可以用于基于事件驱动的模拟器。
//     队列中保存要模拟的事件，每个事件都有一个发生的时间作为关键字。事件必须按照发生的时间顺序进行模拟，因为某一时间的模拟结果可能触发对其他时间的模拟。
//     每一步，模拟程序调用Extract_Min来选择下一个要模拟的事件。当新事件产生时，模拟器通过调用Insert将其插入最小优先队列。
//   显然，优先队列可以用堆来实现。优先队列的元素对应应用程序中的对象。通常，需要确定哪个对象对应一个给定的优先队列元素。
//   因此，在用堆实现优先队列时，需要在堆中的每个元素里存储对应对象的句柄(handle)(如指针、整型数，具体依赖应用程序)，通常句柄为数组下标。
//   堆维护时，也要注意维护句柄。
//   Heap_Maximum(A)
//   1 return A[1]
//   Heap_Extract_Max(A)
//   1 if A.heap-size < 1
//   2    error "heap underflow"
//   3 max = A[1]
//   4 A[1] = A[A.heap-size]
//   5 A.heap-size = A.heap-size - 1
//   6 Max-Heapify(A,1)
//   7 return max
//   Heap_Extract_Max的时间复杂度为O(lgn). 因为除了Max_Heapify是O(lgn)以外，其他都是常数阶操作
//   Heap_Increase_Key：在优先队列中，我们希望增加关键字的优先队列元素由对应的数组下标i来标识。首先需要将元素A[i]的关键字更新为新值。
//     因为增大A[i]的关键字可能会违反最大堆性质，所以采用插入循环方式，从当前结点到根结点的路径上，为新增关键字寻找恰当的插入位置。
//     在过程中，当前元素会不断与父结点进行比较，如果当前元素关键字较大，则当前元素与其父结点交换。
//     这一过程不断重复，直到当前元素关键字小于其父结点时终止。（到这一步符合了最大堆性质）
//   Heap_Increase_Key(A,i,key)
//   1 if key < A[i]
//   2    error "new key is smaller than current key"
//   3 A[i] = key
//   4 while i > 1 and A[PARENT(i)] < A[i]
//   5       exchange A[i] with A[PARENT(i)]
//   6       i = PARENT(i)
//   Max_Heap_Insert:它的输入是要被插入到最大堆A中的新元素的关键字。Max_Heap_Insert首先通过增加一个关键字为-无穷的叶节点来扩展最大维。
//   然后调用Heap_Increase_Key为新结点设置对应的关键字，同时保持最大堆的性质。
//   Max_Heap_Insert(A,key)
//   1 A.heap-size = A.heap-size + 1
//   2 A[A.heap-size] = -无穷
//   3 Heap_Increase_Key(A,A.heap-size,key)
//   在包含n个元素的堆上，Max_Heap_Insert的运行时间为O(lgn)
//   总之，在一共包含n个元素的堆中，所有优先队列的操作都可以在O(lgn)时间内完成。

// test 
// 1 说明Heap_Extract_Max在堆A={15,13,9,5,12,8,7,4,0,6,2,1}上的操作过程
//   15,13,9,5,12,8,7,4,0,6,2,1
//   1,13,9,5,12,8,7,4,0,6,2
//   13,1,9,5,12,8,7,4,0,6,2
//   13,12,9,5,1,8,7,4,0,6,2
//   13,12,9,5,6,8,7,4,0,1,2

// 2 说明Max_Heap_Insert(A,10)在堆A={15,13,9,5,12,8,7,0,6,2,1}上的操作过程
//   先在末尾插入一个-inf，再调用Heap_Increase_Key把结点值提高为要插入的key
//   15,13,9,5,12,8,7,0,6,2,1，-inf
//   15,13,9,5,12,8,7,4,0,6,2,1,10
//   15,13,9,5,12,10,7,4,0,6,2,1,8
//   15,13,10,5,12,9,7,4,0,6,2,1,8

// 3 要求用最小堆实现最小优先队列，请写出Heap_Minimum、Heap_Extract_Min、Heap_Decrease_Key和Min_Heap_Insert的伪代码
//   Heap_Minimum(A)
//   1 return A[heap-size]
 
//   Heap_Extract_Min(A)
//   1 if A.heap-size < 1
//   2    error "heap underflow"
//   3 Min = A[1]
//   4 A[1] = A[A.heap-size]
//   5 A.heap-size = A.heap-size - 1
//   6 Min-Heapify(A,1)
//   7 return min

//   Heap_Decrease_Key(A,i,key)
//   1 if key > A[i]
//   2    error "new key is smaller than current key"
//   3 A[i] = key
//   4 while i > 1 and A[PARENT(i)] > A[i]
//   5       exchange A[i] with A[PARENT(i)]
//   6       i = PARENT(i)

//   Min_Heap_Insert(A,key)
//   1 A.heap-size = A.heap-size + 1
//   2 A[A.heap-size] = -无穷
//   3 Heap_Decrease_Key(A,A.heap-size,key)

// 4 在Max_Heap_Insert的第2行，为什么要先把关键字设为-inf，然后又将其改为所需值?
//   用已有代码简化操作，否则需要反复比较来找到插入数据的位置。

// 5 试分析使用下列循环不变量，Heap_Increase_Key的正确性：
//   在算法第4-6行while循环每次迭代开始时，子数组A[1...A.heap-size]，要满足最大堆的性质。
//   如果违背，只有一种可能：A[i] > A[PARENT(i)]。 这里可以假定在调用Heap_Increase_Key时，A[1...A.heap-size]是满足最大堆性质。
//   初始化：A[i]=key，i>1循环不变式成立
//   保持：  如果迭代前循环不变式为真，那么不再进行迭代，此时保持循环不变式（即满足终止情况）。
//           或者进行A[PARENT(i)]>A[i],i=PARENT(i),此时保持了循环不变式，成立。
//   终止：  原先A[i]已经被调整到合适位置，数组满足最大堆性质。

// 6 在Heap_Increase_Key的第五行交换操作中，一般需要通过三次赋值来完成。如何利用Insertion_Sort内循环部分思想，只用一次赋值完成这一操作？
//static Increase_Priority(A, i, key)
//{
//	if (key < A[i])
//		return;
//	while (i > 1 && A[parent(i)] < key)
//	{
//		A[i] = A[parent(i)];
//		i = parent(i);
//	}
//	A[i] = key;
//}

// 7 说明如何使用优先队列来实现一个先进先出队列，以及如何使用优先队列来实现栈。
//   队列：每次插入元素的优先级都比上一元素优先级小。弹出时，先进的优先级大，先出。
//   栈：  每次插入元素的优先级都比上一元素优先级大。弹出时，后进的优先级大，先出。

// 8 Heap_Delete(A,i)操作能将结点i从堆A中删除。对于一个包含n个元素的堆，设计一个能够在O(lgn)时间内完成的Heap_Delete操作。
//   Heap_Delete(A,i)
//   1 if A[i] > A[A.heap-size]
//   2    A[i] = A[A.heap-size]
//   3    Max_Heapify(A,i)
//   4 else
//   5    Heap_Increase_Key(A,i,A[A.heap-size])
//   6 A.heap-size -= 1

// 9 设计一个时间复杂度为O(nlgk)的算法，它能够将k个有序链表合并为一个有序链表，这里n是所有输入链表包含的总的元素个数。（使用最小堆完成k路归并）
//#define Element int
//typedef struct 
//{
//	Element Data;
//	LinkNode* Next;
//}LinkNode;
//int GetLength(LinkNode* head)
//{
//	return head->Data;
//}
//void Add(LinkNode* head, Element Data)
//{
//	LinkNode* point = head;
//	for (; point->Next != NULL; point++)
//	{
//		point = point->Next;
//	}
//	LinkNode* node;
//	printf("请输入新结点数据：");
//	scanf_s("%d", &node->Data);
//	point->Next = node;
//	head->Data++;
//}
//void Delete(LinkNode* head, int index)
//{
//	if (index < 0 || index >= GetLength(head))
//	{
//		printf("请检查目录！");
//		return ;
//	}
//	LinkNode* point = head;
//	for (int i = 0; i < index; i++)
//	{
//		point = point->Next;
//	}
//	point->Data = point->Next->Data;
//	point->Next = point->Next->Next;
//	head->Data--;
//}
//void Insert(LinkNode* head, int index)
//{
//	if (index < 0 || index >= GetLength(head))
//	{
//		printf("请检查目录！");
//		return;
//	}
//	LinkNode* point = head;
//	for (int i = 0; i < index; i++)
//	{
//		point = point->Next;
//	}
//	LinkNode* node;
//	printf("请输入新结点数据：");
//	scanf_s("%d", &node->Data);
//	point->Next = node;
//	head->Data++;
//}
//int Search(LinkNode* head,Element data)
//{
//	LinkNode* point = head;
//	int index = 0;
//	while (point != NULL)
//	{
//		if (point->Data == data)
//		{
//			printf("数据:%d 位于链表的第%d位", data, index);
//			return index;
//		}
//		index++;
//		point = point->Next;
//	}
//	return -1;
//}
//int GetData(LinkNode* head, int index)
//{
//	if (index < 0 || index >= GetLength(head))
//	{
//		printf("请检查目录！");
//		return;
//	}
//	LinkNode* point = head;
//	for (int i = 0; i <= index; i++)
//	{
//		point = point->Next;
//	}
//	return point->Data;
//}
//void Traverse(LinkNode* head)
//{
//	LinkNode* point = head;
//	while (point->Next != NULL)
//	{
//		point = point->Next;
//		printf("数据为:%d ", point->Data);
//	}
//	printf("遍历完成！");
//}
//typedef struct
//{
//	int heapsize;
//	LinkNode* heap;
//}Minheap;
//int Left(int i)
//{
//	return i << 1;
//}
//int Right(int i)
//{
//	return ((i << 1) + 1);
//}
//int Parent(int i)
//{
//	return i >> 1;
//}
//
//void Min_Heapify(Minheap* A, int i)
//{
//	int smallest = i;
//	int l = Left(i + 1);
//	int r = Right(i + 1);
//	if (l <= A->heapsize && GetData(A->heap,l-1) < A->heap->Data)
//	{
//		smallest = l - 1;
//	}
//	if (r <= A->heapsize && GetData(A->heap, r - 1) < GetData(A->heap, smallest))
//	{
//		smallest = r - 1;
//	}
//	if (smallest != i)
//	{
//		Minheap* temp = A->heap[smallest];
//		A->heap[smallest] = A->heap[i];
//		A->heap[i] = temp;
//	}
//}
//void BuildMinheap(Minheap* A)
//{
//	for (int i = A->heapsize; i >= 0; i--)
//	{
//		Min_Heapify(A,i);
//	}
//}
//int GetHeapSize(Minheap* A)
//{
//	return A->heapsize;
//}
//void AlterHeapSize(Minheap* A, int i)
//{
//	A->heapsize = i;
//}
//Minheap* GetElement(Minheap* A, int i)
//{
//	return A->heap[i];
//}
//void SetElement(Minheap* A, LinkNode* key, int i)
//{
//	A->heap[i] = key;
//}
//void Swap(Minheap* A, int i, int j)
//{
//	A->heap[i], A->heap[j] = A->heap[j], A->heap[i];
//}
//LinkNode* Append(Minheap* A, LinkNode* i)
//{
//	A->heap = Append(A->heap, i);
//}
//Minheap* NewMinheap(int heapsize, LinkNode* a[])
//{
//	Minheap* minheap = Minheap{ heapsize:heapsize,heap : a };
//	minheap.BuildMinheap();
//	return minheap;
//}
//LinkNode* KMerge(LinkNode* linkedListArr[])
//{
//	l = LinkNode{ Data:0,Next : nil };
//	a = NewMinHeap(len(linkedListArr), linkedListArr);
//	while (a.GetHeapSize() > 0)
//	{
//		linkNode = a.heap[0];
//		l.Add(linkNode.Data);
//		if (linkNode.Next != NULL)
//		{
//			a.SetElement(0, linkNode.Next);
//			a.Min_Heapify(0);
//		}
//		else
//		{
//			a.heap[0], a.heap[a.GetHeapSize() - 1] = a.heap[a.GetHeapSize() - 1], a.heap[0];
//			a.AlterHeapSize(a.GetHeapSize() - 1);
//			a.MinHeapify(0);
//		}
//	}
//	return &1;
//}

// hard test
// 1 用插入的方法建堆
//   通过反复调用Max_Heap_Insert向一个堆中插入元素，用BUild_Max_Heap'如下实现方式：
//   Build_Max_Heap'(A)
//   1 A.heap-size = 1
//   2 for i=2 to A.length
//   3     Max_Heap_Insert(A,A[i])
//   a 当输入数据相同的时候，Build_Max_Heap' 和Build_Max_Heap生成的堆是否总是一样？
//     不是总一样，叶结点顺序不同。 对于一个数组A{3,2,1,4,5}运行Build_Max_Heap'时得到54123，运行Build_Max_heap时得到54132
//   b 证明：在最坏情况下，调用Build_Max_Heap'建立一个包含n个元素的堆的时间复杂度为theta(nlgn)
//     每次插入花费O(lgn),共插入n次，时间复杂度O(nlgn)。

// 2 d叉堆分析
//   d叉堆与二叉堆类似，但其中每个非叶结点有d个孩子而不仅是2个。
//   a 如何在一个数组中表示d叉堆？
//     PARENT[i] = math.Floor((i+1)/d)  child(k,i) = (i-1)*d +1+k (i代表数组第i个元素，k表示第k个子元素)
//   b 包含n个元素的d叉堆高度是多少？
//     logd(n*(d-1))
//   c 请给出Extract_Max在d叉最大堆上的一个有效实现，并用d和n表示出它的时间复杂度。
//     Extract_Max
//     1 if A.heap-siz<1 
//     2    err "heap underflow"
//     3 max = A[1]
//     4 A[1] = A[heap-size]
//     5 A.heap-size--
//     6 Dmax_Heapify(A,1)
//     Dmax_Heapify(A,i)
//     1 largest = i
//     2 for k=1 to A.heapsize
//     3     if child(k,i)<= A.heap-size and A[child(k,i)] > A[i]
//     4        largest = child(k,i)
//     5 if largest != i 
//     6    exchange A[i] with A[largest]
//     7    Dmax_Heapify(A,largest)
//     时间复杂度为dlogd(n)
//   d 给出Insert在d叉最大堆上的一个实现，并用d和n表示出它的时间复杂度。
//     Insert
//     1 A.heap-size++
//     2 A[A.heap-size] = key
//     3 i = A.heap-size
//     4 while i>1 and A[PARENT(i)]<A[i]
//     5       exchange A[i] with A[PARENT(i)]
//     6       i = PARENT(i)
//     时间复杂度为O(logd(n))
//   e 给出Increase_Key(A,i,k)的一个有效实现，并用d和n表示出它的时间复杂度。
//     否则执行A[i]=k，并更新相应的d叉最大堆，并用d和n表示它的时间复杂度。
//     Increase_Key(A,i,k)
//     1 if key<A[i]
//     2    err"new key is smaller than current key"
//     3 A[i] = key
//     4 while i>1 and A[PARENT(i)]<A[i]
//     5       exchange A[i] with A[PARENT(i)]
//     6       i = PARENT(i)
//     时间复杂度为O(logd(n))

// 3 Young氏矩阵 
//   在一个mxn的Young氏矩阵中，每一行数据都是从左向右排序的，每一列数据都是从上到下排序的。Young氏矩阵中也会存在一些值为inf的数据项表示不存在的数。
//   因此Young tableau可以用来存储r<=mn个有限数。
//   a 画出一个包含元素为{9,16,3,2,4,8,5,14,12}的4x4 Young tableau
//     2   4   12  14
//     3   5   16  inf
//     8   9   inf inf
//     inf inf inf inf
//   b 对于一个mxn的Young tableau Y来说，请证明：如果Y[1,1]=inf,则Y为空；如果Y[m,n]<inf,则Y为满。
//     先给出Young tableau的性质1：对于矩阵中的任意一个元素Y[i,j],如果i'<=i且j'<=j，那么一定有Y[i',j']<=Y[i,j].
//     证明：同一行中，左边元素不大于右边元素，所以有Y[i',j'] <= Y[i',j].
//           同一列中，上边元素不大于下边元素，所以有Y[i',j]  <= Y[i,j]
//           综上，Y[i',j']<=Y[i,j]
//     类似的，有性质2：对于矩阵中的任意一个元素Y[i,j],如果i'>=i且j'>=j ,那么一定有Y[i',j']>=Y[i,j]
//     证明原题：
//         根据性质1、2，Y[1,1]是Young tableau中最小的元素，因为Y[1,1]=inf ，所以全部元素都为inf，所以数组为空。
//                       Y[m,n]是Young tableau中最大的元素，Y[m,n]<inf，所以全部元素<inf，所以数组为满。
//   c 请给出一个在mxn Young tableau上时间复杂度为O(m+n)的Extract_Min的算法实现。
//     可以考虑使用一个递归过程，将规模为mxn的问题分解为(m-1)xn 或mx(n-1)的子问题(考虑使用Max_Heapify)
//     定义T(p)用来表示Extract_Min在任意mxn的Young tableau上的时间复杂度，其中p=m+n.给出并求解T(p)的递归表达式，其结果为O(m+n)
//     Young_Matrix_Extract_Min(Y)
//     1 m = Y.rows
//     2 n = Y.columns
//     3 if m<1 or n<1
//     4    error "Young Matrix underflow"
//     5 min = Y[1,1]
//     6 if min=inf
//     7    error "Young Matrix empty"
//     8 Y[1,1] = inf
//     9 i = 1
//    10 j = 1
//    11 while true
//    12       if i<m
//    13          smallest = BOTTOM
//    14          if j<n && Y[i,j+1]<Y[i+1,j]
//    15             smallest = RIGHT
//    16          else if j<n
//    17               smallest = RIGHT
//    18          else
//    19                break
//    20          if smallest=BOTTOM && Y[i+1,j]<Y[i,j]
//    21             exchange Y[i,j] with Y[i+1,j]
//    22             i=i+1
//    23           else if smallest=BOTTOM && Y[i,j+1]<Y[i,j]
//    24             exchange Y[i,j] with Y[i,j+1]
//    25             j=j+1
//    26           else
//    27             break
//    28 return min
//    while迭代中，要么i+1，要么j+1，最多加到m、n因此迭代最多m+n次，因此时间复杂度为O(m+n)
//   d 试说明如何在O(m+n)时间内，将一个新元素插入到一个未满的mxn的Young tablau中。
//     Young_Matrix_Insert(Y,key)
//     1 m = Y.rows
//     2 n = Y.columns
//     3 if m<1 or n<1
//     4    error "Young Matrix underflow"
//     5 if Y[m,n]<inf
//     6    error "Young Matrix full"
//     7 Y[m,n] = key
//     8 i = m
//     9 j = n
//    10 while ture
//    11       if i>1
//    12          largest = TOP
//    13          if j>1 && Y[i,j-1]>Y[i-1,j]
//    14             largest = LEFT
//    15       else if j>1
//    16          largest = LEFT
//    17       else
//    18          break
//    19       if largest=TOP && Y[i-1,j]>Y[i,j]
//    20          exchange Y[i,j] with Y[i-1,j]
//    21          i--
//    22       else if largest=LEFT && Y[i,j-1]>Y[i,j]
//    23          exchange Y[i,j] with Y[i,j-1]
//    24          j--
//    25       else
//    26          break
//   e 在不用其他排序算法的情况下，试说明如何利用一个nxn的Young tableau在O(nnn)时间内将nn个数进行排序。
//     建立一个nxn的Young tableau，用Insert将每一个元素依次插入矩阵。每次插入耗时O(n+n)=O(n),nn个元素耗时nnO(n)=O(nnn)
//     再调用Extract_Min依次取出最小元素即可完成排序，这一步花费O(nnn)
//     总共花费O(nnn)
//   f 设计一个时间复杂度为O(m+n)的算法，可以判断一个给定的数是否存储再mxn的Young tableau中
//     Young_Matrix_Search(Y,key)
//     1 m = Y,rows
//     2 n = Y.columns
//     3 i = m
//     4 j = 1
//     5 while i>=1 && j<=n
//     6       if key > Y[i,j]
//     7          j++
//     8       else if key<Y[i,j]
//     9          i--
//    10       else
//    11          print "x is at (i,j)"
//    12          return
//    13 print "x is not in Y"
//    时间复杂度为O(m+n)


// 7 快速排序
//   对于包含n个数的输入数组来说，快速排序是一种最坏情况时间复杂度为theta(nn)的排序算法，但是是实际应用中最好的选择，因为平均性能很好。
//   其期望时间复杂度theta(nlgn),且隐含的常数因子非常小。还能进行原址排序，甚至在虚存环境中也能很好工作。
//   接下来介绍快速排序算法及其重要的划分子程序，对性能进行讨论，给出一个基于随机抽样的快速排序算法，最坏theta(nn)、元素互异时期望时间复杂度O(nlgn)

// 7.1 快速排序的描述
//   与归并排序一样，采取分治思想。下面对一个典型子数组A[p...r]进行快速排序的三步分治过程：
//     分解：数组A[p...r]被划分为两个（可能为空）子数组A[p...q-1]和A[q+1...r]，使得A[p...q-1]中的每一个元素都<=A[q]。
//           而A[q]<=A[q+1...r]中的每一个元素。其中下标q也是划分过程的一部分。
//     解决：通过调用快速排序，对子数组A[p...q-1]和A[q+1...r]进行排序
//     合并：因为子数组都是原址排序，所以不需要进行合并：数组A[p...r]已经有序。
//    Quicksort(A,p,r)
//    1 if p < r
//    2    q = Partition(A,p,r)
//    3    Quicksort(A,p,q-1)
//    4    Quicksort(A,q+1,r)
//    数组划分（Partition）
//      算法关键部分是Partition过程，实现了对子数组A[p...r]的原址重排。
//      Partition(A,p,r)
//      1 x = A[r]
//      2 i = p-1
//      3 for j=p to r-1
//      4     if A[j] <= x
//      5        i++
//      6        exchange A[i] with A[j]
//      7 exchange A[i+1] with A[r]
//      8 return i+1
//      Partition总是选择一个x=A[r]作为主元，并围绕它来划分子数组A[p...r]
//      随着程序执行，数组被划分成4个(可能有空的)区域。for循环每一轮迭代开始，每一个区域都符合一定性质。
//      将这些性质作为循环不变量：
//        在3-6行每一轮迭代开始时，对于任意数组下标k，有：
//        1 若p   <= k <=i，   则A[k] <= x
//        2 若i+1 <= k <= j-1，则A[k] >x
//        3 若k    = r，       则A[k] = x
//        但上述情况没有覆盖到下标j to r-1，对应位置的值与主元之间也不存在特定大小关系。
//      证明循环不变式：
//        初始化：在第一轮循环开始之前，i=p-1 j=p。因为在p和i之间、i+1和j-1之间都不存在值，所以循环不变量的前两个条件显然都满足。第一行赋值操作满足条件3。
//        保持：  当A[j]>x时，循环体唯一操作是j+1.j增加后，对A[j-1],条件2成立，且其他项保持不变。
//                当A[j]<=x时，将i+1，交换A[i]和A[j]，再将j+1。因为进行了交换，现有A[i]<=x,条件1成立。
//                类似的，能得到A[j-1]>x。根据循环不变量，被交换进A[j-1]的值总是大于x。
//        终止：  终止时，j=r。于是，数组中的每个元素都必然输入循环不变量所描述的三个集合中的一个：包含了所有小于等于x的元素集合、包含所有大于x的元素集合和只有一个元素x的集合。
//      Partition的最后两行中，通过将主元与最左的大于x的元素进行交换，就可以将主元移到它在数组的正确位置上，并返回主元新下标。
//      此时，Partition的输出满足划分步骤规定的条件。实际上，执行完Quicksort的第2行之后，A[q]严格小于A[q+1..r]内的每一个元素。
//      Partition在子数组A[p...r]上时间复杂度时theta(n),其中n = r-p+1

// test
// 1 说明Partition在数组A={13,19,9,5,12,8,7,4,21,2,6,11}上的操作过程
//   13，19，9，5，12，8，7，4，21，2，6，11
//   9，19，13，5，12，8，7，4，21，2，6，11
//   9，5，13，19，12，8，7，4，21，2，6，11
//   9，5，8，19，12，13，7，4，21，2，6，11
//   9，5，8，7，12，13，19，4，21，2，6，11
//   9，5，8，7，4，13，19，12，21，2，6，11
//   9，5，8，7，4，2，19，12，21，13，6，11
//   9，5，8，7，4，2，6，12，21，13，19，11
//   9，5，8，7，4，2，6，11，21，13，19，12

// 2 当数组A[p...r]中的元素都相同时，Partition返回的q值是什么？
//   修改Partition，使得当数组A[p...r]中所有元素值都相同时，q=[(p+r)/2]
//   当元素相同时，q=i+1=r-1+1=r
//void swap(int x, int y)
//{
//	int temp = x;
//	x = y;
//	y = temp;
//}
//int Pratition(int A[], int p, int r)
//{
//	int x = A[r];
//	int i = p - 1;
//	int flag = 1;
//	for (int j = p; j < r - 1; j++)
//	{
//		if (x >= A[i] && flag > 0)
//		{
//			i++;
//			swap(A[i], A[j]);
//		}
//		if (x == A[i])
//		{
//			flag = -flag;
//		}
//	}
//	swap(A[i + 1], A[r]);
//	return i + 1;
//}

// 3 简要证明：在规模为n的子数组上，Partition的时间复杂度为theta(n).
//   主要时间代价为for循环，循环p-r次，O(p-r)=O(n)

// 4 如何修改Quicksort，使得它能够以非递增序进行排序。
//   仅需把x>=A[i] 改为 x<=A[i]

// 7.2 快速排序的性能
//   快速排序运行时间依赖于划分是否平衡，平衡依赖于用于划分的元素。如果划分平衡，则性能与归并排序一样；如果不平衡，则性能接近插入排序。
//   最坏情况划分：当划分产生两个子问题分布包含了n-1个元素和0个元素。
//       假设每次划分都产生最坏情况，划分操作时间复杂度为theta(n).
//       由于对一个大小为0的数组进行递归调用会直接返回，因此T(0)=theta(1).
//       算法运行时间递归式为：T(n)=T(n-1)+T(0)+theta(n)=T(n-1)+theta(n)
//       直观上每层递归代价可以累加，得到算术级数，结果为theta(nn)。实际上，利用代入法可以直接得到递归式T(n)=T(n-1)+theta(n)得解T(n)=theta(nn)。
//       此外，当输入数组已经有序时，快速排序时间复杂度仍为theta(nn),而插入排序为O(n)
//   最好情况划分：两个子问题规模都不大于n/2。其中一个子问题为[n/2]，另一子问题为[n/2]-1。
//       算法运行时间递归式为：T(n)=2T(n/2)+theta(n)
//       根据主定理，解得T(n)=theta(nlgn)
//   平衡的划分
//       快速排序的平均运行时间更接近于最好情况。
//       假设划分算法总是产生9：1的划分，时间复杂度递归式为T(n)=T(9n/10)+T(n/10)+cn
//       对应递归树中，每层代价都是cn，直到深度log10(n)=theta(lgn)处到达递归边界条件为止，之后每层代价至多为cn，递归在深度为log10/9(n)=theta(lgn)处终止。
//       直观上不平衡，但运行时间为O(nlgn)。事实上，只要划分是常数比例，算法运行时间总是O(nlgn)
//   对于平均情况的直观观察
//       为了对快速排序的各种随机情况有一个清楚的认识，需要对遇到各种输入的出现频率做出假设。
//       快速排序的行为依赖于输入数组中元素的值的相对位置。这里假设所有排列等概率出现。
//       当对一个随机输入的数组运行快速排序时，每层都有同样的划分不太可能。预期某些划分平衡而某些不平衡。
//       平均情况下，Partition所产生的划分同时混合好差。好的情况为最好情况，差的情况为最坏情况，假设两种交替出现。
//       根结点处，划分代价为n，划分产生最坏情况。下一层上，出现最好情况。假设大小为0的子数组边界条件代价为1.
//       差划分后接好划分，产生三个子数组，大小分别为0、（n-1)/2-1、(n-1)/2，其划分代价为theta(n)+theta(n-1)=theta(n)
//       直观上上看，差划分的代价被吸收到好划分的代价中。因此好坏交替出现时，代价和全好的一样，仍为O(nlgn)。区别只是隐含的常数因子不同。

// test
// 1 利用代入法证明：递归式T(n)=T(n-1)+theta(n)
//   假设T(n) = theta(nn)  T(n) <= cnn
//   T(n) = T(n-1) + theta(n)
//        = c(n-1)~2 + n
//        = cnn -(2c-1)n + c
//       <= cnn

// 2 当数组A的所有元素都具有相同值时，Quicksort的时间复杂度是？
//   O(nn)

// 3 证明：当数组A包含不同元素、且按降序排序时，Quicksort的运行时间是theta(nn)
//   当元素不同且降序排序时，每次划分取主元为最小，每次划分都是不平衡划分，因此运行时间是theta(nn)

// 4 银行一般会按交易时间记录某一账户的交易情况。但是很多人喜欢收到银行对账单是按支票号码排序。
//   将按交易时间排序的序列转换成按支票号排序，实质是对几乎有序的输入序列进行排序的问题。请证明：这个问题上Insertion_Sort性能往往优于Quicksort。
//   对于一个已经排好序的数组，Quicksort运行时间为theta(nn).插入排序在有序情况下只需要比较n-1次。因而插入排序往往更优。

// 5 假设快速排序的每一层所作划分比例都是1-a:a，其中0<a<=1/2且是一个常数。
//   试证明：相应递归树中，叶结点的最小深度大约是-lgn/lga，最大深度约是-lgn/lg(1-a)不考虑取整.
//   最小深度：设最大深度为m，每次向a分割方向下降，m次划分后仅剩一个元素n*a~m=1,a~m=1/n,两边取对数mlga=lg1-lgn,m=-lgn/lga
//   最大深度：同理n*((1-a)~m)=1,(1-a)~m=1/n，两边取对数，mlg(1-a)=-lgn,m=-lgn/lg(1-a)

// 7.3 快速排序的随机化版本
//   打破所有输入等可能出现的假设，引入随机性。采用随机抽样的技术，将分析简化。
//   随机抽样从子数组中随机选出一个元素作为主元。先将A[r]与A[p...r]中一个随机元素交换。
//   期望在平均情况下，对输入数组的划分比较均衡。
//   Randomized_Partition(A,p,r)
//   1 i = Random(p,r)
//   2 exchange A[r] with A[i]
//   3 return Partition(A,p,r)
//   Randomized_Quicksort(A,p,r)
//   1 if p<r
//   2    q = Randomized_Partiton(A,p,r)
//   3    Randomized_Quicksort(A,p,q-1)
//   4    Randomized_Quicksort(A,q+1,r)

// test
// 1 为什么分析随机化算法的期望运行时间，而不是其最坏运行时间呢？
//   因为它代表的时间成本更为典型。（最坏运行时间出现概率小）

// 2 在Randomized_Quicksort的运行过程中，在最坏情况下，随机数生成器Random被调用了多少次？最好情况呢？
//   T(n) = T(n-1) + 1 = theta(n)

// 7.4 快速排序分析
//   给出快速排序的更严谨证明
// 7.4.1 最坏情况分析
//   最坏情况下，快速排序每一层递归的时间复杂度为theta(nn)
//   利用代入法，假设T(n)是最坏情况下Quicksort在输入规模为n的数据集合上所花费的时间，有递归式：
//       T(n) = max(0<=1<=n-1)(T(q)+T(n-q-1)) + theta(n)
//   因为Partition函数生成的两个子问题的规模总和为n-1，所以参数q的变化范围是0到n-1.
//   不妨猜测T(n)<=cnn成立，其中c为常数。将此式代入递归式，得：
//   T(n) <= max(0<=1<=n-1)(cqq + c(n-q-1)~2) + theta(n)
//         = c*max(0<=q<=n-1)(qq + (n-q-1)~2) + theta(n)
//        <= c*(nn - 2n + 1) + theta(n)
//         = cnn - c(2n-1)n + theta(n)
//        <= theta(cnn)
//   选择一个足够大的常数c，使得c(2n-1)显著大于theta(n),有T(n) = O(nn)
// 7.4.2 期望运行时间
//   Randomized_Quicksort将任意比例元素划分到一个子数组中，算法递归树深度为theta(lgn)，每层代价为O(n)，总运行时间为O(nlgn).
//   运行时间和比较操作
//     Quicksort，Randomized_Quicksort除了如何选择主元元素以外，其他方面完全相同。
//     Quicksort的运行时间由Partition操作决定。每次Partition调用选择一个主元元素，且该元素不会被包含在后续的操作调用。因此Partition至多调用n次。
//     调用一次Partition的时间为O(1)加上循环用时，这段用时与3-6行for循环迭代次数成正比。每次迭代都需要进行第4行的比较操作。因此只需统计比较次数就能得到for循环耗时。
//   引理7.1 当在一个包含n个元素的数组上运行Quicksort时，假设在Partition的第4行中所作比较的次数为X，那么Quicksort的运行时间为O(n+X).
//   证明：为了了解算法什么时候对数组中的两个元素进行比较，什么时候不比较。将元素重新命名为z1,z2,...,zn,其中zi是数组A中第i小的元素。
//         此外，定义Zij={zi,z(i+1),...,zj}为zi与zj之间的元素集合。
//         算法算法什么时候会比较zi和zj呢？ 首先，每一对元素至多比较一次。因为各元素只与主元元素比较一次，且Partition调用结束后，该主元元素再也不和其他元素比较。
//         用到指示器随机变量Xij = I{zi与zj进行比较} 其中考虑比较操作是否在算法执行过程中任意时间发生，而不是局限在一次迭代或对Partition的一次调用中发生。
//         因为一对元素最多比较一次，所以总比较次数X = 求和(i=1 to n-1)(求和(j=i+1 to n)(Xij))
//         两边取期望，E(X) = E(求和(i=1 to n-1)(求和(j=i+1 to n)(Xij))) = 求和(i=1 to n-1)(求和(j=i+1 to n)(Pr(zi与zj比较)))
//         对Pr，假设Randomized_partition随机且独立选择主元。
//         考虑两个元素何时不会进行比较。对于一个输入，假设第一个主元是zk（i<k<j），则以zk为界分成两组（其中每个元素都与zk比较），而前一个组的永远不会和后一个组的元素比较。
//         假设每个元素互异，一旦一个满足zi<zk<zj的主元zk被选取后，zi和zj就再也不会被比较了。因此zi和zj进行比较，当且仅当其中一个被第一个选为主元。
//         在zij中的某个元素被选为主元之前，整个集合zij的元素都属于某一划分的同一分区。因此，zij中任何元素都会等可能被首先选为主元。
//         因为zij中有j-i+1个元素，并且主元选择随机且独立，所以任何元素被首先选为主元的概率是1/(j-i+1). 
//         Pr{zi与zj进行比较} = Pr{zi或zj是集合zij中选出的第一个主元}
//                            = Pr{zi是集合zij中选出的第一个主元} + Pr{zj是集合zij中选出的第一个主元}
//                            = 1/(j-i+1) + 1/(j-i+1)
//                            = 2/(j-i+1)
//         综上，E[X] = 求和(i=1 to n-1)(求和(j=i+1 to n)(2/(j-i+1)))
//                    < 求和(i=1 to n-1)(求和(k=1 to n)(2/k)))
//                    = 求和(i=1 to n-1)(O(lgn))
//                    = O(nlgn)
//    于是，使用Randomized_Partition，在输入元素互异情况下，快速排序算法的期望运行时间为O(nlgn)

// test
// 1 证明：在递归式T(n) = max(0<=q<=n-1)(T(q) + T(n-q-1)) + theta(n)中,T(n)=Omiga(nn)
//   设theta(n) = cn   猜测T(n)>=cnn成立
//   当q=0或q=n-1时，取最大值T(n) >= c(n-1)~2 + theta(n) >= cnn - (2c-1)n + c >= cnn (when c<=1/2)
//   即证T(n)=Omiga(nn)

// 2 证明，在最好情况下，快速排序的运行时间为Omiga(nlgn)
//   最好情况下，子数组二分，有递归式T(n) = 2T(n/2) + theta(n)
//   由主定理得，a=2,b=2,n的logb(a)次方=n=f(n)，所以T(n)=theta(nlgn)=Omiga(nlgn)

// 3 证明：在q=0,1,...,n-1区间内，当q=0或q=n-1时，qq+(n-q-1)~2取得最大值。
//   设y = qq+(n-q-1)~2 = 2(q - (n-1)/2)~2 + ((n-1)~2)/2
//   y为开口向上，对称轴为(n-1)/2的抛物线函数
//   所以当q=0=n-1时取最大值

// 4 证明：Randomized_Quicksort期望运行时间为Omiga(nlgn)
//   普通快排与随机快排只有主元选择上的不同。
//   普通快排在均分情况下达到最好情况，时间复杂度为Omiga(nlgn).
//   随机快排在随机到均分情况下达到最好情况，时间复杂度也为Omiga(nlgn).

// 5 当输入数据几乎有序时，插入排序速度很快。在实际应用中，可以利用这一点提高快速排序的速度。
//   当对一个长度小于k的子数组快速排序时，让它不做排序就返回。当上层快排调用返回后，对整个数组运行插入排序来完成排序。
//   试证明：这一排序算法的期望时间复杂度为O(nk+nlg(n/k))。应该如何选择k？
//   E[Xij] = E(求和(i=k+1 to n)(求和(j=i+k+1 to n)(2/(j-i+1))))
//          = 求和(i=k+1 to n)(求和(m=k-1 to n-i)(2/(m+1)))   (when m=j-i)
//         <= 2求和(i=k+1 to n)(lg(n-i+1) - lg(k-2+1))
//         <= 2求和(i=k+1 to n)(lg(n-i+1/k-1))
//         <= 2求和(i=k+1 to n)(lg(n-k/k-1))
//   所以n-k/k-1 > 1,k < (n+1)/2， 若k>根号n,有n-k/k-1 < n/k
//   E[Xij] <= 2求和(i=k+1 to n)(lg(n-k/k-1))
//          <= 2求和(i=k+1 to n)(lg(n/k))
//           = 2(n-k)lg(n/k)
//   插入排序对长度为k的n/k个已排好序的子数组，每个子数组时间复杂度O(kk),n/k个，总共时间复杂度为O(kk*n/k)=O(kn)
//   快排+插入排序的总时间复杂度O(kn+nlg(n/k))，即证。
//   实践中，k越小，快排时间越长、插排时间越短，快排增加的时间远不及插排减少的时间，因此k值尽可能小，又k属于(根号n,(n+1)/2)，所以k值应趋近于根号n。

// 6 考虑对Partition做这样的修改：从数组A中随机选出3个元素，并用这三个元素的中位数对数组进行划分。
//   求以a的函数形式表示的、最坏划分比例为a:1-a的近似概率，其中0<a<1。
//   0到n-1上的元素等可能做主元，符合均匀分布。
//   设x为数组前半部分元素个数，y为数组后半部分元素个数
//   1<a<1/2时，a<1-a  P{x<a} + P{x>1-a} + P{a<x<a-1} = 1
//              而x<a ∪ x>1-a时，划分情况更糟，其概率为P{x<a∪x>1-a} = P{x<a} + P{x>1-a} = 1 - P{a<x<1-a} = 1 - (1-2a) = 2a
//   1/2<a<1时，x>a ∪ x<1-a情况更糟，概率为P{x>a ∪ x<1-a} = P{x>a} + P{x<1-a} = 1 - P{1-a<x<a} = 2-2a 

// 8 线性时间排序
//   之前的排序算法，各元素最终次序依赖于它们之间的比较。这类排序称为比较排序。
//   比较排序在最坏情况都要经过Omiga(nlgn)次比较。
//   这一规律不适用于线性时间排序
// 8.1 排序算法的下界
//   比较排序算法中，只使用比较来获得输入序列中元素的次序信息，不能用其他方法观察元素的值或次序信息。
// 8.1.1 决策树模型
//   比较排序可以抽象为一棵决策树。决策树是完全二叉树，可以表示在给定输入规模下，某一特定排序算法对所有元素的比较操作。
//   在决策树中，每个内部结点都以i:j标记(1<=i,j<=n)，叶节点上都标注一个序列<pie(1),pie(2),...,pie(n)>，排序算法的执行对应于一条从树的根结点到叶节点的路径。
//   左子树表示一旦确定ai<=aj之后的后续比较，右子树表示确定ai>aj之后的后续比较。当到达一个叶节点时，表示排序算法已经确定了一个顺序。
//   对一个正确的比较排序算法来说，n个元素的n！种可能都应该出现在决策树的叶节点上。
//   每一个叶节点都必须是可以从根结点经由某条路径到达的对应于比较排序的一次实际执行过程（称这种叶节点为可达的）
// 8.1.2 最坏情况的下界
//   决策树中，从根结点到任意一个可达的叶节点之间的最长简单路径的长度，表示对应排序算法中最坏情况下的比较次数。
//   一个比较排序算法中的最坏情况比较次数就等于其决策树的高度。
//   当决策树中每种排列都是以可达的叶节点形式出现时，该决策树的下界就是比较排序算法运行时间的下界。
// 8.1.3 定理8.1 
//   最坏情况下，任何比较排序算法都需要做Omiga(nlgn)次比较。
//   证明：根据前面的讨论，对于一棵每个排列都是一个可达的叶节点的决策树来说，树的高度完全可以被确定。
//         考虑一棵高度为h、具有l个可达叶节点的决策树，对应于一个对n个元素所做的比较排序。
//         因为输入数据的n！种可能的排列都是叶节点，所以有n!<=l。由于在一棵高为h的二叉树，叶节点数不多于2~h，有n!<=l<=2~h
//         两边取对数，有 h >= lg(n!) = nlgn + nlg(n-1) +...+ nlg1 = Omiga(nlgn)
// 8.1.4 推论8.2 
//   堆排序和归并排序都是渐近最优的比较排序算法。
//   证明：堆排序和归并排序的运行时间上界为O(nlgn),与定理8.1给出的最坏情况下界Omiga(nlgn)一致。

// test
// 1 在一棵比较排序算法的决策树中，一个叶节点可能的最小深度是多少？
//   数组本身有序，不需要进行排序，此时为最小深度，比较n-1次，深度为n.

// 2 不用斯特林近似公式，给出lg(n!)的渐近紧确界。利用A.2节中介绍的技术来求累加和: 求和(k=1 to n)(lgk)
//   lg(n!) = 求和(k=1 to n)(lgk)
//          = 求和(k=1 to n/2)(lgk) + 求和(k=(n/2)+1 to n)(lgk)
//         <= 求和(k=1 to n/2)(lg(n/2)) + 求和(k=(n/2)+1 to n)(lgn)
//          = (n/2)*lg(n/2) + nlgn
//          = O(nlgn)
//   lg(n!) = 求和(k=1 to n)(lgk)
//          = 求和(k=1 to n/2)(lgk) + 求和(k=(n/2)+1 to n)(lgk)
//         >= 求和(k=1 to n/2)(lg2) + 求和(k=(n/2)+1 to n)(lg(n/2))
//          = (n/2)lg2 + (n/2)*lg(n/2)

// 3 证明：对n！种长度为n的输入中的至少一半，不存在能达到线性运行时间的比较排序算法。如果只要求对1/n的输入到达线性时间呢？1/2~n呢？
//   由定理8.1，比较算法时间复杂度下界为Omiga(nlgn),是非线性的，无法达到线性时间。（似乎与test1矛盾）

// 4 假设现有一个包含n个元素的待排序序列。该序列由n/k个子序列组成，每个子序列包含k个元素。
//   一个给定子序列中的每个元素都小于其后继子序列中的所有元素，且大于其前驱子序列中的每个元素。
//   因此，对于这个长度为n的序列的排序转化为对n/k个子序列中的k个元素的排序。
//   试证明：这个排序问题中所需比较次数的下界是Omiga(nlgk).
//   简单合并下界（前提是独立对每个子序列进行排序）：共有n/k个子序列，单个子序列比较次数为Omiga(klgk),共需Omiga(nlgk)次。
//   考察整个序列：每个子序列有k！种可能排列，一共有n/k个子序列，那么整个序列有（k!）~(n/k)种可能排列。
//                 假设决策树高为h，满足2~h >= （k!）~(n/k)  得h >= lg(（k!）~(n/k)) = (n/k)*lg(k!) = Omiga(nlgk)

// 8.2 计数排序
//   假设n个输入元素中的每一个输入元素都是0到k区间内的一个整数，其中k为某个整数。当k=O(n)时，排序的运行时间为theta(n).
//   计数排序基本思想是：对每一个输入元素x，确定小于x的元素个数。可以之间把x放到它在输出数组中的位置上。（当有几个元素相同时，需要略作修改）
//   该算法需要输入数组A[1...n],输出数组B[1...n],临时存储空间C[0...k]
//   Counting_Sort(A,B,k)
//   1 ket C[0...k] be a new array
//   2 for i=0 to k
//   3     C[i] = 0
//   4 for j=1 to A.length
//   5     C[A[j]] = C[A[j]] + 1  // C[i]存放等于i的元素个数
//   6 for i=1 to k
//   7     C[i] = C[i] + C[i-1]   // C[i]存放小于等于i的元素个数
//   8 for j=A.length downto 1
//   9     B[C[A[j]]] = A[j]
//  10     C[A[j]] = C[A[j]] - 1  // 当出现相同元素时，第一个放在预定位置上，下一个放在它的前一位
//   2-3for花费theta(k)，4-5for花费theta(n)，6-7for花费tehta(k)，8-10for花费theta(n)。总时间代价theta(k+n)，当k=O(n)时，采用计数排序，运行时间为theta(n).
//   计数排序的下界优于Omiga(nlgn)，不同于比较排序，它采用输入元素实际值来确定其位置。
//   计数排序另一重要性质就是它是稳定的：具体相同值的元素在输出数组中的相对次序与它们在输入数组中的相对次序相同。
//           也就是说，对两个相同元素，在输入数组中先出现的在输出数组中也先出现。通常，这种稳定性只有当排序的数据附带卫星数据时才比较重要。因此基数排序可以做基数排序的子过程。

// test
// 1 说明Counting_Sort在数组A={6,0,2,0,1,3,4,6,1,3,2}上的操作过程。
//   C={2,2,2,2,1,0,2}
//   C={2,4,6,8,9,9,11}
//   B={0,0,0,0,0,2,0,0,0,0,0}  C={2,4,5,8,9,9,11}
//   B={0,0,0,0,0,2,0,3,0,0,0}  C={2,4,5,7,9,9,11}
//   B={0,0,0,1,0,2,0,3,0,0,0}  C={2,3,5,7,9,9,11}
//   B={0,0,0,1,0,2,0,3,0,0,6}  C={2,3,5,7,9,9,10}
//   B={0,0,0,1,0,2,0,3,4,0,6}  C={2,3,5,7,8,9,10}
//   B={0,0,0,1,0,2,3,3,4,0,6}  C={2,3,5,6,8,9,10}
//   B={0,0,1,1,0,2,3,3,4,0,6}  C={2,2,5,6,8,9,10}
//   B={0,0,1,1,0,2,3,3,4,0,6}  C={1,2,5,6,8,9,10}
//   B={0,0,1,1,2,2,3,3,4,0,6}  C={1,2,4,6,8,9,10}
//   B={0,0,1,1,2,2,3,3,4,0,6}  C={0,2,4,6,8,9,10}
//   B={0,0,1,1,2,2,3,3,4,6,6}  C={0,2,4,6,8,9,10}

// 2 试证明Counting_Sort是稳定的。
//   对相同元素，倒序赋值，后出现的元素赋在靠后的位置，先出现的元素随着第10行操作，放在靠前的位置。维持了稳定性。

// 3 假设在Counting_Sort的第8行循环开始部分，将代码改写为; 8 for j=1 to A.length
//   试证明该算法仍然正确。它还稳定吗？
//   元素依旧按照位置顺序放入输出数组，仍然正确。
//   不稳定，导致先出现的元素放在靠后的位置，10行操作使后出现的元素放在靠前位置，违反稳定性定义。

// 4 设计一个算法，能够对于任何给定的介于0到k之间的n个整数先进行预处理，然后在O(1)时间内回答输入的n个整数有多少个落在区间[a...b]内。预处理时间应为theta(n+k)。
//   Counting(A,k,a,b)
//   1 ket C[0...k] be a new array
//   2 for i=0 to k
//   3     C[i] = 0
//   4 for j=1 to A.length
//   5     C[A[j]] = C[A[j]] + 1  // C[i]存放等于i的元素个数
//   6 for i=1 to k
//   7     C[i] = C[i] + C[i-1]   // C[i]存放小于等于i的元素个数
//   8 return C[b]-C[a-1]

// 8.3 基数排序
//   一种用在卡片排序机上的算法。一张卡片80列，每一列可以有12处位置穿孔。对排序机编程检查每个卡片的给定列，根据穿孔位置分别放入12个容器。第一个位置穿孔的放在最上，第二个其次。
//   对十进制数字，每列只用到10个位置。一个d位数字占用d列。卡片机一次只能看一列，n张d位数排序需要设计一个算法。
//   直觉上从最高位往下排序，但会产生许多需要临时保持的卡片，所以采用从最低位向高位排序。最低位排序好合成一叠，再排序次低位，重复直至所有位排序完成。
//   为了保证基数排序的正确性，每一位的排序算法必须稳定。
//   在串行随机存取计算机上，有时会使用基数排序来对具有多关键字域的记录进行排序。
//   假设n个d位元素存放在数组A中，其中第一位是最低位，第d位是最高位。
//   Radix_Sort(A,d)
//   1 for i=1 to d
//   2     use a stable sort to sort array A on digit i
// 8.3.1 引理8.3
//   给定n个d位数，其中每一个数位有k个可能的取值。如果Radix_Sort使用的稳定排序算法耗时theta(n+k),那么它可以在theta(d(n+k))时间内将这些数排好序。
//   证明：算法时间代价依赖与for循环内使用的子过程算法耗时，for循环次数d*稳定排序算法耗时theta(n+k)=theta(d(n+k))
//         当d为常数且k=O(n)时，基数排序具有线性时间代价。一般情况中，可以灵活决定如何将每个关键字分解成若干位。
// 8.3.2 引理8.4
//   给定一个b位数和任何正整数r<=b，如果Radix_Sort使用的稳定排序算法对数据取值区间是0到k的输入进行排序耗时theta(n+k)，那么它可以在theta((b/r)(n+2~r))时间内将这些数排好序。
//   证明：对于一个值r<=b，每个关键字可以看做d=[B/R]个r位数。每个数都是在0到2~r-1内的一个整数，采用计数排序，k=2~r-1.
//         每轮排序花费时间theta(n+k) = theta(n+2~r),计数排序总花费theta(d(n+2~r)) = theta((b/r)(n+2~r))
//   对于给定的n和b，希望选择的r能够最小化表达式theta((b/r)(n+2~r)). 如果b<[lgn],则对于任何r<=b都有(n+2~r)=theta(n),r=b这一结果渐近最优。
//   如果b>=[lgn]，选择r=[lgn]可以得到偏差不超过常数系数范围内的最优时间代价。运行时间为theta(bn/lgn).
//   基数排序期望运行时间为theta(n),看似比快排要好，但是隐藏的常数因子要大得多，且不是原址排序会占用主存空间。具体应用要根据硬件、需求取舍。

// test
// 1 说明Radix_Sort在下列英文单词上的操作过程;cow,dog,sea,rug,row,mob,box,tab,bar,ear,tar,dig,big,tea,now,fox
//   cow  sea  tab  bar
//   dog  tea  bar  big
//   sea  mob  ear  box
//   rug  tab  tar  cow
//   row  dog  sea  dig
//   mob  rug  tea  dog
//   box  dig  dig  ear
//   tab  big  big  fox
//   bar  bar  mob  mob
//   ear  ear  dog  now
//   tar  tar  cow  row
//   dig  cow  row  rug
//   big  row  now  sea
//   tea  now  box  tab
//   now  box  fox  tar
//   fox  fox  rug  tea

// 2 下面的排序算法中哪些是稳定的：插入排序、归并排序，堆排序、快速排序。给出一个能使任何排序算法都稳定的方法。给出方法带来的额外时间和空间开销是？
//   稳定：插入排序、归并排序。
//   开辟额外空间theta(n),存储元素的原始索引。通过与原始索引的位置比较保证相同元素的前后次序不变。

// 3 利用归纳法证明基数排序是正确的。在哪里需要假设所用底层排序算法是稳定的。
//   在证明排序第d位有两个相等元素并不改变d-1位已经排好元素顺序的时候。

// 4 说明如何在O(n)时间内，对0到nnn-1区间内的n个整数进行排序。
//   将n个数都看做n进制数，只需三位即可对0到nnn-1范围内的n个数进行排序。采用基数排序，时间复杂度为O(n)

// 5 本节第一个卡片排序算法中，为排序d位十进制数，最坏情况下需要多少轮排序，最坏情况下需要记录多少堆卡片。
//   排序第i位需要10~i-1遍，最坏情况要等比数列求和(10~d-1)/9遍，工序10~d个堆。

// 8.4 桶排序
//   假设输入数据服从均匀分布，平均情况下它的时间代价为O(n)。类似计数排序，对输入数据做出某种假设而排序速度快。
//   计数排序假设输入数据属于一个小区间内的整数，桶排序假设输入是由一个随机过程产生（该过程将元素均匀、独立分布在[0,1)区间上）
//   桶排序将[0,1)区间划分为n个相同大小的子区间（称为桶）.将n个输入数分别放到各个桶中。因为输入数据是均匀、独立分布在[0,1）区间上，一般不出现很多数在同一个桶中。
//   先对每个桶中的数进行排序，然后遍历每个桶，按次序列出各个桶中元素即可。
//   假设输入是一个包含n个元素的数组A，每个元素A[i]满足0<=A[i]<1。此外，需要一个临时数组B[0...n-1]存放链表(桶),并假设存在一种用于维护这些链表的机制。
//   Bucket_Sort(A)
//   1 n = A.length
//   2 let B[0...n-1] be a new array
//   3 for i=0 to n-1
//   4     make B[i] an empty list
//   5 for i=1 to n
//   6     insert A[i] into list B[nA[i]]
//   7 for i=0 to n-1
//   8     sort list B[i] with insertion sort
//   9 concatenate the lists B[0],B[1],...,B[n-1] together in order
//   验证算法正确性，观察元素A[i]和A[j]。假设A[i]<=A[j]，由于[nA[i]]<=[nA[j]],元素A[i]、A[j]放入同一个桶，或者被放入一个下标更小的桶。
//   如果放入同一桶，7-8行for循环会将按适当顺序排列。如果落入不同桶，9行会将桶按适当顺序排列。因此，算法正确。
//   分析桶排序运行时间。
//       最坏情况下，除第8行以外，其他各行时间代价都是O(n)。还需分析第8行n次插入排序调用花费时间。
//         分析调用插入排序时间代价。假设ni是表示桶B[i]中元素个数的随机变量，因为插入排序的时间代价是平方阶的，所以桶排序时间代价：
//         T(n) = theta(n) + 求和(i=0 to n-1)O(ni~2)
//       平均情况下，对输入数据取期望有：
//         E[T(n)] = E[theta(n) + 求和(i=0 to n-1)(ni~2)]
//                 = theta(n) + 求和(i=0 to n-1)(E[O(ni~2)])  // 期望线性性质
//                 = theta(n) + 求和(i=0 to n-1)(O(E[ni~2]))  // 公式（C.22）
//         E[ni~2] = 2 - 1/n  对所有i=0,1,...,n-1成立。（因为输入数组A的每一个元素等概率落入任意一个桶中，所以每个桶i具有相同期望值E[ni~2]）
//         证明上式，定义指示器随机变量：对所有i=0,1,...,n-1和j=1,2,...,n，Xij = I{A[j]落入桶i}
//              因此，ni = 求和(j=1 to n)(Xij)
//              展开平方项，重新组合各项：E[ni~2] = E[(求和(j=1 to n)(Xij))~2]
//                                                = E[求和(j=1 to n)(求和(k=1 to n)(XijXik))]
//                                                = E[求和(j=1 to n)(Xij~2) + 求和(1<=j<=n)(求和(1<=k<=n)(XijXik))]
//                                                = 求和(j=1 to n)(E[Xij~2]) + 求和(1<=j<=n)(求和(1<=k<=n)(E[XijXik]))
//              分别计算这两项的累加和指示器变量Xij为1的概率是1/n，其他情况为0，有：
//                  E[Xij~2] = 1~2*1/n + 0~2*(1 - 1/n) = 1/n
//              当k != j时，随机变量Xij和Xik是独立的，因此有：
//                  E[XijXik] = E[Xij]E[Xik] = 1/n~2
//              于是，E[ni~2] = n*1/n + n(n-1)*1/n~2 = 2 - 1/n
//         期望运行时间为theta(n) + nO(2 - 1/n) = theta(n)
//         即使输入数据不服从均匀分布，桶排序也仍然可以线性时间内完成。只需要输入数据满足：所有桶的大小的平方和与总的元素数呈线性关系。

// test 
// 1 说明Bucket_Sort在数组A={0.79,0.13,0.16,0.64,0.39,0.20,0.89,0.53,0.71,0.42}上的操作过程
//       A         B
//   1  0.79     0 /
//   2  0.13     1    0.13   0.16  /
//   3  0.16     2    0.20   /
//   4  0.64     3    0.39   /
//   5  0.39     4    0.42   /
//   6  0.20     5    0.53   /
//   7  0.89     6    0.64   /
//   8  0.53     7    0.71   0.79  /
//   9  0.71     8    0.89   /
//  10  0.42     9    /

// 2 解释为什么桶排序在最坏情况下运行时间是theta(nn)？我们应该如何修改算法，使其保持平均情况为线性时间代价的同时，最坏情况下时间代价为theta(nlgn)?
//   桶排序最坏情况，所有元素在一个桶内用插入排序排，插入排序最坏耗时theta(nn)，所以桶排序最坏情况运行时间为theta(nn)。
//   将桶排序内部的排序换成时间复杂度为O(nlgn)的排序算法(如堆排序、快排、归并排序)，但桶排序涉及链表，只能使用归并排序。

// 3 设X是一个随机变量，用于表示将一枚硬币抛掷两次时，正面朝上的次数。E[X~2]是多少？(E[X])~2是多少？
//   X    0    1    2
//  P(X)  1/4  1/2  1/4
//   E[X~2] = 0~2*1/4 + 1~2*1/2 + 2~2*1/4 = 1.5
//   (E[X])~2 = (0*1/4 + 1*1/2 + 2*1/4)~2 = 1

// 4 在单位圆内给定n个点，Pi=(xi,yi)，对所有i=1,2,..,n，有0<xi~2 + yi~2<=1
//   假设所有的点服从均匀分布，即在单位圆的任一区域内找到给定点的概率与该区域的面积成正比。
//   请设计一个在平均情况下有theta(n)时间代价的算法，能够按照点到原点之间的距离di=根号(xi~2 + yi~2)对这n个点进行排序。
//   提示：在Bucket_Sort中，设计适当的桶大小，用以反映各个点在单位圆中均匀分布情况。
//   将单位圆按同心圆面积n等分。即S=pie，每个区域s=pie/n，对应同心圆区域的半径ri=根号(i/n)(i=1,2,...,n)
//   对于第i个等分区域，点到圆心距离属于(ri-1,ri]。对单位圆内的n个点进行桶排序，依据点到圆心距离放入桶。
//   由于按面积等分，按距离放桶，在点如桶前，需要采用二分法，查找点所在区间，耗时O(n);或者用面积做参考，对点(xi,yi)，经过该点的同心圆面积Ai=pie(xi~2 + yi~2),放入第[Ai/S]=[N(xi~2 +yi~2)]个桶中。
//   Circle_Point_Bucket_Sort(X,Y)
//   1 n = X.length
//   2 create 2 new arrays Bx[1...n] and By[1...n]
//   3 for i=1 to n
//   4     make Bx[i] an empty list
//   5     make By[i] an empty list
//   6 for i=1 to n
//   7     j = [N(xi~2 + yi~2)]
//   8     insert X[i] into list Bx[j]
//   9     insert Y[i] into list By[j]
//  10 for i=1 to n
//  11     sort list Bx[i] with insertion sort
//  12     sort list By[i] with insertion sort
//  13 concatenate the lists Bx[1],Bx[2],...,Bx[n] together in order
//  14 concatenate the lists By[1],Bu[2],...,By[n] together in order

// 5 定义随机变量X的概率分布函数P(x)=Pr{X<=x}。假设有n个随机变量Xi服从一个连续概率分布函数P，且可以在O(1)时间内被计算得到。设计一个算法，使其能够在平均情形下在线性时间内完成这些数的排序。
//   根据概率函数P(x)将随机变量Xi划分到n个桶内。对于任一Xi，将其放入第[NP(X[i])]个桶。如果n个随机变量Xi服从概率分布函数P(x),那么执行上述划分后，所有随机变量应当会均匀分布在所有桶中。
//   Random_Variable_Bucket_Sort(X)
//   1 n = X.length
//   2 create a new array B[1...n]
//   3 for i=1 to n
//   4     make B[i] an empty list
//   5 for i=1 to n
//   6     j = [NP(X[i])]
//   7     insert X[i] into list B[j]
//   8 for i=1 to n
//   9     sort list B[i] with insertion sort
//  10 concatenate the lists B[1],B[2],...,B[n] together in order

// 9 中位数和顺序统计量
//  在一个由n个元素组成的集合中，第i个顺序统计量是该集合中第i小的元素。
//  即最小值是第1个顺序统计量，最大值是第n个顺序统计量。
//  中位数是所属集合的中点元素。n为奇数时，中位数是第(n+1)/2个顺序统计量；n为偶数时，中位数分别是第n/2和n/2 + 1个顺序统计量。
//  或称下中位数是第[(n+1)/2]个顺序统计量、上中位数是第[(N+2)/2]个顺序统计量。 本书所用中位数都是下中位数。
//  本章讨论一个由n个互异元素构成集合中选择第i个顺序统计量的问题，将其形式化定义为：
//      输入：一个包含n个互异数的集合A和一个整数i(1<=i<=n)
//      输出：元素x属于A，且A中恰好有i-1个其他元素小于它。
//   可以通过排序在O(nlgn)时间内解决这个问题，也有一些更快的算法可以在O(n)时间内完成。

// 9.1 最小值和最大值
// 9.1.1 找最值
//   在一个有n个元素的集合中，可以通过n-1次比较得出最值。
//   Minimum(A)
//   1 min = A[1]
//   2 for i=2 to A.length
//   3     if min > A[i]
//   4        min = A[i]
//   5 return min
//   为了找到最值，必须要做n-1次比较，从执行次数来看，该算法最优。
// 9.1.2 同时找到最小值最大值
//   某些应用中，必须找到一个包含n个元素的集合中的最小值和最大值。
//   用渐近最优的theta(n)次比较，各需n-1次比较。事实上，只需最大3[n/2]次比较，输入元素成对比较，较小的与当前最小值比，较大的与当前最大值比，每对两个元素共需3次比较。
//   如果n为奇数，将最小值最大值的初值都设为第一个元素的值，成对处理余下元素。如果n为偶数，对前两个元素做一次比较，决定最值初值，成对处理余下元素。

// test
// 1 证明：最坏情况下，找到n个元素中第二小的元素需要n+[lgN]-2次比较。
//   两两比较，找到最小值需要n-1次，过程中产生[lgN]个数大于最小值，从中进行[lgN]-1比较找到这些数的最小值（即第二小的元素）

// 2 证明：在最坏情况下，同时找到n个元素中最大值和最小值的比较次数的下界是[3N/2]-2.
//   (提示：考虑有多少个数有成为最大值或最小值的潜在可能，然后分析每次比较如何影响这些计数)
//   输入元素两两比较，较小比最小值，较大比最大值2个元素每次循环比较3次，仅需n/2次循环，总比较次数为[3N/2]-2

// 9.2 期望为线性时间的选择算法
//   一般选择问题比找最值要难，但两个问题的渐近运行时间相同：theta(n)
//   采用分治算法Randomized_Select只处理划分的一边，利用Randomized_Partition过程。
//   Randomized_Select(A,p,r,i)
//   1 if p==r
//   2    return A[p]
//   3 q = Randmized_Partition(A,p,r)
//   4 k = q-p+1
//   5 if i==k
//   6    return A[q]
//   7 else if i<k
//   8    return Randomized_Select(A,p,q-1,i)
//   9 else return Randomized_Select(A,q+1,r,i-k)
//   Randomized_Select的最坏情况运行时间为theta(nn)。
//   分析Randomized_Select的期望运行时间，设该算法在一个含有n个元素的输入数组A[p...r]上的运行时间是一个随机变量，记为T(n)
//   Randomized_Partition能等概率的返回任何元素作为主元。对每个k，子数组A[p...q]有k个元素的概率为1/n。
//   对所有k=1,2,...,n，定义指示器随机变量Xk为：Xk=I{子数组A[p,,,q]正好包含k个元素}，假设元素互异，有E[Xk]=1/n
//   当调用Randomized_Partition并选择A[q]作为主元时，事先不知道是否会得到正确答案而立即结束，在两个子数组上递归。
//   该过程依赖于第i小的元素相对于A[q]（主元）落在哪个位置。
//   T(n) <= 求和(k=1 to n)(Xk*(T(max(k-1,n-k))+O(n)))
//   E[T(n)] <= E[求和(k=1 to n)(Xk*(T(max(k-1,n-k)))) + O(n)]
//            = 求和(k=1 to n)(E[Xk]*E[T(max(k-1,n-1k))]) + O(n)
//            = 求和(k=1 yo n)(1/n*E[T(max(k-1,n-k)]) + O(n)
//   对max(k-1,n-k) = k-1 若k>[N/2]
//                  = n-k 若k<=[N/2]
//   如果n为偶数，从T([N/2])到T(n-1)的每一项在总和中恰好出现两次；如果n为奇数，除了T([N/2])出现一次外，其他项出现两次，有：
//   E[T(n)] <= 2/n求和(k=[n/2] to n-1)(E[T(k)]) + O(n)
//   用替代假设法得到E[T(n)] = O(n). 假设对满足这个递归式初始条件的某个常数c，有E[T(n)]<=cn,对所有n>0，O(n)所描述的函数有上界an
//   E[T(n)] <= 2/n求和(k=[n/2] to n-1)(ck) + an
//           <= cn - (cn/4 - c/2 - an) (when n<2c/(c-4a))

// test
// 1 证明：在Randomized_Select中，对长度为0的数组，不会进行递归调用。
//   长度为0，第1-2行，满足if语句，直接返回A[p],不进行下面的递归调用。
//   递归调用基于第3行的划分，有r>=q>=p，i<k,L8产生长度为0的数组则p>q-1,则L4中k=q-p+1<2，k=0或1，同时需要i>0且i为整数，不满足i<k，因此L8不产生长度为0的数组。
//   i>k,L9产生长度为0的数组需要q+1>r,即q=r，此时L4中k=q-p+1=r-p+1=原数组长度，相当于没调用（调用出错），因此L9无法产生长度为0的数组。

// 2 讨论：指示器随机变量Xk和T(max(k-1,n-k))是独立的。
//   

// 3 给出Randomized_Select的一个基于循环的版本
//   Randomized_Select(A,p,r,i)
//   1 while ture
//   2    if p==r
//   3       return A[p]
//   4    q=Randomized_Partition(A,p,r)
//   5    k=q-p+1
//   6    if i==k
//   7       return A[q]
//   8    else if i<k
//   9       r=q
//  10    else
//  11       p=q
//  12       i=i-k

// 4 假设用Randomized_Select去选择数组A={3,2,9,0,7,5,4,8,6,1}的最小元素，给出能够导致Randomized_Select最坏情况发生的一个划分序列。
//   当输入数组降序排列时，最坏情况发生。


// 9.3 最坏情况为线性时间的选择算法
//   Select使用Partition算法，但将划分主元也作为输入参数。
//   通过执行下列步骤可以确定一个有n>1个不同元素的输入数组中第i小的元素。
//   1 将输入数组的n个元素划分为[n/5]组，每组5个元素，且至多只有一组由剩下的n mod5个元素组成。
//   2 寻找这[N/5]组中每一组的中位数：首先对每组元素进行插入排序，然后确定每组有序元素的中位数。
//   3 对第2步中找出的[N/2]个中位数，递归调用Select找出其下中位数x
//   4 利用修改的Partition，按中位数x对输入数组进行划分。让k比划分的低区中的元素数目多1.因此x是第k小的元素，有n-k个高区。
//   5 如果i=k，则返回x。如果i<k，则低区递归调用Select找出第i小元素。如果i>k，则高区递归查找第i-k小的元素。
//   分析Select的运行时间，先确定大于划分主元x的元素个数的下界。
//       第二步中，至少有一半大于或等于中位数的中位数x。因此，在这[N/5]个组中，除了当n不能被5整除时产生的所含元素少于5的那个组和包含x的那个组之外，至少有一半的组中有3个元素大于x。
//       大于x的元素个数至少为：3([1/2[N/5]]-2) >= 3n/10 - 6
//       类似地，至少有3n/10 - 6个元素小于x。因此，最坏情况下，第五步中，Select的递归调用最多作用于7n/10 + 6个元素。
//       1、2、4需要O(n)时间，3需要T([N/5]),5需要至多为T(7n/10 + 6)
//       假设T(n)单调递增，任何少于140个元素的输入需要O(1)时间。
//       T(n) <= O(1)                            n<140
//               T([N/5]) + T(7n/10 + 6) + O(n)  n>=140
//       采用替换法证明T(n)线性。 对常数c和所有n>0，有T(n)<=cn.
//           T(n) <= c[N/5] + c(7n/10 + 6) + an
//                <= cn/5 + c + 7cn/10 + 6c + an
//                 = 9cn/10 + 7c + an
//                 = cn + (-cn/10 + 7c + an) (when -cn/10 + 7c + an <=0)
//        当n>70，c>=10a(n/(n-70))。假设n>140,所以有n/(n-70)<=2 ,选择c>=20a就能满足不等式 （其实只需大于70的整数，再选择对应c即可）
//   排序算法有下界Omiga(nlgn),线性时间排序算法对输入进行假设达到线性时间内排序的目的，而线性时间选择算法没有使用排序，不需假设输入就解决了问题。

// test
// 1 在算法Select中，输入元素被分为每组5个元素。如果被分为每组7个元素，该算法仍然会是线性时间吗？证明：如果分成每组3个元素，Select的运行时间不是线性的。
//   每组7个时：至少有一半的组有4个元素大于主元x，至多有5n/7 + 8个元素递归调用Select。
//              T(n) <= T(n/7) + T(5n/7 + 8) + O(n) <= cn + (-cn/7 + 8c + an) (when -cn/7 + 8c + an <= 0)
//              取n>=112,c>=14a,有T(n)=O(n);n<112,T(n)=O(1)
//   每组3个时：至少有2n/3 + 4个元素递归调用。
//              T(n) <= T(n/3) + T(2n/3 + 4) + O(n) <= cn + (4c + an)
//              由于假设c>0,a>0,所以4c+an>0,T(n) != O(n)

// 2 分析Select，证明：如果n>=140,则至少[N/4]个元素大于中位数的中位数x，至少[N/4]个元素小于x？
//   n>=140,3(1/2[N/5] - 2) >= 3n/10 - 6 >= 2.5n/10 + 1 >= n/4 + 1 >= [N/4]
//   同理，至少[N/4]个元素小于x

// 3 假设所有元素互异，在最坏情况下，如何才能使快速排序的运行时间为O(nlgn).
//   使用最坏情况排序运行时间为O(nlgn)的算法。

// 4 对一个包含n个元素的集合，假设一个算法只使用比较来确定第i小元素，证明：无需额外比较操作，它也能找到第i-1小和第n-i大的元素。
//   

// 5 假设已经有了一个用于求解中位数的黑箱子程序，他在最坏情况下需要线性运行时间。写出一个能解决任一顺序统计量的选择问题的线性时间算法。
//   Select(A,p,r,i)
//   1 if p>=r
//   2    return A[p]
//   3 x = Find(A,p,r) // 黑箱子程序
//   4 q = Partition(A,p,r,t)
//   5 k = q - p + 1
//   6 if i==k
//   7    return A[q]
//   8 else if i<k
//   9    return Select(A,p,q-1,i)
//  10 else
//        return Select(A,q+1,r,i-k)

// 6 对一个包含n个元素的集合，k分位数是指能把有序集合分成k个等大小集合的第k-1个顺序统计量。给出一个能找出某一集合的k分位数的O(nlgk)时间的算法
//   利用类似二分法进行查找。k偶数时，即为原本的二分法；k奇数时，近似二分法，[k/2]附件的整数进行划分。形成一棵递归树，树高为lgk，每层最多O(n).

// 7 设计一个O(n)时间算法，对于给定的包含n个互异元素的集合S和一个正整数k<=n，该算法能确定S中最接近中位数的k个元素。
//   1 求出中位数x
//   2 用x减去集合中的每个数得到差的绝对值存储在数组b中
//   3 求b中第k小的数d
//   4 遍历原集合，输出集合中数据与x差的绝对值<=d的数
//using namespace std;
//void swap(int x, int y)
//{
//	int temp;
//	temp = x;
//	x = y;
//	y = temp;
//}
//int Partition(int a[], int low, int high,int x)
//{
//	int i = low;
//	high--;
//	while (a[i] != x)
//	{
//		i++;
//	}
//	swap(a[low], a[i]);
//	while (low < high)
//	{
//		while (low < high && a[high] >= x)
//		{
//			high--;
//		}
//		a[low] = a[high];
//		while (low < high && a[low] <= x)
//		{
//			low++;
//		}
//		a[high] = a[low];
//	}
//	a[low] = x;
//	return low;
//}
//int Select(int* a, int low, int high, int k)
//{
//	int i, j, x, q, n;
//	n = high - low;
//	if (n < 5)
//	{
//		sort(a + low, a + high);
//		return a[low + k - 1];
//	}
//	for (i = 0; i < n / 5; i++)
//	{
//		sort(a + low + i * 5, a + low + i * 5 + 5);
//		swap(a[low + i], a[low + i * 5 + 2]);
//	}
//	x = Select(a, low, low + n / 5, n / 10 + 1);
//	j = Partition(a, low, high, x);
//	q = j - low + 1;
//	if (q == k)
//	{
//		return x;
//	}
//	else if (q > k)
//	{
//		return Select(a, low, j + 1, k);
//	}
//	else
//		return Select(a, j + 1, high, k - q);
//}
//void Select_K_Numbers(int* a, int n, int k)
//{
//	int* b = new int[n];
//	int i, x, d;
//	x = Select(a, 0, n, (n + 1) / 2);
//	for (i = 0; i < n; i++)
//	{
//		b[i] = abs(a[i] - x);
//	}
//	d = Select(b, 0, n, k);
//	for (i = 0; i < n; i++)
//	{
//		if (abs(a[i] - x) <= d)
//		{
//			printf("%d ", a[i]);
//		}
//		printf("/n");
//	}
//}
//int main()
//{
//	int const n = 9;
//	const int k = 3;
//	int a[n] = { 8,4,1,-89,-12,0,36,789 };
//	Select_K_Numbers(a, n, k);
//	return 0;
//}

// 8 设X[1...n]和Y[1...n]，每个都包含n个有序的元素。请设计一个O(lgn)时间的算法来找出数组X和Y中所有2n个元素的中位数。
//int Search_Median(int* a, int* b, int n, int low, int high)
//{
//	while (low < high)
//	{
//		int middle = (low + high) / 2;
//		if (middle == n - 1 && a[middle] <= b[0])
//		{
//			return a[middle];
//		}
//		else if (middle < n - 1)
//		{
//			if (a[middle] <= b[n - middle - 1] && a[middle] >= b[n - middle - 2])
//			{
//				return a[middle];
//			}
//			else if (a[middle] >= b[n - middle - 1])
//			{
//				high = middle - 1;
//			}
//			else
//			{
//				low = middle + 1;
//			}
//		}
//	}
//	return -1;
//}


// 第三部分 数据结构
//     集合作为计算机科学的基础。算法操作的集合是动态的。
//     不同算法需要对集合执行不同操作。 如：字典(dictionary):在一个集合中插入和删除元素，测试元素是否属于集合。
//     动态集合的元素
//       每个元素都由一个对象表示，一个指向对象的指针就能对其各个属性进行检查和操作。
//       一些类型的动态集合假定对象中的一个关键字值的集合。如果关键字全不相同，可以将动态集合视为一个关键字值的集合。
//       对象可能包含卫星数据，它们与其他对象属性一起移动，但集合实现不使用它们。
//       对象也可以有由集合操作使用的属性（可能包含有关集合中其他对象的数据或指针）。
//     动态集合上的操作
//       两类：简单返回有关集合的查询操作和改变集合的修改操作。一些标准操作如下：
//       search(S,k)：一个查询操作，给定一个集合S和关键字k，返回指向S中某个元素的指向x，使得x.key=k;没有返回NIL
//       insert(S,x):一个修改操作，将由x指向的元素加入集合S中。通常假定元素x中集合S所需要的每个属性都已经被初始化好了。
//       delete(S,x):一个修改操作，给定指针x指向集合S的一个元素，从S中删除x。
//       minimum(S) :一个查询操作，在全序集S上返回一个指向S中具有最小关键字元素的指针。
//       maximum(S) :一个查询操作，在全序集S上返回一个指向S中具有最大关键字元素的指针。
//       successor(S,x):一个查询操作，给定关键字属于全序集S的一个元素x，返回S中比x大的下一个元素的指针；如果x最大，返回NIL。
//       predecessor(S,x):一个查询操作，给定关键字属于全序集S的一个元素x，返回S中比x小的前一个元素的指针；如果x最小，返回NIL。
//       某些情况下，能够将successor和predecessor查询操作推广到一些具有相同关键字的集合上。对于一个有n个关键字的集合，通常假设是调用一次maximum后再调用n-1次successor，就可以按序枚举出该集合中的所有元素。
//       度量一个集合操作的执行时间通常要对照这个集合的大小。
//     10-14描述能用于实现动态集合的几种数据结构。
//     10：给出一些简单数据结构的使用基础，如栈、队列、链表、有根树。
//     11：介绍散列表，支持字典操作insert、delete、search
//     12：介绍二叉搜索树，支持上面所列出的所有动态集合。最坏情况下，一次搜索theta(n)；随机构建下，一次搜索theta(lgn)
//     13：介绍红黑树，二叉搜索树的变种，一种平衡搜索树，称为B树。
//     14：给出如何将红黑树扩张，使其支持基本操作外的一些操作。对关键字集合能够动态维护顺序统计量，实数区间的维护。

// 10 基本数据结构
//    讨论如何使用指针的简单数据结构来表示动态集合。栈、队列、链表和有根树，由数组构造对象和指针的方法。
// 10.1 栈和队列
//  栈和队列都是动态集合，其上进行delete操作所移除的元素是预先设定的。
//  在栈中，被删除的是最近插入的元素：即实现一种后进先出策略。
//  在队列中，被删除的是存在时间最长的元素：先进先出策略。
// 10.1.1 栈(stack)
//  栈上insert操作被称为压入(push)，无元素参数的delete操作被称为弹出(pop).
//  数组[1...n]来实现一个最多容纳n个元素的栈。该数组有一个属性S.top指向最新插入的元素。栈中包含的元素为S[1...S.top]，其中S[1]是栈底元素，S[S.top]是栈顶元素。
//  当S.top=0时，栈中不含元素，即栈是空的。 测试一个栈是否为空可以用查询操作Stack_Empty。 如果试图对空栈执行弹出，则称栈下溢(underflow)，如果S.top超过n，则称栈上溢(overflow)
//  栈的几种操作只需：
//  Stack_Empty(S)
//  1 if S.top == 0
//  2    return TRUE
//  3 else return FALSE

//  Push(S,x)
//  1 S.top = S.top + 1
//  2 S[S.top] = x

//  Pop(S,x)
//  1 if Stack_Empty(S)
//  2    error"underflow"
//  3 else S.top = S.top - 1
//  4    return S[S.top + 1]
//  三种操作都耗时O(1)

// 10.1.2 队列(queue)
//  队列上insert操作称为入队(enqueue)，delete操作称为出队(dequeue);dequeue操作也没有元素参数。
//  队列有队头(head)和队尾(tail)，当有一个元素入队时，放在队尾。
//  数组Q[1...n]表示一个容纳n-1个元素的队列。属性Q.head指向对头元素，属性Q.tail指向下一个新元素将要插入的位置。队列元素存放在Q.head,Q.head+1,...,Q.tail-1处(n-1个)
//  初始时，Q,head=Q.tail=1,队列为空，此时如果删除一个，则队列发生下溢。当Q.head=Q.tail+1时，队列为满，此时如果插入一个，则队列发生上溢。
//  下列伪代码，假设n=Q.length
//   Enqueue(Q,x)
//   1 Q[Q.tail] = x
//   2 if Q.tail == Q.length
//   3    Q.tail = 1
//   4 else Q.tail = Q.tail + 1

//   Dequeue(Q)
//   1 x = Q[Q.head]
//   2 if Q.head == Q.length
//   3    Q.head = 1
//   4 else Q.head = Q.head + 1
//   5 return x
//   两种操作时间都为O(1)

// test
// 2 如何在一个数组A[1...n]中实现两个栈，使得当两个栈元素之和不为n时，两者都不会发生上溢。
//   指针top1指向数组A[1],指针top2指向数组A[n]。入栈时两侧向中间添加，出栈时中间向两侧减少。入栈操作前检查该位置是否为空，空说明没有溢出，满说明栈数组已满，栈上溢停止操作报错。

// 4 重新Enqueue和Dequeue，使之能处理队列的下溢和上溢。
//   Enqueue(Q,x)
//   if Q.head == Q.tail+1
//      error"overflow"
//   else 
//     Q[Q.tail] = x
//     if Q.tail == Q.length
//        Q.tail = 1
//     else Q.tail = Q.tail + 1

//   Dequeue(Q)
//   if Q.head == Q.tail
//      error"underflow"
//   else
//     x = Q[Q.head]
//     if Q.head = Q.length
//        Q.head = 1
//     else Q.head = Q.head + 1
//     return x

// 5 栈插入和删除元素只能在同一端进行，队列的插入操作和删除操作分别在两端进行。但有一种双端队列，其插入和删除操作分别在两端进行。
//   写出4个时间均为O(1)的过程，分别实现在双端队列的两端插入和删除元素的操作，该队列用一个数组实现。
//   Left_Enqueue(Q,x)     // 左端插入
//   if Q.head == Q.tail + 1
//      error"overflow"
//   if Q,head == 1
//      Q[n] = x
//      Q.head = n
//   else
//      Q[Q.head - 1] = x
//      Q.head = Q.head - 1

//   Right_Enqueue(Q,x)    // 右端插入
//   if Q.head == Q.tail + 1
//      error"overflow"
//   else
//      Q[Q.tail] = x
//      if Q.tail == n
//         Q.tail = 1
//      else
//         Q.tail = Q.tail + 1

//   Left_Dequeue(Q)
//   if Q.head == Q.tail
//      error"underflow"
//   else
//      x = Q[Q.head]
//      if Q.head == n
//         Q.head = 1
//      else Q.head = Q.head + 1
//   return x

//   Right_Dequeue(Q)
//   if Q,head == Q.tail
//      error"underflow"
//   else
//      if Q.tail == 1
//         x = Q[n]
//         Q.tail = n
//      else
//         x = Q[Q.tail - 1]
//         Q.tail = Q.tail - 1
//   return x

// 6 说明如何用两个栈实现一个队列
//   使用栈S1和栈S2。 入队：元素压入栈S1 O(1);出队：将栈S1中的所有元素弹出，压入S2，然后弹出栈顶元素 O(n)

// 7 说明如何用两个队列实现一个栈
//   使用队列Q1和队列Q2. 入栈：Q1和Q2之间有一个空队列，将值放入空队列，然后把另一个队列中的所有值依次出队并加入这个队列 O(n)；出栈：直接将非空队列中出队 O(1)

// 10.2 链表(linked list)
//  一种其中各对象按线性顺序排列的数据结构。顺序由对象内的指针决定。
//  双向链表的每个元素都是一个对象，一个对象有一个关键字和两个指针(next\prev)，以及其他辅助数据(卫星数据).
//  设x为链表的一个元素，x.next指向下一个元素,x.prev指向上一个元素。 如果x.prev=NIL，则x为首元素(头);如果x.next=NIL，则x为最后一个元素(尾)。
//  链表可以有多种形式。可以是单链接或双链接的，可以是已排序或未排序的，可以是循环的或非循环的。
//      如果单链接，则省略prev指针；如果已排序，则链表线性顺序与链表元素中的关键词顺序一致；如果链表循环，则表头的prev指向表尾，表尾的next指向表头。
//  本节所处理的链表假设都是未排序且双链接的。
// 10.2.1 链表的搜索
//  List_Search(L,k)采用简单的线性搜索方法，用于查找链表L中第一个关键字为k的元素，并返回指向该元素的指针，没有返回NIL。
//  List_Search(L,k)
//  1 x = L.head
//  2 while x != NIL and x.key != k
//  3       x = x.next
//  4 return x
//  搜索一个有n个对象的链表，过程List_Search在最坏情况下运行时间为theta(n)
// 10.2.2 链表的插入
//  List_Insert将已设置好关键词key的元素x连接入链表前端(插入为表头)
//  List_Insert(L,x)
//  1 x.next = L.head
//  2 if L.head != NIL
//  3    L.head.prev = x
//  4 L.head = x
//  5 x.prev = NIL
//  在一个含n个元素的链表上执行List_Insert的运行时间是O(1)
// 10.2.3 链表的删除
//  List_Delete将一个元素x从链表L中移除。该过程要求给定一个指向x的指针，然后通过一些修改，将x“删除”(断开x与前后元素的链接)
//  要删除就先要找到这个元素(使用List_Search)
//  List_Delete(L,x)
//  1 if x.prev != NIL         // x不是表头
//  2    x.prev.next = x.next  // 则x的上一个元素中指向下一个元素的指针，指向x的下一个元素
//  3 else L.head = x.next     // x是表头，则表头变成x的下一个元素
//  4 if x.next != NIL         // x不是表尾
//  5    x.next.prev = x.prev  // 则x下一个元素中指向上一个元素的指针，指向x的上一个元素
//  运行时间为O(1)，删除给定关键字的元素，最坏情况下要theta(n)，因为要花theta(n)时间找到该元素。
// 10.2.4 哨兵(sentinel)
//  如果可以忽视表头和表尾的边界条件，就能简化List_Delete代码
//  List_Delete'(L,x)
//  1 x.prev.next = x.next
//  2 x.next.prev = x.prev
//  哨兵是一个哑对象，作用是简化边界条件的处理。例如，在L中设置一个对象L.nil，代表NIL，但也和其他对象相同的各个属性。对于代码中出现NIL的引用，全变成对L.nil的引用。
//  将常规的双向链表转变为一个有哨兵的双向循环链表，哨兵位于表头和表尾之间。L.nil.next指向表头，L.nil.prev指向表尾。
//  因此可以去掉L.head,转而使用L.nil.next表示表头位置。空链表用一个哨兵构成。
//  List_Search'(L,x)
//  1 x = L.nil.next
//  2 while x != L.nil and x.key != k
//  3       x = x.next
//  4 return x
//  List_Insert'(L,x)
//  1 x.next = L.nil.next
//  2 L.nil.next.prev = x
//  3 L.nil.next = x
//  4 x.prev = L.nil
//  哨兵不能降低数据结构相关操作的渐近时间界，但是可以降低常数因子。好处往往是简化代码，而不是提高速度。
//  注意慎用哨兵，因为对于较短的链表，使用哨兵占用空间，多个短链表会造成存储浪费。

// test
// 1 单链表上的动态集合操作Insert能否在O(1)时间内实现？Delete呢？
//   Insert操作可以在O(1)内实现。Delete由于需要耗时找到要被删除的元素，所以不能在O(1)内完成。

// 2 用一个单链表L实现一个栈。要求操作push和pop的运行时间仍为O(1)。
//   由于栈操作特点是后进先出，所以插入和删除操作均在表头进行。插入相当于push，删除(无需Search)相当于pop，耗时仍为O(1)

// 3 用单链表实现一个队列，要求操作Enqueue和Dequeue运行时间仍为O(1)。
//   由于队列操作特点是先进先出，所以插入在表头进行，删除在表尾进行。插入相当于Enqueue，删除(无需Search)相当于Dequeue，耗时仍为O(1)

// 4 List_Search'过程中的每一次循环都需两个测试，一是检查x!=L.nil,二是检查x.key!=k。试说明如何省略对x!=L.nil的检查。
//   如果已知链表长度，可以用计数方式忽略对哨兵的检查。
//   最好别用：将哨兵属性值设为x，这样两个检查就合并了。

// 5 使用单向循环链表实现字典操作Insert，Delete和Search,给出所写过程的运行时间。
//   Insert(L,x)
//   if L.nil.next == L.head
//      return "L is full"
//   else
//      L.nil.next = x
//      x = L.nil
// 
//   Delete(L,x)
//   p = L.head
//   while p.next != x
//         if p.next == L.nil
//            return "x is not exist"
//         else
//            p = p.next
//   p.next = x.next
//   x.next = NIl
//   free x
// 
//   Search(L,x)
//   p = L.head
//   while p.next != x
//         if p.next != x
//            error"x is not exist"
//   return p.next

// 6 动态集合Union以两个不相交的集合S1、S2作为输入，并返回集合S=S1∪S2,包含S1、S2所有元素。该操作通常会破坏集合S1和S2
//   试说明如何选用一种合适的表类数据结构，来支持O(1)时间内的Union操作。
//   把第一个链表的尾节点的下一个元素改为第二个链表的头元素即可。

// 7 给出一个theta(n)时间的非递归过程，实现对一个含n个元素的单链表逆转。要求除存储链表本身所需的空间外，该过程只能使用固定大小的存储空间。
//   Reserve_List(L)
//   p = L.head
//   q = p.next
//   while q.next
//         t = q.next
//         q.next = p
//         p = q
//         q = t
//   head.next = NULL
//   q.next = p
//   return q

// 10.3 指针和对象的实现
//  在没有显式的指针数据类型的情况下实现链式数据结构的两种方法。利用数组和数组下标来构造对象和指针。
// 10.3.1 对象的多数组表示
//  对每个属性使用一个数组表示，可以表示一组有相同属性的对象。
//  数组的一个元素存放上一个元素的下标，一个存放关键字，一个存放下一个元素的下标。这样构成一个对象放在数组里，数组含多个对象。
//  通常用一个不能代表数组中任何实际位置的整数(0或-1)表示NIL。变量L存放表头元素的下标。
// 10.3.2 对象的单数组表示
//  计算机内存的字往往从整数0到M-1进行编址，其中M是一个足够大的整数。
//  许多程序设计语言中，一个对象在计算机内存中占据一组连续的存储单元。指针是第一个存储单元的地址加上偏移量。
//  在不支持显式的指针数据类型的编程环境下，采取同样的策略。
//  单数组中，一个对象占用一段连续的子数组A[j...k],对象中的每个属性对应于0到k-j之间的一个偏移量，指向该对象的指针就是下标j。
//  例如假定key、next、prev对于偏移量0，1，2。如果需要读取i.prev的值，只需要指针i的值加2即可。
//  单数组的表示方法比较灵活，允许不同长度的对象存储在同一个数组中，但是管理起来较为困难。 一般采用对象多数组表示法。
// 10.3.3 对象的分配与释放
//  向一个双向链表表示的动态集合插入一个关键字，必须分配一个指向该链表表示中尚未利用的对象的指针。
//    有必要对链表表示中尚未利用的对象空间进行管理，使其能被分配。
//    在某些系统中，由垃圾收集器负责确定哪些对象是未使用的。然而需要应用很简单可由自己负责将未使用的对象返回给存储管理器。
//  以多数组表示的双向链表为例，探讨同构对象的分配与释放问题。
//    假设多数组表示法中的各数组长度为m，且某一时刻该动态集合含有n<=m个元素。n个对象代表现存与集合中的元素，剩下m-n个对象是自由的。自由对象可用来表示将要插入该动态集合的元素。
//    把自由对象存在一个单链表中，称为自由表。自由表只使用next数组，表头存在全局变量free中。 对象不是在L中就是在自由表中，且同时只能存在一个表中。
//    自由表类似于栈：下一个被分配的对象就是最后被释放的那个。
//    Allocate_Object()
//    1 if free == NIL
//    2    error"out of space"
//    3 else x = free
//    4    free = x.next
//    5    return x
//    Free_Object(x)
//    1 x.next = free
//    2 free = x
//    初始时，自由表含有全部n个未分配的对象。一旦自由表用完，再运行Allocate_Object会报错。
//    甚至可以让多个链表共用一个自由表。
//    两过程运行时间都为O(1)。可以将其改造，让对象中的任一属性都可以像自由表的next属性一样使用，从而使其可以对任何同构对象组都适用。

// test
// 1 画图表示序列<13,4,8,19,5,11>,其存储形式为多数组表示的双向链表。
//          1  2  3  4  5  6
//   prev   /  1  2  3  4  5
//   key    13 4  8  19 5  11
//   next   2  3  4  5  6  /

// 2 对一组同构对象用单数组表示法实现，写出过程Allocate_Object和Free_Object.
//   

// 3 在Allocate_Object和Free_Object过程的实现中，为什么不需要设置或重置对象的prev属性？
//   分配内存时，只需要找到该对象(当前分配)以及下一个对象(下次分配),不需要前驱。

// 4 希望双向链表的所有元素在存储器中保持紧凑。(如多数组表示中占用前m个下标位置)
//   假设除指向链表本身的指针外没有其他指针指向该链表元素，试说明如何实现过程Allocate_Object和Free_Object使该过程变得紧凑。(提示使用栈的数组实现)
//   释放的空间放入栈中。申请空间时，若栈非空，弹出栈中元素用于分配；若栈为空。顺序分配空间。

// 5 设L是一个长度为n的双向链表，存储于长度为m的数组key、prev和next中。假设这些数组由维护双链自由表F的两个过程Allocate_Object和Free_Object进行管理。
//   假设m个元素中，恰有n个在链表L上，m-n个在自由表上。给定链表L和自由表F，试写出过程Compactify_List(L,F)，用来移动L中的元素使其占用数组中1,2,...,n的位置。
//   调整F以保持其正确性，并占用数组中n+1,n+2,...,m的位置。要求时间为theta(n),且只使用固定量的额外存储空间。
//   先查找自由表前n个位置中的空位置，保存到临时数组。然后将下标大于n的链表L中的元素与其交换，填满自由表，这样原本不紧凑的链表就变得紧凑了。

// 10.4 有根树的表示
//  表示链表的方法可以推广到任意同构的数据结构。
//  树的结点用对象表示。与链表相似，假设每个结点都有一个关键字key。其余属性随树的种类不同会有所变化。
// 10.4.1 二叉树
//  二叉树结点具有属性p、left、right分别存放父结点、左子结点、右子节点的指针。
//  如果x.p=NIL，则x为根结点。属性T.root指向树T的根结点，如果T.root=NIL,则树为空。
// 10.4.2 分支无限制有根树
//  二叉树表示方法可以推广到每个结点的子节点数至多为常数k的任意类型的树：只需将left和right属性用child1,child2,...,childk代替。
//    当子结点数无限制时，这种方法就失效了，因为不知道应当预先分配多少个属性。
//    此外，即使子节点数k限制在常数内，但若多数结点只有少量子节点，则浪费大量存储空间。
//  因此有一个巧妙的方法可以表示子节点任意的树。其优势在于，对任意n个结点的有根树，只需要O(n)的存储空间。称为左孩子右兄弟表示法。
//    每个结点都包含一个父结点指针p，且T.root指向T的根结点。
//    然而每个结点中不是包含指向每个子节点的指针，而是只有两个指针：
//        1 x.left-child指向结点x最左边孩子的结点
//        2 x.right-sibling指向x右侧相邻的兄弟结点
//        如果x没有子结点，则x.left-child=NIL;如果结点x是其父结点的最右子结点，则x.right-sibling=NIL.
// 10.4.3 树的其他表示方法
//  有时也有其他方法表示有根树。如第六章对一棵完全二叉树用堆来表示，堆用一个单数组加上堆的最末结点的下标表示。
//  根据具体应用选择表示方法。

// test
// 2 给定一个n结点的二叉树，写出一个O(n)时间的递归过程，将该树每个结点的关键字输出。
//   Tree_Print(T)
//   print key[T]
//   if left[T] != NIL
//      Tree_Print(left[T])
//   if right[T] != NIL
//      Tree_Print(right[T])

// 3 给定一个n结点的二叉树，写出一个O(n)时间的非递归过程，将该树每个结点的关键字输出。可以使用一个栈作为辅助数据结构。
//   Tree_Print(T,S)
//   print key[T]
//   Push(S,T)
//   while(true)
//       if left[T] != NIL
//          T <- left[T]
//       else
//          do
//             T = Pop(S)
//             if T = NIL
//                return
//          while(left[T] = NIL)
//          T <- right[T]

// 4 给定一个n结点的任意有根树，写出一个O(n)时间的过程，输出其所有关键字。该树以左子右兄表示法存储。
//   同二叉树遍历输出。

// 5 给定一个n结点的二叉树，写出一个O(n)时间的非递归过程，将该树每个结点的关键字输出。要求除该树本身的存储空间外只能使用固定量的额外存储空间，且过程不得修改树。
//   类似中序遍历，对一个结点，分为：
//   1 如果有左子，先处理左子。
//   2 返回自己，并访问
//   3 如果有右子，处理右子
//   4 返回父结点
//   5 如果从左子返回说明右子没有处理从2开始，如果从右子返回说明这一层处理完毕从4开始。
//   6 返回到根结点时，遍历结束。
//  Print(T)
//	root_num = 0
//  last = now = T.root
//  while (root_num != 2)
//     if last == now.left-child
//        if now.right-child != NIL
//           last = now
//           now = now.right-child
//           print now.key
//        else
//           last = now
//           now = now.parent
//           if now == T.root
//              root_num += 1
//     else if last == now.right-child
//           last = now
//           now = now.parent
//           if now == T.root
//              root_num += 1
//     else
//           if now.left-child != NIL
//              last = now
//              now = now.left-child
//              print now.key
//           else if now.right-child != NIL
//              last = now
//              now = now.right-child
//              print now.key
//           else
//              last,now = now,last
//              if now == T.root
//                 root_num += 1

// 6 任意有根树的左子右兄表示法中的每个结点用到三个指针。对于任何结点都可以在常数时间到达父结点，并在与其孩子数呈线性关系的时间内到达所有孩子结点。
//   说明如何在每个结点中只使用两个指针和一个布尔值的情况下，使结点的父结点或者所有子节点可以在与其孩子数呈线性关系的时间内到达。
//   首先左子指针不能丢，不然无法寻找子树。
//   其次每一层中最右侧结点没有右子指针，而且一个结点的若干个子结点的父指针都指向自己(即多个子结点重复保存了父指针信息).
//   因此让最右侧的子节点保存父指针，用bool值表示该子节点是否为最右侧子结点。(多个子节点用到父指针时只需向右寻找存在最右结点的父指针)

// 第十一章 散列表(hash table)
//   许多应用都需要一种动态集合，至少需要支持Insert、Search和Delete字典操作。
//   散列表是实现字典操作的一种有效数据结构。其中查找一个元素的时间与链表中查找的时间相同，theta(n)。
//   实际应用中，散列表查找性能极好。在一些合理假设下，散列表中查找一个元素的平均时间是O(1)
//   散列表是普通数组概念的推广。由于对普通数组可以直接寻址，使得能在O(1)时间内访问数组中任意位置。如果存储空间允许，可以提供一个数组为每个可能的关键字保留一个位置，以利用直接寻址技术优势。
//   当实际存储的关键字数目比全部可能关键字总数要小时，采用散列表就成为直接数组寻址的一种有效替代，因为散列表使用一个长度与实际存储的关键字数目成比例的数组来存储。
//   散列表中不是直接把关键字作为下标而是根据关键字计算出相应下标。

// 11.1 直接寻址表
//  当关键字的全域U比较小时，直接寻址是一种简单有效的技术。假设应用用到一个动态集合，其中每个元素都是取自U(m个元素)。假设关键字互异。
//  为表示动态集合，用一个数组(直接寻址表)，记为T[0...m-1]。其中每个位置称为槽(slot)
//  槽k指向集合中一个关键字为k的元素。如果该集合中没有关键字为k的元素，则T[k]=NIL
//  字典操作：
//  Direct_Address_Search(T,k)
//  1 return T[k]
//  Direct_Address_Insert(T,x)
//  1 T[x.key] = x
//  Direct_Address_Delete(T,x)
//  1 T[x.key] = NIL
//  上述每个操作用时O(1)
//   对于某些应用，直接寻址表本身就可以存放动态集合中的元素。即不把每个元素的关键字及其卫星数据都放在直接寻址表外部的一个对象中，再由表中某个槽的指针指向该对象。
//   从而直接把对象放在槽中，节省空间。使用对象内的一个特殊关键字来表明该槽为空槽。
//   通常不必存储该对象的关键字属性，因为如果知道一个对象在表中的下标就可以得到关键字。然而，如果不存储关键字就必须有某种方法确定某个槽是否为空。

// test
// 1 假设一动态集合S用一个长度为m的直接寻址表T来表示。请给出一个查找S中最大元素的过程。所给过程在最坏情况下的运行时间为？
//   最坏情况下，逐一遍历，耗时O(m)

// 2 位向量是一个仅包含0和1的数组。长度为m的向量所占空间要比包含m个指针的数组少得多。请说明如何用一个位向量来表示一个包含不同元素的动态集合。字典操作时间为O(1)
//   用二进制表示关键字。

// 3 试说明如何实现一个直接寻址表，表中各元素关键字不必都不相同，且各元素可以有卫星数据。
//   所有三种字典操作的运行时间应为O(1).
//   由于各元素关键字不互异，所以可以将元素关键字与卫星数据作为新关键字(判断依据)，再由指针进行字典操作。

// 11.2 散列表
//  直接寻址技术缺点明显：如果全域很大，则在一台标准计算机可用内存中，要存储一张大小为U的表T不太实际。实际存储的关键字集合K也许比U小得多，大部分空间浪费了。
//  当存储在字典中的关键字集合K比所有可能的关键字U要小许多时，散列表需要的存储空间要比直接寻址小得多。
//    尤其，当散列表存储需求小于theta(k)，同时散列表中查找一个元素的优势仍得到保持，只需要O(1)时间。区别这个耗时对散列表是平均情况耗时，对直接寻址是最坏情况耗时。
//  直接寻址方式下，具有关键字k的元素被存在槽k中。散列方式下，该元素存在槽h(k)中；即利用散列函数h，由关键字k计算出槽的位置。函数h将关键字的全域U映射到散列表T的槽位上。
//    散列表的大小m一般比U小得多。可以说一个具有关键字k的元素被散列到槽h(k)上，也可以说是h(k)是关键字k的散列值。散列函数缩小了数组下标的范围，减小了数组大小。
//    此处存在一个问题：两个关键字可能映射到同一个槽中，称之为冲突(collision)。
//    可以找一个合适的散列函数h来避免所有冲突。散列愿意指随机混杂和拼凑，使h尽可能随机从而避免冲突或使冲突次数最小化。另一方面需要某种方法解决可能的冲突。
//    链接法使一种最简单的冲突解决方法。还有一种解决方法称为开放寻址法。
// 11.2.1 通过链接法解决冲突
//  把散列同一槽中的所有元素都放在一个链表中。槽j中有一个指针，指向存储所有散列到j的元素的链表的表头；如果不存在这样的元素，则槽j中为NIL。
//  Chained_Hash_Insert(T,x)
//  1 insert x at the head of list T[h(x.key)]
//  Chained_Hash_Search(T,k)
//  1 search for an element with key k in list T[h(k)]
//  Chained_Hash_Delete(T,x)
//  1 delete x from the list T[h(x.key)]
//  插入操作的最坏情况运行时间为O(1).插入过程在某种程度上要快一些，因为假设待插入元素x没有出现在表中；如果需要可以在插入前执行一个搜索来检查这个假设。
//  查找操作的最坏情况运行时间与表的长度成正比。
//  如果散列表中的链表是双向链接的，则删除一个元素x(已知x的指针)的操作可以在O(1)时间内完成。(如果链表单向链接，则为例删除元素x，必须先在表中找到元素改变其next属性)
// 11.2.2 链接法散列分析
//  给定一个能存放n个元素的、具有m个槽位的散列表T，定义T的装载因子a为n/m，即一个链的平均存储元素数。
//  用链接法散列的最坏情况性能很差：所有的n个关键字都散列到同一个槽中，从而产生出一个长度为n的链表。这时，最坏情况下查找时间为theta(n),加上计算散列函数时间，和用链表链接所有元素差不多。
//  散列方法的平均性能依赖于所选取的散列函数h，将所有关键字集合分布在m个槽位上的均匀程度。先加上任意给定元素等可能散列到m个槽中的任何一个，且与其他元素被散列到什么位置无关，称之为简单均匀散列。
//    对j=0,1,...,m-1，列表T[j]的长度用nj表示，有：n=n0 + n1 + ... + n(m-1) 并且nj的期望值为E[nj]=a=n/m
//    假定可以在O(1)时间内计算出散列值h(k)，从而查找关键字为k的元素的时间线性依赖于表T[h(k)]的长度nh(k)。考虑查找算法查找元素的期望数：1.查找不成功 2.成功找到
//    定理11.1 在简单均匀散列的假设下，对于用链接法解决冲突的散列表，依次不成功的查找的平均时间为theta(1+a)
//      证明：在简单均匀散列下，任何未被存储在表中的关键字k都等可能被散列到m个槽中的一个。不成功时，查找的期望时间就是查找至链表T[h(k)]末尾的期望时间，长度为E[nh(k)]=a,即一次不成功的查找平均检查a个元素总时间为theta(1+a)
//    对于成功查找情况不同，某个链表被查找到的概率与它所包含的元素数成正比。
//    定理11.2 在简单均匀散列下，对于用链表法解决冲突的散列表，一次成功的查找所需平均时间为theta(1+a)
//      证明：假定要查找的元素是表中存放的n个元素中的任何一个，且等可能的。对元素x的一次成功查找中，所检查的元素数就是x所在链表中x前面的元素数多1.
//            该链表中，新元素都在表头插入，因此x之前的元素都是在x之后被插入的。
//            为了确定所检查元素的期望数目，对x所在链表，在x之后插入到表中的期望元素数加1，再对表中n个元素x取平均。
//            设xi表示插入到表中的第i个元素(i=1...n),并设ki = xi.key。对关键字ki和kj，定义指示器随机变量Xij=I{h(ki) = h(kj)}
//            在简单均匀散列的假设下，有Pr{h(ki) = h(kj)} = 1/m  由引理5.1得，E[Xij]=1/m
//            在一次成功的查找中，检查元素的期望数目为：
//              E[1/n*求和(i=1 to n)(1+求和(j=i+1 to n)(Xij))] = 1/n*求和(i=1 to n)(1+求和(j=i+1 to n)(E[Xij]))
//                                                             = 1/n*求和(i=1 to n)(1+求和(j=i+1 to n)(1/m))
//                                                             = 1 + 1/nm*(求和(i=1 to n)(n) - 求和(i=1 to n)(i))
//                                                             = 1 + (n-1)/2m
//                                                             = 1 + a/2 -1/2n
//              耗时即为theta(2 + a/2 -1/2n) = theta(1+a) 字典全部操作平均情况下都可以在O(1)时间内完成。

// test
// 1 假设用一个散列函数h将n个不同的关键字散列到一个长度为m的数组T中。假设采用简单均匀散列，那么期望的冲突数是多少？
//   更准确的，集合{{k,l}:k!=l,且h(k)=h(l)}基的期望值是多少？
//   C2(n) 1/m

// 2 对于一个用链接法解决冲突的散列表，说明将关键字5，28，19，15，20，33，12，17，10插入到该表过程。设该表有9个槽位，并设其散列函数为h(k) = k mod 9
//   

// 3 如果将链模式改动一下，使得每个链表都能保持已排好序的顺序，散列的性能就可以有较大的提高。改动对成功查找、失败查找、插入和删除操作的运行时间有何影响？
//   成功查找：没影响
//   失败查找：提高效率
//   插入：降低效率
//   删除：没影响

// 4 说明在散列表内部，如何通过将所有未占用的槽位链接成一个自由链表，来分配和释放元素所占的存储空间。假定一个槽位可以存储一个标志、一个元素加上一个或两个指针。
//   所有的字典和自由链表操作均应具有O(1)的期望运行时间。该自由链表需要是双向链表吗？或者只需要单链表即可？
//   链接方式和第十章自由链表存储方法相同，但是分配元素不是按照顺序而是按照散列函数。双向链表更利于自由链表的插入和删除操作。

// 5 假设一个具有n个关键字的集合存储到一个大小为m的散列表中。试说明如果这些关键字均源于全域U，且|U|>nm，则U中还有一个大小为n的子集，其由散列到同一槽位中的所有关键字构成，使得链接法散列的查找时间最坏情况下为theta(n)
//   最坏情况下，n个关键字散列到同一槽中，该槽中查找时间即为theta(n)

// 6 假设将n个关键字存储到一个大小为m且通过链接法解决冲突的散列表中，同时已知每条链的长度，包括其中最长链的长度L。
//   请描述从散列表的所有关键字中均匀随机地选择某一元素并在O(L*(1+1/a))的期望时间内返回该关键字的过程。
//   a=n/m,L为最长链长度,即L>=a。 所以L*(1 + 1/a) >= 1+a
//   又因为成功查找期望时间为O(1+a),即O(L*(1+1/a))

// 11.3 散列函数
//  如何设计好的散列函数，并介绍三种具体方法。其中两种本质上属于启发式方法，第三章方法则利用随机技术来提供可证明的良好性能
//  好的散列函数的特点
//    好的散列函数应尽可能满足简单均匀散列假设：每个关键字等可能地散列到m个槽中，且与其他关键字已散列到哪个槽无关。
//    有时，知道关键字的概率分布，可用于验证其是否符合简单均匀散列假设，有时不知道概率分布则不能检查。
//    在实际应用中，常常可以运用启发式方法来构造性能好的散列函数。设计时，可以利用关键字分布的有用信息。
//    一种好的方法导出的散列值，在某种程度上应独立于数据可能存在的任何模式。例如“除法散列”
//    最后，注意到散列函数的某些应用可能会要求比简单均匀散列更强的性质。例如，可能希望某些近似的关键字具有截然不同的散列值。
//  将关键字转换为自然数
//    多数散列函数都假定关键字的全域为自然数集N={0,1,2,...}。因此，如果所给关键字不是自然数，就需要找到一种方法将它们转换为自然数。
//    例如，一个字符串可以被转换为按适当的基数符号表示的整数。 pt按ASCII码转换为(112,116)对应关键字=112x128+116=14452
// 11.3.1 除法散列法
//  通过取k除以m的余数，将关键字k映射到m个槽中的某一个位置上，散列函数为：h(k) = k mod m
//    例如散列表大小为m=12，关键字k=100，h(k) = 100/12 余 4，即h(k)=4。 由于只需做一次除法，所以除法散列法很快。
//  当应用除法散列法时，要避免选择m的某些值。例如，m不应为2的幂，因为如果m=2^p，则h(k)=就是k的p个最低位数字。除非排除已知各种最低p位的排列形式为等可能，否则设计函数时，最好考虑关键字所有位。
//  一个不太接近2的整数幂的素数往往是一个较好的选择。
//    例如，表中放2000个字符串，每个字符8位。一次不成功查找平均检查三个元素，则分配的散列表大小为m=701。理由：701是接近2000/3但不接近2的任何次幂的素数
// 11.3.2 乘法散列法
//  用关键字k乘常数A(0<A<1)，并提取kA的小数部分。 用m乘这个值，再向下取整。 散列函数为：h(k) = [m(kA mod 1)]
//  乘法散列法的一个优点是对m的选择不是很关键，一般选择为2的某个幂次(m=2^p,p为某个整数)。这是因为按该方法再大多数计算机上很容易实现。
//    假如，某计算机的字长为w位，而k正好可用一个单字表示。限制A为形如s/2^w的一个分数，0<s<2^w。
//    先用w位整数s=A*2^w乘上k，结果是一个2w位的值r1*2^w + r0，其中r1位乘积的高位字，r0为乘积低位字。所求p位散列值中，包含了r0的p个最高有效位。
//    虽然该方法对任何A值都适用，但对某些值效果更好。最佳选择于待散列的数据的特征有关。Knuth认为A近似(根号5 - 1)/2比较理想。
// 11.3.3 全域散列法
//  任何一个特定的函数都可能出现，n个关键字存到一个槽中。唯一有效的改进方法是随机选择散列函数，使之独立于要存储的关键字。该方法称为全域散列，其平均性能很好。
//  全域散列执行开始时，从一组设计好的函数中，随机选择一个作为散列函数，随机化保证没有哪一种输入会始终导致最好情况。仅当编译器选择了一个随机的散列函数该函数对某一种输入才会出现最差情况，但该情况出现可能性很小。
//  设H为一组有限散列函数，它将给定关键字全域U映射到{0,1,...,m-1}。这样一个函数组称为全域的，如果对每一对不同的关键字k,l属于U，满足h(k)=h(l)的散列函数h属于H的个数至多为|H|/m。
//    换言之，如果从H中随机选择一个散列函数，当关键字k！=l时，两者发生冲突的概率不大于1/m，这也正好是从集合中独立随机h(k)和h(l)是冲突发生的概率。
//  定理11.3 如果h选自一组全域散列函数，将n个关键字散列到一个大小为m的表T中，并用链接法解决冲突。如果关键字k不在表中，则k被散列至其中的链表的期望长度E[nh(k)]至多为a=n/m。如果关键字k在表中，则包含关键字k的链表的期望长度E[nh(k)]至多为1+a





////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// 附录C.2 概率
// 借助样本空间S来定义概率。 S:基本事件的集合。每个基本事件可以视为某个试验的一个可能结果。

// 事件时样本空间S的一个子集。 事件S称为必然事件，事件空称为空事件。
// 如果事件满足A∩B=空，则事件AB是互斥的。
// 将基本事件s属于S看做事件{s}，所有基本事件都是互斥的。

// 概率论公理
// 样本空间S上的概率分布Pr{}是一个从S的事件到实数的映射，满足如下概率论公理：
//   1 对于任意事件A，Pr{A}>=0
//   2 Pr{S}=1
//   3 对于两个互斥事件AB，有Pr{A∪B} = Pr{A} + Pr{B} 。更一般的，对于任意事件序列Ai（i=1，2，...），其两两互斥，有Pr{∪iAi} = 求和i(Ai)
// 称Pr{A}为事件A的概率。由此引申出如下公式：
//   1 Pr{空} = 0
//   2 若A属于B，则Pr{A} <= Pr{B}
//   3 用A`表示S-A（A的补），则Pr{A`} = 1 - Pr{A}
//   4 对任意两个事件AB Pr{A∪B} = Pr{A} + Pr{B} - Pr{A∩B} <= Pr{A} + Pr{B}

// 离散概率分布
// 如果一个概率分布定义在有限或者无限可数的样本空间上，则该概率分布是离散的。
// 令S是样本空间，对于任意事件A，因为基本事件是互斥的，所以有： Pr{A} = 求和(s属于A) (Pr{s})
// 如果S有限，且每个基本事件s属于S的概率为 Pr{s} = 1/|S|
// 则得到的概率分布为S上的均匀概率分布。这种情况下，常从S中随机选择一个元素来描述实验。

// 连续均匀概率分布
// 在连续均匀概率分布中，不是所有样本空间的子集都被看做事件。
// 连续均匀概率分布定义在实数闭区间[a,b]上(a<b)。 区间上每一点都是等可能的。
// 由于区间有无穷点，若每点有同样有限正概率，则违反公理。因此赋予S部分子集以概率
// 对于闭区间[c,d](a<=c<=d<=b),连续均匀概率分布定义事件[c,d]的概率为： Pr{[c,d]} = (d-c)/(b-a) 因此任意一点的概率为0
// 此外 Pr{[c,d]} = Pr{(c,d)}

// 条件概率与独立
// 知道一些关于试验结果的先验知识，条件概率形式化了这部分。
// 已知事件B发生，事件A的条件概率定义为：Pr{A|B} = Pr{A∩B}/Pr{B}
// 也可以理解为，已知B发生，此时A也发生的概率，即B条件下AB同时发生的概率。
// 若Pr{A∩B} = Pr{A}Pr{B} ，则称两个事件是独立的，若Pr{B}不等于0，则其等价于条件概率 Pr{A|B} = Pr{A}
// 如果对于所有1<=i<j<=n，有Pr{Ai∩Aj} = Pr{Ai}Pr{Aj}，则称事件A1，A2，...,An两两独立，它们的子集也满足该等式

// 贝叶斯定理
// 根据条件概率的定义与交换律A∩B=B∩A，对于两个概率不为0的事件A和B，有：
//     Pr{A∩B} = Pr{B}Pr{A|B} = Pr{A}Pr{B|A}
//     Pr{A|B} = Pr{A}Pr{B|A}/Pr{B}
// 以上公式称为贝叶斯定理
// 因为   B = (B∩A)∪(B∩A~)，且B∩A与B∩A~是互斥事件。
// 所以   Pr{B} = Pr{B∩A} + Pr{B∩A~} = Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~}
// 变形得 Pr{A|B} =  Pr{A}Pr{B|A}/(Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~})
// 该定理可以简化条件概率的运算。


// test
// 1 甲抛一枚均匀硬币一次，乙抛一枚均匀硬币两次，甲得到正面朝上结果多于乙的概率?
//   1/2 x 1/4 = 1/8

// 2 证明布尔不等式，对于有限或可数无限事件序列Ai
//   Pr{∪iAi}<= Pr{A1} + Pr{A2} +...
//   Pr{∪iAi} = Pr{A1} + Pr{A2} +... - Pr{∩iAi}
//            <= Pr{A1} + Pr{A2} +...  (when Ai为相互独立事件时取等号)

// 3 假设10张牌，标有1到10的数字，打乱。从牌堆一次一张移除三张牌，依次选出三张牌按照递增顺序排列的概率为？
//   A1：第一张抽到1（1/10） 第二张抽到2（1/9）第三张随便
//                       第二张抽到3（1/9）第三张7/8
//   。。。。。。
//   1/10 x 1/9 x 1/8 x (8+7+6+5+4+3+2+1)
//   A2：第一张抽到2 1/10 x 1/9 x 1/8 x (7+6+5+4+3+2+1)
//   。。。。。。
//   A7：第一张抽到7 1/10 x 1/9 x 1/8 x (2+1)
//   A8：第一张抽到8 1/10 x 1/9 x 1/8 x 1
//   Pr{A} = 求和(1 to 8) Pr{Ai} = 120/720 = 1/6

// 4 证明：Pr{A|B} + Pr{A~|B} = 1
//   Pr{A|B} = Pr{A}Pr{B|A}/(Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~})
//   Pr{A~|B} =  Pr{A~}Pr{B|A~}/(Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~})
//   Pr{A|B} + Pr{A~|B} = (Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~})/(Pr{A}Pr{B|A} + Pr{A~}Pr{B|A~})
